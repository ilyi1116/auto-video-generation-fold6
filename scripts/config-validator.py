#!/usr/bin/env python3
"""
é…ç½®éªŒè¯å·¥å…· - é€‚é… Termux Android ç¯å¢ƒ

åŠŸèƒ½:
1. é¡¹ç›®é…ç½®æ–‡ä»¶éªŒè¯ (pyproject.toml, alembic.ini)
2. ç¯å¢ƒå˜é‡æ–‡ä»¶éªŒè¯ (.env æ–‡ä»¶)
3. Docker é…ç½®éªŒè¯ (docker-compose.yml)
4. æœåŠ¡é…ç½®éªŒè¯ (Dockerfile, requirements.txt)
5. æ•°æ®åº“é…ç½®éªŒè¯ (Alembic migrations)
6. å®‰å…¨é…ç½®æ£€æŸ¥ (æ•æ„Ÿä¿¡æ¯æ –æµ‹)

ä½œè€…: Claude Code
æ—¥æœŸ: 2025-08-04
"""

import json
import logging
import os
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import toml
import yaml
from pydantic import BaseModel, Field

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ValidationIssue(BaseModel):
    """é…ç½®éªŒè¯é—®é¢˜æ¨¡å‹"""
    severity: str  # critical, warning, info
    category: str  # syntax, security, compatibility, missing
    file_path: str
    line_number: Optional[int] = None
    message: str
    suggestion: Optional[str] = None
    details: Dict = Field(default_factory=dict)


class ConfigValidationResult(BaseModel):
    """é…ç½®éªŒè¯ç»“æœæ¨¡å‹"""
    file_path: str
    file_type: str
    status: str  # valid, invalid, missing
    issues: List[ValidationIssue] = Field(default_factory=list)
    metadata: Dict = Field(default_factory=dict)
    timestamp: datetime = Field(default_factory=datetime.now)


class ConfigurationValidator:
    """é…ç½®éªŒè¯å™¨"""
    
    def __init__(self, project_path: str = "."):
        self.project_path = Path(project_path)
        self.is_termux = self._detect_termux()
        self.results: List[ConfigValidationResult] = []
        
        # å®šä¹‰éœ€è¦éªŒè¯çš„é…ç½®æ–‡ä»¶
        self.config_files = {
            "pyproject.toml": {
                "type": "toml",
                "description": "é¡¹ç›®é…ç½®æ–‡ä»¶",
                "required": True,
                "validator": self._validate_pyproject_toml
            },
            "alembic.ini": {
                "type": "ini",
                "description": "Alembic æ•°æ®åº“è¿ç§»é…ç½®",
                "required": True,
                "validator": self._validate_alembic_ini
            },
            "docker-compose.yml": {
                "type": "yaml",
                "description": "Docker Compose é…ç½®",
                "required": True,
                "validator": self._validate_docker_compose
            },
            "docker-compose.unified.yml": {
                "type": "yaml",
                "description": "ç»Ÿä¸€ Docker Compose é…ç½®",
                "required": False,
                "validator": self._validate_docker_compose
            },
            ".env": {
                "type": "env",
                "description": "ç¯å¢ƒå˜é‡æ–‡ä»¶",
                "required": False,
                "validator": self._validate_env_file
            },
            "config/environments/development.env": {
                "type": "env",
                "description": "å¼€å‘ç¯å¢ƒé…ç½®",
                "required": True,
                "validator": self._validate_env_file
            },
            "config/environments/production.env": {
                "type": "env",
                "description": "ç”Ÿäº§ç¯å¢ƒé…ç½®",
                "required": False,
                "validator": self._validate_env_file
            }
        }
        
        # å®šä¹‰æ•æ„Ÿä¿¡æ¯æ¨¡å¼
        self.sensitive_patterns = [
            (r'password\s*=\s*["\']?[^\s"\'\\n]+', "å¯†ç å¯èƒ½æ˜æ–‡å­˜å‚¨"),
            (r'secret\s*=\s*["\']?[^\s"\'\\n]+', "ç§˜é’¥å¯èƒ½æ˜æ–‡å­˜å‚¨"),
            (r'api[_-]?key\s*=\s*["\']?[^\s"\'\\n]+', "API å¯†é’¥å¯èƒ½æ˜æ–‡å­˜å‚¨"),
            (r'token\s*=\s*["\']?[^\s"\'\\n]+', "ä»¤ç‰Œå¯èƒ½æ˜æ–‡å­˜å‚¨"),
            (r'private[_-]?key', "ç§é’¥ä¿¡æ¯"),
            (r'-----BEGIN\s+(RSA\s+)?PRIVATE\s+KEY-----', "PEM æ ¼å¼ç§é’¥")
        ]
        
        logger.info(f"é…ç½®éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ - Termux: {self.is_termux}, é¡¹ç›®è·¯å¾„: {self.project_path}")
    
    def _detect_termux(self) -> bool:
        """æ£€æµ‹æ˜¯å¦åœ¨ Termux ç¯å¢ƒä¸­è¿è¡Œ"""
        return (
            os.environ.get('PREFIX', '').startswith('/data/data/com.termux') or
            'termux' in os.environ.get('HOME', '').lower() or
            Path('/data/data/com.termux').exists()
        )
    
    def _add_issue(self, result: ConfigValidationResult, severity: str, category: str, 
                   message: str, line_number: Optional[int] = None, 
                   suggestion: Optional[str] = None, details: Optional[Dict] = None):
        """æ·»åŠ éªŒè¯é—®é¢˜"""
        issue = ValidationIssue(
            severity=severity,
            category=category,
            file_path=result.file_path,
            line_number=line_number,
            message=message,
            suggestion=suggestion,
            details=details or {}
        )
        result.issues.append(issue)
    
    def _read_file_safely(self, file_path: Path) -> Tuple[bool, Optional[str], Optional[str]]:
        """å®‰å…¨è¯»å–æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return True, content, None
        except FileNotFoundError:
            return False, None, "æ–‡ä»¶ä¸å­˜åœ¨"
        except PermissionError:
            return False, None, "æ²¡æœ‰æ–‡ä»¶è¯»å–æƒé™"
        except UnicodeDecodeError:
            return False, None, "æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œé UTF-8 æ ¼å¼"
        except Exception as e:
            return False, None, f"è¯»å–æ–‡ä»¶å¼‚å¸¸: {str(e)}"
    
    def _check_sensitive_content(self, result: ConfigValidationResult, content: str):
        """æ£€æŸ¥æ•æ„Ÿä¿¡æ¯"""
        lines = content.split('\\n')
        
        for line_num, line in enumerate(lines, 1):
            for pattern, description in self.sensitive_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    self._add_issue(
                        result, "warning", "security",
                        f"{description}: {line.strip()[:50]}...",
                        line_number=line_num,
                        suggestion="è€ƒè™‘ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–åŠ å¯†å­˜å‚¨æ•æ„Ÿä¿¡æ¯",
                        details={"pattern": pattern, "matched_line": line.strip()}
                    )
    
    def _validate_pyproject_toml(self, file_path: Path, content: str) -> ConfigValidationResult:
        """éªŒè¯ pyproject.toml æ–‡ä»¶"""
        result = ConfigValidationResult(
            file_path=str(file_path),
            file_type="toml",
            status="valid"
        )
        
        try:
            # è§£æ TOML æ–‡ä»¶
            config = toml.loads(content)
            result.metadata["parsed_config"] = True
            
            # æ£€æŸ¥å¿…è¦çš„èŠ‚
            required_sections = ['build-system', 'project']
            for section in required_sections:
                if section not in config:
                    self._add_issue(
                        result, "warning", "missing",
                        f"ç¼ºå°‘å¿…è¦çš„èŠ‚: [{section}]",
                        suggestion=f"æ·»åŠ  [{section}] èŠ‚åˆ° pyproject.toml"
                    )
            
            # æ£€æŸ¥é¡¹ç›®ä¿¡æ¯
            if 'project' in config:
                project = config['project']
                
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                required_fields = ['name', 'version', 'description']
                for field in required_fields:
                    if field not in project:
                        self._add_issue(
                            result, "warning", "missing",
                            f"é¡¹ç›®ä¿¡æ¯ä¸­ç¼ºå°‘ {field} å­—æ®µ"
                        )
                
                # æ£€æŸ¥ä¾èµ–
                if 'dependencies' in project:
                    deps = project['dependencies']
                    result.metadata["dependency_count"] = len(deps)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¸¸è§çš„å®‰å…¨é—®é¢˜ä¾èµ–
                    problematic_deps = []
                    for dep in deps:
                        if isinstance(dep, str):
                            dep_name = dep.split('==')[0].split('>=')[0].split('<=')[0].strip()
                            # è¿™é‡Œå¯ä»¥æ·»åŠ å·²çŸ¥çš„é—®é¢˜ä¾èµ–æ£€æŸ¥
                            if 'insecure' in dep_name.lower():
                                problematic_deps.append(dep_name)
                    
                    if problematic_deps:
                        self._add_issue(
                            result, "warning", "security",
                            f"å¯èƒ½ä¸å®‰å…¨çš„ä¾èµ–: {', '.join(problematic_deps)}"
                        )
            
            # æ£€æŸ¥æ„å»ºç³»ç»Ÿ
            if 'build-system' in config:
                build_system = config['build-system']
                if 'requires' not in build_system:
                    self._add_issue(
                        result, "warning", "missing",
                        "æ„å»ºç³»ç»Ÿä¸­ç¼ºå°‘ requires å­—æ®µ"
                    )
            
        except toml.TomlDecodeError as e:
            result.status = "invalid"
            self._add_issue(
                result, "critical", "syntax",
                f"TOML è¯­æ³•é”™è¯¯: {str(e)}",
                suggestion="æ£€æŸ¥ TOML è¯­æ³•æ˜¯å¦æ­£ç¡®"
            )
        except Exception as e:
            result.status = "invalid"
            self._add_issue(
                result, "critical", "syntax",
                f"è§£ææ–‡ä»¶å¤±è´¥: {str(e)}"
            )
        
        # æ£€æŸ¥æ•æ„Ÿä¿¡æ¯
        self._check_sensitive_content(result, content)
        
        return result
    
    def _validate_alembic_ini(self, file_path: Path, content: str) -> ConfigValidationResult:
        """éªŒè¯ alembic.ini æ–‡ä»¶"""
        result = ConfigValidationResult(
            file_path=str(file_path),
            file_type="ini",
            status="valid"
        )
        
        try:
            import configparser
            
            config = configparser.ConfigParser()
            config.read_string(content)
            
            result.metadata["parsed_config"] = True
            result.metadata["sections"] = list(config.sections())
            
            # æ£€æŸ¥å¿…è¦çš„èŠ‚
            required_sections = ['alembic']
            for section in required_sections:
                if section not in config:
                    self._add_issue(
                        result, "critical", "missing",
                        f"ç¼ºå°‘å¿…è¦çš„èŠ‚: [{section}]"
                    )
            
            # æ£€æŸ¥ alembic èŠ‚çš„å¿…è¦é…ç½®
            if 'alembic' in config:
                alembic_section = config['alembic']
                
                required_keys = ['script_location', 'sqlalchemy.url']
                for key in required_keys:
                    if key not in alembic_section:
                        self._add_issue(
                            result, "critical", "missing",
                            f"alembic èŠ‚ä¸­ç¼ºå°‘å¿…è¦çš„é…ç½®: {key}"
                        )
                
                # æ£€æŸ¥æ•°æ®åº“ URL æ ¼å¼
                if 'sqlalchemy.url' in alembic_section:
                    db_url = alembic_section['sqlalchemy.url']
                    if not db_url.startswith(('postgresql', 'sqlite', 'mysql')):
                        self._add_issue(
                            result, "warning", "compatibility",
                            f"ä¸å¸¸è§çš„æ•°æ®åº“ URL æ ¼å¼: {db_url[:50]}..."
                        )
                    
                    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ˜æ–‡å¯†ç 
                    if '@' in db_url and ':' in db_url:
                        self._add_issue(
                            result, "warning", "security",
                            "æ•°æ®åº“ URL ä¸­å¯èƒ½åŒ…å«æ˜æ–‡å¯†ç ",
                            suggestion="è€ƒè™‘ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶æ¥å­˜å‚¨æ•°æ®åº“å‡­æ®"
                        )
            
        except configparser.Error as e:
            result.status = "invalid"
            self._add_issue(
                result, "critical", "syntax",
                f"INI æ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}"
            )
        except Exception as e:
            result.status = "invalid"
            self._add_issue(
                result, "critical", "syntax",
                f"è§£ææ–‡ä»¶å¤±è´¥: {str(e)}"
            )
        
        # æ£€æŸ¥æ•æ„Ÿä¿¡æ¯
        self._check_sensitive_content(result, content)
        
        return result
    
    def _validate_docker_compose(self, file_path: Path, content: str) -> ConfigValidationResult:
        """éªŒè¯ Docker Compose æ–‡ä»¶"""
        result = ConfigValidationResult(
            file_path=str(file_path),
            file_type="yaml",
            status="valid"
        )
        
        try:
            # è§£æ YAML æ–‡ä»¶
            config = yaml.safe_load(content)
            result.metadata["parsed_config"] = True
            
            # æ£€æŸ¥ç‰ˆæœ¬
            if 'version' not in config:
                self._add_issue(
                    result, "warning", "missing",
                    "ç¼ºå°‘ Docker Compose ç‰ˆæœ¬å£°æ˜"
                )
            else:
                version = config['version']
                result.metadata["compose_version"] = version
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†è¿‡æ—¶çš„ç‰ˆæœ¬
                if version.startswith('2.'):
                    self._add_issue(
                        result, "warning", "compatibility",
                        f"Docker Compose ç‰ˆæœ¬ {version} å·²è¿‡æ—¶ï¼Œå»ºè®®å‡çº§åˆ° 3.x"
                    )
            
            # æ£€æŸ¥æœåŠ¡å®šä¹‰
            if 'services' not in config:
                self._add_issue(
                    result, "critical", "missing",
                    "ç¼ºå°‘ services èŠ‚ï¼Œè¿™æ˜¯ Docker Compose çš„æ ¸å¿ƒéƒ¨åˆ†"
                )
            else:
                services = config['services']
                result.metadata["service_count"] = len(services)
                result.metadata["service_names"] = list(services.keys())
                
                # æ£€æŸ¥æ¯ä¸ªæœåŠ¡
                for service_name, service_config in services.items():
                    if not isinstance(service_config, dict):
                        self._add_issue(
                            result, "critical", "syntax",
                            f"æœåŠ¡ {service_name} çš„é…ç½®å¿…é¡»æ˜¯ä¸€ä¸ªå¯¹è±¡"
                        )
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰é•œåƒæˆ–æ„å»ºé…ç½®
                    if 'image' not in service_config and 'build' not in service_config:
                        self._add_issue(
                            result, "critical", "missing",
                            f"æœåŠ¡ {service_name} ç¼ºå°‘ image æˆ– build é…ç½®"
                        )
                    
                    # æ£€æŸ¥ç«¯å£æ˜ å°„æ˜¯å¦åˆç†
                    if 'ports' in service_config:
                        ports = service_config['ports']
                        for port in ports:
                            if isinstance(port, str) and ':' in port:
                                host_port, container_port = port.split(':', 1)
                                try:
                                    host_port_num = int(host_port)
                                    if host_port_num < 1024 and not self.is_termux:
                                        self._add_issue(
                                            result, "warning", "compatibility",
                                            f"æœåŠ¡ {service_name} ä½¿ç”¨äº†ç‰¹æƒç«¯å£ {host_port_num}ï¼Œå¯èƒ½éœ€è¦ root æƒé™"
                                        )
                                except ValueError:
                                    pass
                    
                    # æ£€æŸ¥ç¯å¢ƒå˜é‡å®‰å…¨æ€§
                    if 'environment' in service_config:
                        env_vars = service_config['environment']
                        if isinstance(env_vars, list):
                            for env_var in env_vars:
                                if isinstance(env_var, str) and '=' in env_var:
                                    key, value = env_var.split('=', 1)
                                    if any(sensitive in key.lower() for sensitive in ['password', 'secret', 'key', 'token']):
                                        if not value.startswith('${'):
                                            self._add_issue(
                                                result, "warning", "security",
                                                f"æœåŠ¡ {service_name} ä¸­çš„æ•æ„Ÿç¯å¢ƒå˜é‡ {key} å¯èƒ½ä½¿ç”¨äº†æ˜æ–‡å€¼",
                                                suggestion="ä½¿ç”¨ ${VARIABLE_NAME} æ ¼å¼å¼•ç”¨ç¯å¢ƒå˜é‡"
                                            )
            
            # æ£€æŸ¥ç½‘ç»œé…ç½®
            if 'networks' in config:
                networks = config['networks']
                result.metadata["network_count"] = len(networks)
                result.metadata["network_names"] = list(networks.keys())
            
            # æ£€æŸ¥æ•°æ®å·é…ç½®
            if 'volumes' in config:
                volumes = config['volumes']
                result.metadata["volume_count"] = len(volumes)
                result.metadata["volume_names"] = list(volumes.keys())
            
        except yaml.YAMLError as e:
            result.status = "invalid"
            self._add_issue(
                result, "critical", "syntax",
                f"YAML è¯­æ³•é”™è¯¯: {str(e)}",
                suggestion="æ£€æŸ¥ YAML æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæ³¨æ„ç¼©è¿›å’Œç‰¹æ®Šå­—ç¬¦"
            )
        except Exception as e:
            result.status = "invalid"
            self._add_issue(
                result, "critical", "syntax",
                f"è§£ææ–‡ä»¶å¤±è´¥: {str(e)}"
            )
        
        # æ£€æŸ¥æ•æ„Ÿä¿¡æ¯
        self._check_sensitive_content(result, content)
        
        return result
    
    def _validate_env_file(self, file_path: Path, content: str) -> ConfigValidationResult:
        """éªŒè¯ç¯å¢ƒå˜é‡æ–‡ä»¶"""
        result = ConfigValidationResult(
            file_path=str(file_path),
            file_type="env",
            status="valid"
        )
        
        lines = content.strip().split('\\n')
        result.metadata["line_count"] = len(lines)
        
        env_vars = {}
        duplicates = set()
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
            if not line or line.startswith('#'):
                continue
            
            # æ£€æŸ¥ç¯å¢ƒå˜é‡æ ¼å¼
            if '=' not in line:
                self._add_issue(
                    result, "warning", "syntax",
                    f"æ— æ•ˆçš„ç¯å¢ƒå˜é‡æ ¼å¼: {line}",
                    line_number=line_num,
                    suggestion="ç¯å¢ƒå˜é‡åº”è¯¥ä½¿ç”¨ KEY=VALUE æ ¼å¼"
                )
                continue
            
            key, value = line.split('=', 1)
            key = key.strip()
            value = value.strip()
            
            # æ£€æŸ¥é‡å¤çš„ç¯å¢ƒå˜é‡
            if key in env_vars:
                duplicates.add(key)
                self._add_issue(
                    result, "warning", "syntax",
                    f"é‡å¤çš„ç¯å¢ƒå˜é‡: {key}",
                    line_number=line_num,
                    suggestion="ç§»é™¤é‡å¤çš„å˜é‡å®šä¹‰"
                )
            
            env_vars[key] = value
            
            # æ£€æŸ¥ç¯å¢ƒå˜é‡åç§°è§„èŒƒ
            if not re.match(r'^[A-Z][A-Z0-9_]*$', key):
                self._add_issue(
                    result, "info", "syntax",
                    f"ç¯å¢ƒå˜é‡å {key} ä¸ç¬¦åˆå¸¸è§çº¦å®šï¼ˆå…¨å¤§å†™åŠ ä¸‹åˆ’çº¿ï¼‰",
                    line_number=line_num,
                    suggestion="å»ºè®®ä½¿ç”¨å…¨å¤§å†™å­—æ¯å’Œä¸‹åˆ’çº¿çš„ç¯å¢ƒå˜é‡å"
                )
            
            # æ£€æŸ¥ç©ºå€¼
            if not value:
                self._add_issue(
                    result, "warning", "missing",
                    f"ç¯å¢ƒå˜é‡ {key} çš„å€¼ä¸ºç©º",
                    line_number=line_num
                )
            
            # æ£€æŸ¥æ•æ„Ÿä¿¡æ¯
            if any(sensitive in key.lower() for sensitive in ['password', 'secret', 'key', 'token']):
                if len(value) < 8:
                    self._add_issue(
                        result, "warning", "security",
                        f"æ•æ„Ÿç¯å¢ƒå˜é‡ {key} çš„å€¼å¯èƒ½å¤ªçŸ­ï¼ˆå°‘äº8ä½ï¼‰",
                        line_number=line_num,
                        suggestion="ä½¿ç”¨æ›´é•¿çš„ã€æ›´å¤æ‚çš„å¯†ç æˆ–å¯†é’¥"
                    )
                
                if value in ['password', 'secret', '123456', 'admin', 'root']:
                    self._add_issue(
                        result, "critical", "security",
                        f"æ•æ„Ÿç¯å¢ƒå˜é‡ {key} ä½¿ç”¨äº†å¼±å¯†ç : {value}",
                        line_number=line_num,
                        suggestion="ä½¿ç”¨å¼ºå¯†ç æˆ–éšæœºç”Ÿæˆçš„å¯†é’¥"
                    )
        
        result.metadata["env_var_count"] = len(env_vars)
        result.metadata["duplicate_count"] = len(duplicates)
        
        # æ£€æŸ¥å¸¸è§çš„å¿…è¦ç¯å¢ƒå˜é‡
        if 'development' in str(file_path):
            expected_vars = ['DATABASE_URL', 'REDIS_URL', 'API_HOST', 'API_PORT']
            for var in expected_vars:
                if var not in env_vars:
                    self._add_issue(
                        result, "info", "missing",
                        f"å¼€å‘ç¯å¢ƒä¸­å¯èƒ½ç¼ºå°‘å¸¸ç”¨ç¯å¢ƒå˜é‡: {var}"
                    )
        
        # æ£€æŸ¥æ•æ„Ÿä¿¡æ¯
        self._check_sensitive_content(result, content)
        
        return result
    
    def validate_all_configs(self) -> List[ConfigValidationResult]:
        """éªŒè¯æ‰€æœ‰é…ç½®æ–‡ä»¶"""
        logger.info(f"å¼€å§‹éªŒè¯ {len(self.config_files)} ä¸ªé…ç½®æ–‡ä»¶...")
        
        results = []
        
        for file_name, file_config in self.config_files.items():
            file_path = self.project_path / file_name
            
            # è¯»å–æ–‡ä»¶
            success, content, error = self._read_file_safely(file_path)
            
            if not success:
                # æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥
                result = ConfigValidationResult(
                    file_path=str(file_path),
                    file_type=file_config['type'],
                    status="missing" if "not exist" in error else "invalid"
                )
                
                severity = "critical" if file_config['required'] else "warning"
                self._add_issue(
                    result, severity, "missing",
                    f"{file_config['description']}æ–‡ä»¶é—®é¢˜: {error}",
                    suggestion=f"åˆ›å»º {file_name} æ–‡ä»¶" if "not exist" in error else "æ£€æŸ¥æ–‡ä»¶æƒé™å’Œæ ¼å¼"
                )
                
                results.append(result)
                continue
            
            # éªŒè¯æ–‡ä»¶å†…å®¹
            try:
                validator = file_config['validator']
                result = validator(file_path, content)
                results.append(result)
                
                # ç»Ÿè®¡é—®é¢˜ä¸¥é‡ç¨‹åº¦
                critical_issues = len([i for i in result.issues if i.severity == "critical"])
                warning_issues = len([i for i in result.issues if i.severity == "warning"])
                info_issues = len([i for i in result.issues if i.severity == "info"])
                
                status_icon = "âœ…" if result.status == "valid" else "âŒ"
                logger.info(
                    f"{status_icon} {file_name}: {result.status.upper()} - "
                    f"{critical_issues} ä¸¥é‡, {warning_issues} è­¦å‘Š, {info_issues} æç¤º"
                )
                
            except Exception as e:
                result = ConfigValidationResult(
                    file_path=str(file_path),
                    file_type=file_config['type'],
                    status="invalid"
                )
                
                self._add_issue(
                    result, "critical", "syntax",
                    f"éªŒè¯å™¨å¼‚å¸¸: {str(e)}"
                )
                
                results.append(result)
                logger.error(f"âŒ {file_name}: éªŒè¯å™¨å¼‚å¸¸ - {str(e)}")
        
        self.results = results
        return results
    
    def validate_service_configs(self) -> List[ConfigValidationResult]:
        """éªŒè¯æœåŠ¡é…ç½®æ–‡ä»¶"""
        service_results = []
        
        # æŸ¥æ‰¾æ‰€æœ‰æœåŠ¡ç›®å½•
        services_dir = self.project_path / "services"
        if not services_dir.exists():
            return service_results
        
        for service_path in services_dir.iterdir():
            if not service_path.is_dir():
                continue
            
            service_name = service_path.name
            
            # æ£€æŸ¥ Dockerfile
            dockerfile_path = service_path / "Dockerfile"
            if dockerfile_path.exists():
                success, content, error = self._read_file_safely(dockerfile_path)
                if success:
                    result = self._validate_dockerfile(dockerfile_path, content)
                    service_results.append(result)
            
            # æ£€æŸ¥ requirements.txt
            requirements_path = service_path / "requirements.txt"
            if requirements_path.exists():
                success, content, error = self._read_file_safely(requirements_path)
                if success:
                    result = self._validate_requirements_txt(requirements_path, content)
                    service_results.append(result)
        
        return service_results
    
    def _validate_dockerfile(self, file_path: Path, content: str) -> ConfigValidationResult:
        """éªŒè¯ Dockerfile"""
        result = ConfigValidationResult(
            file_path=str(file_path),
            file_type="dockerfile",
            status="valid"
        )
        
        lines = content.strip().split('\\n')
        
        has_from = False
        has_workdir = False
        runs_as_root = True
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            
            if not line or line.startswith('#'):
                continue
            
            # æ£€æŸ¥ FROM æŒ‡ä»¤
            if line.upper().startswith('FROM'):
                has_from = True
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† latest æ ‡ç­¾
                if ':latest' in line or (':' not in line and 'FROM' in line.upper()):
                    self._add_issue(
                        result, "warning", "compatibility",
                        "ä½¿ç”¨äº† latest æ ‡ç­¾æˆ–æœªæŒ‡å®šæ ‡ç­¾ï¼Œå¯èƒ½å¯¼è‡´æ„å»ºä¸ä¸€è‡´",
                        line_number=line_num,
                        suggestion="ä½¿ç”¨å…·ä½“çš„ç‰ˆæœ¬æ ‡ç­¾ï¼Œå¦‚ python:3.11-slim"
                    )
            
            # æ£€æŸ¥ WORKDIR æŒ‡ä»¤
            elif line.upper().startswith('WORKDIR'):
                has_workdir = True
            
            # æ£€æŸ¥ USER æŒ‡ä»¤
            elif line.upper().startswith('USER'):
                user = line.split()[1] if len(line.split()) > 1 else ''
                if user != 'root':
                    runs_as_root = False
            
            # æ£€æŸ¥å±é™©çš„ RUN æŒ‡ä»¤
            elif line.upper().startswith('RUN'):
                if 'rm -rf /' in line or 'rm -rf /*' in line:
                    self._add_issue(
                        result, "critical", "security",
                        "å±é™©çš„ rm å‘½ä»¤ï¼Œå¯èƒ½åˆ é™¤é‡è¦æ–‡ä»¶",
                        line_number=line_num
                    )
                
                if 'curl' in line and 'bash' in line:
                    self._add_issue(
                        result, "warning", "security",
                        "ç›´æ¥ä»ç½‘ç»œæ‰§è¡Œ shell è„šæœ¬å¯èƒ½å­˜åœ¨å®‰å…¨é£é™©",
                        line_number=line_num,
                        suggestion="å…ˆä¸‹è½½è„šæœ¬å¹¶éªŒè¯å…¶å®‰å…¨æ€§"
                    )
        
        # æ£€æŸ¥å¿…è¦çš„æŒ‡ä»¤
        if not has_from:
            self._add_issue(
                result, "critical", "missing",
                "Dockerfile ä¸­ç¼ºå°‘ FROM æŒ‡ä»¤"
            )
        
        if not has_workdir:
            self._add_issue(
                result, "warning", "missing",
                "å»ºè®®ä½¿ç”¨ WORKDIR æŒ‡ä»¤è®¾ç½®å·¥ä½œç›®å½•"
            )
        
        if runs_as_root:
            self._add_issue(
                result, "warning", "security",
                "å®¹å™¨ä»¥ root ç”¨æˆ·è¿è¡Œï¼Œå­˜åœ¨å®‰å…¨é£é™©",
                suggestion="ä½¿ç”¨ USER æŒ‡ä»¤åˆ‡æ¢åˆ°éç‰¹æƒç”¨æˆ·"
            )
        
        return result
    
    def _validate_requirements_txt(self, file_path: Path, content: str) -> ConfigValidationResult:
        """éªŒè¯ requirements.txt æ–‡ä»¶"""
        result = ConfigValidationResult(
            file_path=str(file_path),
            file_type="requirements",
            status="valid"
        )
        
        lines = content.strip().split('\\n')
        dependencies = []
        
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            
            if not line or line.startswith('#') or line.startswith('-'):
                continue
            
            dependencies.append(line)
            
            # æ£€æŸ¥ç‰ˆæœ¬å›ºå®š
            if '==' not in line and '>=' not in line and '<=' not in line:
                self._add_issue(
                    result, "warning", "compatibility",
                    f"ä¾èµ– {line} æœªæŒ‡å®šç‰ˆæœ¬ï¼Œå¯èƒ½å¯¼è‡´æ„å»ºä¸ä¸€è‡´",
                    line_number=line_num,
                    suggestion="ä½¿ç”¨ == æˆ– >= æŒ‡å®šç‰ˆæœ¬èŒƒå›´"
                )
            
            # æ£€æŸ¥å¸¸è§çš„ä¸å®‰å…¨ä¾èµ–
            package_name = line.split('==')[0].split('>=')[0].split('<=')[0].strip()
            if package_name.lower() in ['pillow', 'requests', 'urllib3']:
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„ç‰ˆæœ¬æ£€æŸ¥
                pass
        
        result.metadata["dependency_count"] = len(dependencies)
        
        return result
    
    def generate_validation_report(self, results: List[ConfigValidationResult]) -> Dict:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        # ç»Ÿè®¡é—®é¢˜
        total_files = len(results)
        valid_files = len([r for r in results if r.status == "valid"])
        invalid_files = len([r for r in results if r.status == "invalid"])
        missing_files = len([r for r in results if r.status == "missing"])
        
        all_issues = []
        for result in results:
            all_issues.extend(result.issues)
        
        critical_issues = [i for i in all_issues if i.severity == "critical"]
        warning_issues = [i for i in all_issues if i.severity == "warning"]
        info_issues = [i for i in all_issues if i.severity == "info"]
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡é—®é¢˜
        category_stats = {}
        for issue in all_issues:
            category = issue.category
            if category not in category_stats:
                category_stats[category] = {"critical": 0, "warning": 0, "info": 0}
            category_stats[category][issue.severity] += 1
        
        # æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡
        file_type_stats = {}
        for result in results:
            file_type = result.file_type
            if file_type not in file_type_stats:
                file_type_stats[file_type] = {"total": 0, "valid": 0, "invalid": 0, "missing": 0}
            file_type_stats[file_type]["total"] += 1
            file_type_stats[file_type][result.status] += 1
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "environment": {
                "is_termux": self.is_termux,
                "project_path": str(self.project_path.absolute())
            },
            "summary": {
                "total_files": total_files,
                "valid_files": valid_files,
                "invalid_files": invalid_files,
                "missing_files": missing_files,
                "total_issues": len(all_issues),
                "critical_issues": len(critical_issues),
                "warning_issues": len(warning_issues),
                "info_issues": len(info_issues),
                "validation_success_rate": round((valid_files / total_files * 100) if total_files > 0 else 0, 1)
            },
            "category_statistics": category_stats,
            "file_type_statistics": file_type_stats,
            "detailed_results": [result.model_dump() for result in results],
            "recommendations": self._generate_validation_recommendations(results)
        }
        
        return report
    
    def _generate_validation_recommendations(self, results: List[ConfigValidationResult]) -> List[str]:
        """åŸºäºéªŒè¯ç»“æœç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        all_issues = []
        for result in results:
            all_issues.extend(result.issues)
        
        critical_issues = [i for i in all_issues if i.severity == "critical"]
        security_issues = [i for i in all_issues if i.category == "security"]
        missing_files = [r for r in results if r.status == "missing"]
        
        if not all_issues:
            recommendations.append("ğŸ‰ æ‰€æœ‰é…ç½®æ–‡ä»¶éƒ½é€šè¿‡äº†éªŒè¯ï¼")
            return recommendations
        
        # ä¼˜å…ˆçº§å»ºè®®
        if critical_issues:
            recommendations.append(
                f"âš ï¸ ä¼˜å…ˆä¿®å¤ {len(critical_issues)} ä¸ªä¸¥é‡é—®é¢˜ï¼Œè¿™äº›é—®é¢˜å¯èƒ½å¯¼è‡´ç³»ç»Ÿæ— æ³•æ­£å¸¸è¿è¡Œ"
            )
        
        if security_issues:
            recommendations.append(
                f"ğŸ”’ å…³æ³¨ {len(security_issues)} ä¸ªå®‰å…¨é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–åŠ å¯†å­˜å‚¨æ•æ„Ÿä¿¡æ¯"
            )
        
        if missing_files:
            missing_names = [Path(r.file_path).name for r in missing_files]
            recommendations.append(
                f"ğŸ“ åˆ›å»ºç¼ºå¤±çš„é…ç½®æ–‡ä»¶: {', '.join(missing_names)}"
            )
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡å»ºè®®
        syntax_issues = [i for i in all_issues if i.category == "syntax"]
        if syntax_issues:
            recommendations.append(
                f"ğŸ”§ ä¿®å¤ {len(syntax_issues)} ä¸ªè¯­æ³•é”™è¯¯ï¼Œæ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œç¼©è¿›"
            )
        
        compatibility_issues = [i for i in all_issues if i.category == "compatibility"]
        if compatibility_issues:
            recommendations.append(
                f"ğŸ”„ è§£å†³ {len(compatibility_issues)} ä¸ªå…¼å®¹æ€§é—®é¢˜ï¼Œå‡çº§è¿‡æ—¶çš„ç‰ˆæœ¬å’Œé…ç½®"
            )
        
        # Termux ç‰¹å®šå»ºè®®
        if self.is_termux:
            recommendations.append(
                "ğŸ“± Termux ç¯å¢ƒæç¤º: æŸäº›é…ç½®å¯èƒ½éœ€è¦é’ˆå¯¹ Android ç¯å¢ƒè¿›è¡Œè°ƒæ•´ï¼Œ"
                "å¦‚ç«¯å£èŒƒå›´ã€æ–‡ä»¶æƒé™ç­‰"
            )
        
        return recommendations
    
    def save_report(self, report: Dict, output_path: str = "config-validation-report.json"):
        """ä¿å­˜éªŒè¯æŠ¥å‘Š"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š é…ç½®éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {Path(output_path).absolute()}")
        
        # åŒæ—¶ç”Ÿæˆç®€åŒ–çš„æ–‡æœ¬æŠ¥å‘Š
        text_report = self._generate_text_report(report)
        text_path = Path(output_path).with_suffix('.txt')
        with open(text_path, 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        logger.info(f"ğŸ“„ æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {text_path.absolute()}")
    
    def _generate_text_report(self, report: Dict) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æ–‡æœ¬æŠ¥å‘Š"""
        lines = [
            "=" * 60,
            "é…ç½®æ–‡ä»¶éªŒè¯æŠ¥å‘Š",
            "=" * 60,
            f"ç”Ÿæˆæ—¶é—´: {report['timestamp']}",
            f"ç¯å¢ƒ: {'Termux Android' if report['environment']['is_termux'] else 'æ ‡å‡† Linux'}",
            f"é¡¹ç›®è·¯å¾„: {report['environment']['project_path']}",
            "",
            "æ€»ä½“çŠ¶å†µ:",
            f"  æ€»æ–‡ä»¶æ•°: {report['summary']['total_files']}",
            f"  æœ‰æ•ˆæ–‡ä»¶: {report['summary']['valid_files']}",
            f"  æ— æ•ˆæ–‡ä»¶: {report['summary']['invalid_files']}",
            f"  ç¼ºå¤±æ–‡ä»¶: {report['summary']['missing_files']}",
            f"  éªŒè¯æˆåŠŸç‡: {report['summary']['validation_success_rate']}%",
            f"  æ€»é—®é¢˜æ•°: {report['summary']['total_issues']}",
            f"    - ä¸¥é‡: {report['summary']['critical_issues']}",
            f"    - è­¦å‘Š: {report['summary']['warning_issues']}",
            f"    - æç¤º: {report['summary']['info_issues']}",
            "",
            "æŒ‰ç±»åˆ«ç»Ÿè®¡:"
        ]
        
        for category, stats in report['category_statistics'].items():
            total = stats['critical'] + stats['warning'] + stats['info']
            lines.append(f"  {category}: {total} (ä¸¥é‡: {stats['critical']}, è­¦å‘Š: {stats['warning']}, æç¤º: {stats['info']})")
        
        lines.extend([
            "",
            "è¯¦ç»†ç»“æœ:"
        ])
        
        for result in report['detailed_results']:
            status_icon = {
                "valid": "âœ…",
                "invalid": "âŒ",
                "missing": "â“"
            }.get(result['status'], "âšª")
            
            issue_count = len(result['issues'])
            lines.append(
                f"  {status_icon} {Path(result['file_path']).name} ({result['file_type']}) - "
                f"{result['status'].upper()} - {issue_count} é—®é¢˜"
            )
            
            # æ˜¾ç¤ºå‰3ä¸ªé‡è¦é—®é¢˜
            important_issues = [i for i in result['issues'] if i['severity'] in ['critical', 'warning']][:3]
            for issue in important_issues:
                lines.append(f"     {issue['severity'].upper()}: {issue['message']}")
        
        lines.extend([
            "",
            "å»ºè®®:"
        ])
        
        for i, recommendation in enumerate(report['recommendations'], 1):
            lines.append(f"  {i}. {recommendation}")
        
        lines.append("=" * 60)
        
        return "\\n".join(lines)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="é…ç½®æ–‡ä»¶éªŒè¯å·¥å…·")
    parser.add_argument("--project-path", "-p", default=".", help="é¡¹ç›®è·¯å¾„")
    parser.add_argument("--include-services", "-s", action="store_true", help="åŒ…å«æœåŠ¡é…ç½®éªŒè¯")
    parser.add_argument("--output", "-o", default="config-validation-report", help="æŠ¥å‘Šæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # åˆ›å»ºé…ç½®éªŒè¯å™¨
    validator = ConfigurationValidator(args.project_path)
    
    # æ‰§è¡Œé…ç½®éªŒè¯
    results = validator.validate_all_configs()
    
    # æ·»åŠ æœåŠ¡é…ç½®éªŒè¯
    if args.include_services:
        service_results = validator.validate_service_configs()
        results.extend(service_results)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = validator.generate_validation_report(results)
    
    # ä¿å­˜æŠ¥å‘Š
    validator.save_report(report, f"{args.output}.json")
    
    # è¾“å‡ºæ€»ç»“åˆ°æ§åˆ¶å°
    summary = report['summary']
    print(f"\\nğŸ“Š é…ç½®éªŒè¯å®Œæˆ:")
    print(f"   æœ‰æ•ˆé…ç½®: {summary['valid_files']}/{summary['total_files']} ({summary['validation_success_rate']}%)")
    print(f"   æ€»é—®é¢˜æ•°: {summary['total_issues']} (ä¸¥é‡: {summary['critical_issues']}, è­¦å‘Š: {summary['warning_issues']})")
    
    if summary['critical_issues'] > 0:
        print(f"   âš ï¸  {summary['critical_issues']} ä¸ªä¸¥é‡é—®é¢˜éœ€è¦ä¿®å¤")
        return 1
    elif summary['warning_issues'] > 0:
        print(f"   âš ï¸  {summary['warning_issues']} ä¸ªè­¦å‘Šå»ºè®®ä¿®å¤")
        return 0
    else:
        print("   âœ… æ‰€æœ‰é…ç½®æ–‡ä»¶éƒ½é€šè¿‡äº†éªŒè¯")
        return 0


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(130)
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)