#!/usr/bin/env python3
"""
CI/CD é…ç½®éªŒè¯è„šæœ¬
éªŒè¯ GitHub Actions å·¥ä½œæµç¨‹é…ç½®çš„æ­£ç¡®æ€§
"""

import os
import sys
import json
import yaml
import subprocess
from pathlib import Path
from typing import List, Dict, Any, Optional

class CICDValidator:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.workflows_dir = self.project_root / ".github" / "workflows"
        self.errors = []
        self.warnings = []
        
    def validate_all(self) -> bool:
        """è¿è¡Œæ‰€æœ‰éªŒè¯æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹ CI/CD é…ç½®éªŒè¯...")
        
        # éªŒè¯é¡¹ç›®ç»“æ„
        self.validate_project_structure()
        
        # éªŒè¯å·¥ä½œæµç¨‹æ–‡ä»¶
        self.validate_workflow_files()
        
        # éªŒè¯å¾®æœåŠ¡ç»“æ„
        self.validate_microservices()
        
        # éªŒè¯ä¾èµ–é…ç½®
        self.validate_dependencies()
        
        # éªŒè¯ Docker é…ç½®
        self.validate_docker_configs()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        return len(self.errors) == 0
    
    def validate_project_structure(self):
        """éªŒè¯é¡¹ç›®ç»“æ„"""
        print("ğŸ“ éªŒè¯é¡¹ç›®ç»“æ„...")
        
        required_paths = [
            "src/services",
            "src/frontend", 
            "src/shared",
            "src/config",
            "infra/k8s",
            "infra/docker",
            "scripts",
            "tests",
            ".github/workflows"
        ]
        
        for path in required_paths:
            full_path = self.project_root / path
            if not full_path.exists():
                self.warnings.append(f"æ¨èè·¯å¾„ä¸å­˜åœ¨: {path}")
        
        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files = [
            "pyproject.toml",
            "docker-compose.unified.yml",
            "alembic.ini"
        ]
        
        for file in key_files:
            file_path = self.project_root / file
            if not file_path.exists():
                self.errors.append(f"å…³é”®æ–‡ä»¶ç¼ºå¤±: {file}")
    
    def validate_workflow_files(self):
        """éªŒè¯å·¥ä½œæµç¨‹æ–‡ä»¶"""
        print("âš™ï¸ éªŒè¯å·¥ä½œæµç¨‹æ–‡ä»¶...")
        
        if not self.workflows_dir.exists():
            self.errors.append("GitHub Actions å·¥ä½œæµç¨‹ç›®å½•ä¸å­˜åœ¨")
            return
        
        workflow_files = list(self.workflows_dir.glob("*.yml"))
        if not workflow_files:
            self.errors.append("æ²¡æœ‰æ‰¾åˆ°å·¥ä½œæµç¨‹æ–‡ä»¶")
            return
        
        for workflow_file in workflow_files:
            self.validate_single_workflow(workflow_file)
    
    def validate_single_workflow(self, workflow_file: Path):
        """éªŒè¯å•ä¸ªå·¥ä½œæµç¨‹æ–‡ä»¶"""
        try:
            with open(workflow_file, 'r', encoding='utf-8') as f:
                workflow = yaml.safe_load(f)
            
            # æ£€æŸ¥å¿…éœ€çš„å­—æ®µ
            if 'name' not in workflow:
                self.warnings.append(f"{workflow_file.name}: ç¼ºå°‘å·¥ä½œæµç¨‹åç§°")
            
            if 'on' not in workflow:
                self.errors.append(f"{workflow_file.name}: ç¼ºå°‘è§¦å‘æ¡ä»¶")
            
            if 'jobs' not in workflow:
                self.errors.append(f"{workflow_file.name}: ç¼ºå°‘ä½œä¸šå®šä¹‰")
                return
            
            # æ£€æŸ¥è·¯å¾„å¼•ç”¨
            self.validate_workflow_paths(workflow_file.name, workflow)
            
        except yaml.YAMLError as e:
            self.errors.append(f"{workflow_file.name}: YAML è¯­æ³•é”™è¯¯ - {e}")
        except Exception as e:
            self.errors.append(f"{workflow_file.name}: éªŒè¯å¤±è´¥ - {e}")
    
    def validate_workflow_paths(self, filename: str, workflow: Dict[Any, Any]):
        """éªŒè¯å·¥ä½œæµç¨‹ä¸­çš„è·¯å¾„å¼•ç”¨"""
        workflow_str = yaml.dump(workflow)
        
        # æ£€æŸ¥è¿‡æ—¶çš„è·¯å¾„å¼•ç”¨
        outdated_paths = [
            "frontend/",
            "services/",
            "requirements.txt"
        ]
        
        for path in outdated_paths:
            if path in workflow_str:
                self.warnings.append(f"{filename}: åŒ…å«è¿‡æ—¶çš„è·¯å¾„å¼•ç”¨ '{path}'")
        
        # æ£€æŸ¥æ¨èçš„è·¯å¾„å¼•ç”¨
        if filename == "ci-cd-main.yml":
            recommended_paths = [
                "src/services/",
                "src/frontend/",
                "pyproject.toml"
            ]
            
            for path in recommended_paths:
                if path not in workflow_str:
                    self.warnings.append(f"{filename}: ç¼ºå°‘æ¨èçš„è·¯å¾„å¼•ç”¨ '{path}'")
    
    def validate_microservices(self):
        """éªŒè¯å¾®æœåŠ¡ç»“æ„"""
        print("ğŸ”§ éªŒè¯å¾®æœåŠ¡ç»“æ„...")
        
        services_dir = self.project_root / "src" / "services"
        if not services_dir.exists():
            self.errors.append("å¾®æœåŠ¡ç›®å½• src/services ä¸å­˜åœ¨")
            return
        
        services = [d for d in services_dir.iterdir() if d.is_dir() and not d.name.startswith('.')]
        
        if not services:
            self.warnings.append("æ²¡æœ‰æ‰¾åˆ°å¾®æœåŠ¡")
            return
        
        print(f"å‘ç° {len(services)} ä¸ªå¾®æœåŠ¡")
        
        for service in services:
            self.validate_single_service(service)
    
    def validate_single_service(self, service_path: Path):
        """éªŒè¯å•ä¸ªå¾®æœåŠ¡"""
        service_name = service_path.name
        
        # æ£€æŸ¥ Dockerfile
        dockerfile = service_path / "Dockerfile"
        if not dockerfile.exists():
            self.warnings.append(f"å¾®æœåŠ¡ {service_name} ç¼ºå°‘ Dockerfile")
        
        # æ£€æŸ¥åº”ç”¨ç›®å½•
        app_dir = service_path / "app"
        if not app_dir.exists():
            self.warnings.append(f"å¾®æœåŠ¡ {service_name} ç¼ºå°‘ app ç›®å½•")
        else:
            # æ£€æŸ¥ä¸»å…¥å£æ–‡ä»¶
            main_file = app_dir / "main.py"
            if not main_file.exists():
                self.warnings.append(f"å¾®æœåŠ¡ {service_name} ç¼ºå°‘ main.py")
        
        # æ£€æŸ¥æµ‹è¯•ç›®å½•
        tests_dir = service_path / "tests"
        if not tests_dir.exists():
            self.warnings.append(f"å¾®æœåŠ¡ {service_name} ç¼ºå°‘æµ‹è¯•ç›®å½•")
        
        # æ£€æŸ¥ä¾èµ–æ–‡ä»¶
        req_files = [
            "requirements.txt",
            "requirements-dev.txt"
        ]
        
        for req_file in req_files:
            if not (service_path / req_file).exists():
                self.warnings.append(f"å¾®æœåŠ¡ {service_name} ç¼ºå°‘ {req_file}")
    
    def validate_dependencies(self):
        """éªŒè¯ä¾èµ–é…ç½®"""
        print("ğŸ“¦ éªŒè¯ä¾èµ–é…ç½®...")
        
        # æ£€æŸ¥ pyproject.toml
        pyproject_file = self.project_root / "pyproject.toml"
        if pyproject_file.exists():
            try:
                import tomllib
                with open(pyproject_file, 'rb') as f:
                    pyproject = tomllib.load(f)
                
                # æ£€æŸ¥å¿…éœ€çš„éƒ¨åˆ†
                if 'project' not in pyproject:
                    self.errors.append("pyproject.toml ç¼ºå°‘ [project] éƒ¨åˆ†")
                
                if 'project' in pyproject and 'dependencies' not in pyproject['project']:
                    self.warnings.append("pyproject.toml ç¼ºå°‘ä¾èµ–å®šä¹‰")
                
                # æ£€æŸ¥å¼€å‘ä¾èµ–
                if 'project' in pyproject and 'optional-dependencies' not in pyproject['project']:
                    self.warnings.append("pyproject.toml ç¼ºå°‘å¯é€‰ä¾èµ–å®šä¹‰")
                
            except Exception as e:
                self.errors.append(f"pyproject.toml è§£æå¤±è´¥: {e}")
        
        # æ£€æŸ¥å‰ç«¯ä¾èµ–
        frontend_dir = self.project_root / "src" / "frontend"
        if frontend_dir.exists():
            package_json = frontend_dir / "package.json"
            if not package_json.exists():
                self.errors.append("å‰ç«¯ç¼ºå°‘ package.json")
            else:
                try:
                    with open(package_json, 'r', encoding='utf-8') as f:
                        package_data = json.load(f)
                    
                    if 'scripts' not in package_data:
                        self.warnings.append("package.json ç¼ºå°‘ scripts å®šä¹‰")
                    
                    required_scripts = ['build', 'test', 'lint']
                    missing_scripts = [s for s in required_scripts if s not in package_data.get('scripts', {})]
                    if missing_scripts:
                        self.warnings.append(f"package.json ç¼ºå°‘å¿…éœ€çš„è„šæœ¬: {missing_scripts}")
                
                except Exception as e:
                    self.errors.append(f"package.json è§£æå¤±è´¥: {e}")
    
    def validate_docker_configs(self):
        """éªŒè¯ Docker é…ç½®"""
        print("ğŸ³ éªŒè¯ Docker é…ç½®...")
        
        # æ£€æŸ¥ docker-compose æ–‡ä»¶
        compose_files = [
            "docker-compose.yml",
            "docker-compose.unified.yml"
        ]
        
        found_compose = False
        for compose_file in compose_files:
            compose_path = self.project_root / compose_file
            if compose_path.exists():
                found_compose = True
                try:
                    with open(compose_path, 'r', encoding='utf-8') as f:
                        compose_data = yaml.safe_load(f)
                    
                    if 'services' not in compose_data:
                        self.errors.append(f"{compose_file}: ç¼ºå°‘æœåŠ¡å®šä¹‰")
                    
                    # æ£€æŸ¥å¸¸è§æœåŠ¡
                    if 'services' in compose_data:
                        services = compose_data['services']
                        recommended_services = ['postgres', 'redis']
                        for service in recommended_services:
                            if service not in services:
                                self.warnings.append(f"{compose_file}: ç¼ºå°‘æ¨èæœåŠ¡ {service}")
                
                except Exception as e:
                    self.errors.append(f"{compose_file}: è§£æå¤±è´¥ - {e}")
        
        if not found_compose:
            self.warnings.append("æ²¡æœ‰æ‰¾åˆ° docker-compose é…ç½®æ–‡ä»¶")
    
    def check_git_hooks(self):
        """æ£€æŸ¥ Git hooks é…ç½®"""
        print("ğŸª æ£€æŸ¥ Git hooks é…ç½®...")
        
        pre_commit_config = self.project_root / ".pre-commit-config.yaml"
        if pre_commit_config.exists():
            try:
                with open(pre_commit_config, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                
                if 'repos' in config:
                    print(f"âœ… æ‰¾åˆ° {len(config['repos'])} ä¸ª pre-commit hooks")
                else:
                    self.warnings.append("pre-commit é…ç½®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
            
            except Exception as e:
                self.errors.append(f"pre-commit é…ç½®è§£æå¤±è´¥: {e}")
        else:
            self.warnings.append("ç¼ºå°‘ pre-commit é…ç½®æ–‡ä»¶")
    
    def generate_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š CI/CD é…ç½®éªŒè¯æŠ¥å‘Š")
        print("="*60)
        
        if self.errors:
            print(f"\nâŒ å‘ç° {len(self.errors)} ä¸ªé”™è¯¯:")
            for i, error in enumerate(self.errors, 1):
                print(f"  {i}. {error}")
        
        if self.warnings:
            print(f"\nâš ï¸ å‘ç° {len(self.warnings)} ä¸ªè­¦å‘Š:")
            for i, warning in enumerate(self.warnings, 1):
                print(f"  {i}. {warning}")
        
        if not self.errors and not self.warnings:
            print("\nâœ… æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡äº†ï¼")
        elif not self.errors:
            print("\nâœ… é…ç½®åŸºæœ¬æ­£ç¡®ï¼Œä½†æœ‰ä¸€äº›ä¼˜åŒ–å»ºè®®")
        else:
            print("\nâŒ é…ç½®å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä¿®å¤")
        
        print("\n" + "="*60)
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        self.generate_recommendations()
    
    def generate_recommendations(self):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        print("ğŸ’¡ æ”¹è¿›å»ºè®®:")
        
        recommendations = [
            "1. ç¡®ä¿æ‰€æœ‰å¾®æœåŠ¡éƒ½æœ‰å®Œæ•´çš„æµ‹è¯•è¦†ç›–",
            "2. å®šæœŸæ›´æ–°ä¾èµ–ä»¥ä¿®å¤å®‰å…¨æ¼æ´",
            "3. ä½¿ç”¨ pre-commit hooks ç¡®ä¿ä»£ç è´¨é‡",
            "4. ç›‘æ§ CI/CD æµç¨‹çš„æ€§èƒ½å’Œå¯é æ€§",
            "5. å®šæœŸå®¡æŸ¥å’Œä¼˜åŒ– Docker é•œåƒå¤§å°",
            "6. å®æ–½è“ç»¿éƒ¨ç½²æˆ–é‡‘ä¸é›€éƒ¨ç½²ç­–ç•¥",
            "7. è®¾ç½®æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œç›‘æ§",
            "8. é…ç½®è‡ªåŠ¨åŒ–çš„å®‰å…¨æ‰«æ"
        ]
        
        for rec in recommendations:
            print(f"   {rec}")
    
    def validate_github_secrets(self):
        """éªŒè¯ GitHub Secrets é…ç½®"""
        print("ğŸ” éªŒè¯ GitHub Secrets é…ç½®...")
        
        required_secrets = [
            "SNYK_TOKEN",
            "SEMGREP_APP_TOKEN", 
            "KUBE_CONFIG"
        ]
        
        print("è¯·ç¡®ä¿åœ¨ GitHub ä»“åº“è®¾ç½®ä¸­é…ç½®äº†ä»¥ä¸‹ Secrets:")
        for secret in required_secrets:
            print(f"   - {secret}")

def main():
    """ä¸»å‡½æ•°"""
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    validator = CICDValidator(project_root)
    
    # è¿è¡ŒéªŒè¯
    success = validator.validate_all()
    
    # é¢å¤–æ£€æŸ¥
    validator.check_git_hooks()
    validator.validate_github_secrets()
    
    # è¿”å›é€‚å½“çš„é€€å‡ºä»£ç 
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()