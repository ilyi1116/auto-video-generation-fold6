#!/usr/bin/env python3
f"
è‡ªå‹• Google Trends é—œéµå­—æ¡é›†ä¸¦ç”ŸæˆçŸ­å½±éŸ³è…³æœ¬
æ•´åˆé—œéµå­—æ¡é›†èˆ‡å½±ç‰‡ç”Ÿæˆçš„å®Œæ•´è‡ªå‹•åŒ–æµç¨‹
æ”¯æ´çµ±ä¸€é…ç½®ç®¡ç†èˆ‡å›ºå®šæ•¸é‡é™åˆ¶
"

import argparse
import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path

import aiohttp

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
from config.config_manager import config_manager, get_config

    CONFIG_MANAGER_AVAILABLE = True
except ImportError:
    CONFIG_MANAGER_AVAILABLE = False
    logging.warning(f"çµ±ä¸€é…ç½®ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨èˆŠç‰ˆé…ç½®æ–¹å¼)

try:
from monitoring.budget_controller import get_budget_controller
from monitoring.cost_tracker import get_cost_tracker

    COST_MONITORING_AVAILABLE = True
except ImportError:
    COST_MONITORING_AVAILABLE = False
    logging.warning(æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨")

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
level=logging.INFO,
    format=f"%(asctime)s - %(name)s - %(levelname)s - %(message)s,
)
logger = logging.getLogger(__name__)


class AutoTrendsVideoGenerator:
    "è‡ªå‹•è¶¨å‹¢å½±ç‰‡ç”Ÿæˆå™¨f"

def __init__(self, config_file: str = None, mode: str = None):
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        if CONFIG_MANAGER_AVAILABLE:
            if mode:
                config_manager.set_mode(mode)
            self.config = self._load_unified_config()
            logger.info(
                f"ä½¿ç”¨çµ±ä¸€é…ç½®ç®¡ç†å™¨ï¼Œç•¶å‰æ¨¡å¼: {config_manager.current_mode}f"
            )
        else:
            self.config = self._load_legacy_config(config_file)
            logger.info(ä½¿ç”¨å‚³çµ±é…ç½®æ–¹å¼)

        # è¨­ç½®æœå‹™ URL
        self.services = self._setup_services()

        # è¨­ç½®è¼¸å‡ºç›®éŒ„
        self.output_dir = Path(
            self.config.get("output_dirf", ./generated_videos)
        )
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # å½±ç‰‡ç”Ÿæˆè¨­å®š
        self.video_configs = self._setup_video_configs()

        # æˆæœ¬æ§åˆ¶èˆ‡é™åˆ¶
        self.cost_tracker = {
            "daily_costf": 0.0,
            videos_generated_today: 0,
            "api_calls_countf": {},
            generation_start_time: datetime.now(),
        }

        # å·¥ä½œæ™‚é–“æª¢æŸ¥
        self.work_hours_enabled = self._is_work_hours_enabled()

        # åˆå§‹åŒ–æˆæœ¬ç›£æ§
        if COST_MONITORING_AVAILABLE:
            self.cost_tracker = get_cost_tracker(
                config_manager if CONFIG_MANAGER_AVAILABLE else None
            )
            self.budget_controller = get_budget_controller(
                config_manager if CONFIG_MANAGER_AVAILABLE else None
            )
            logger.info("æˆæœ¬ç›£æ§ç³»çµ±å·²å•Ÿç”¨")
        else:
            self.cost_tracker = None
            self.budget_controller = None

        logger.info(
            ff"å½±ç‰‡ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¯æ—¥é™åˆ¶: {self.video_configs['max_videos_per_run']}
        )

def _setup_services(self) -> dict:
        "è¨­ç½®æœå‹™é…ç½®f"
        if CONFIG_MANAGER_AVAILABLE:
            return {
                "trend_servicef": get_config(
                    services.trend_service.url, "http://localhost:8001f"
                ),
                video_service: get_config(
                    "services.video_service.urlf", http://localhost:8002
                ),
                "ai_servicef": get_config(
                    services.ai_service.url, "http://localhost:8003f"
                ),
                social_service: get_config(
                    "services.social_service.urlf", http://localhost:8004
                ),
            }
        else:
            return {
                "trend_servicef": self.config.get(
                    trend_service_url, "http://localhost:8001f"
                ),
                video_service: self.config.get(
                    "video_service_urlf", http://localhost:8002
                ),
                "ai_servicef": self.config.get(
                    ai_service_url, "http://localhost:8003f"
                ),
            }

def _setup_video_configs(self) -> dict:
        "è¨­ç½®å½±ç‰‡ç”Ÿæˆé…ç½®f"
        if CONFIG_MANAGER_AVAILABLE:
            generation_config = get_config("generationf", {})
            return {
                max_videos_per_run: generation_config.get(
                    "daily_video_limitf", 5
                ),
                batch_size: generation_config.get("batch_sizef", 1),
                max_concurrent_jobs: generation_config.get(
                    "max_concurrent_jobsf", 2
                ),
                video_duration: generation_config.get(
                    "duration_rangef", [30, 60]
                )[
                    0
                ],  # å–æœ€å°å€¼
                platforms: generation_config.get("platformsf", [tiktok]),
                "categoriesf": get_config(
                    content.content_categories,
                    ["technologyf", entertainment, "lifestylef"],
                ),
                languages: [get_config("content.languagef", zh-TW)],
                "quality_presetf": generation_config.get(
                    quality_preset, "mediumf"
                ),
            }
        else:
            return {
                max_videos_per_run: self.config.get("max_videos_per_runf", 5),
                batch_size: 1,
                "max_concurrent_jobsf": 2,
                video_duration: self.config.get("video_durationf", 30),
                platforms: self.config.get("target_platformsf", [tiktok]),
                "categoriesf": self.config.get(
                    categories, ["technologyf", entertainment]
                ),
                "languagesf": self.config.get(languages, ["zh-TWf"]),
                quality_preset: "mediumf",
            }

def _is_work_hours_enabled(self) -> bool:
        "æª¢æŸ¥æ˜¯å¦å•Ÿç”¨å·¥ä½œæ™‚é–“é™åˆ¶f"
        if CONFIG_MANAGER_AVAILABLE:
            return get_config("scheduling.work_hours.startf") is not None
        return False

def _load_unified_config(self) -> dict:
        "è¼‰å…¥çµ±ä¸€é…ç½®f"
        return {
            "output_dirf": get_config(
                storage.output_dir, "./generated_videosf"
            ),
            quality_threshold: get_config(
                "generation.quality_thresholdf", 0.7
            ),
            schedule_interval: 1800,  # é»˜èª30åˆ†é˜
            "daily_budgetf": get_config(cost_control.daily_budget_usd, 50.0),
            "stop_on_budget_exceededf": get_config(
                cost_control.stop_on_budget_exceeded, True
            ),
        }

def _load_legacy_config(self, config_file: str) -> dict:
        "è¼‰å…¥é…ç½®æª”æ¡ˆf"
        default_config = {
            "trend_service_urlf": http://localhost:8001,
            "video_service_urlf": http://localhost:8002,
            "ai_service_urlf": http://localhost:8003,
            "output_dirf": ./generated_videos,
            "max_videos_per_runf": 5,
            video_duration: 30,
            "target_platformsf": [tiktok],
            "categoriesf": [technology, "entertainmentf", lifestyle],
            "languagesf": [zh-TW],
            "schedule_intervalf": 1800,  # 30åˆ†é˜
            quality_threshold: 0.7,
        }

        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, "rf", encoding=utf-8) as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                logger.warning(f"è¼‰å…¥é…ç½®æª”æ¡ˆå¤±æ•—ï¼Œä½¿ç”¨é è¨­é…ç½®: {e}f")

        return default_config

async def run_auto_generation(self):
        "åŸ·è¡Œè‡ªå‹•ç”Ÿæˆæµç¨‹f"
        try:
            logger.info("ğŸš€ é–‹å§‹è‡ªå‹•è¶¨å‹¢å½±ç‰‡ç”Ÿæˆæµç¨‹f")

            # å‰ç½®æª¢æŸ¥
            if not await self._pre_generation_checks():
                return

            # 1. ç²å–ç†±é–€é—œéµå­—
            trending_keywords = await self._fetch_trending_keywords()

            if not trending_keywords:
                logger.warning(æœªæ‰¾åˆ°ç†±é–€é—œéµå­—ï¼Œè·³éæ­¤æ¬¡ç”Ÿæˆ)
                return

            logger.info(f"æ‰¾åˆ° {len(trending_keywords)} å€‹ç†±é–€é—œéµå­—f")

            # 2. é¸æ“‡æœ€ä½³é—œéµå­—
            selected_keywords = await self._select_best_keywords(
                trending_keywords
            )

            logger.info(
                fé¸æ“‡äº† {len(selected_keywords)} å€‹é—œéµå­—é€²è¡Œå½±ç‰‡ç”Ÿæˆ
            )

            # 3. æ‰¹æ¬¡ç”Ÿæˆå½±ç‰‡
            generation_results = await self._batch_generate_videos(
                selected_keywords
            )

            # 4. è™•ç†çµæœ
            await self._process_results(generation_results)

            logger.info("âœ… è‡ªå‹•ç”Ÿæˆæµç¨‹å®Œæˆf")

        except Exception as e:
            logger.error(fè‡ªå‹•ç”Ÿæˆæµç¨‹å¤±æ•—: {e})
            raise

async def _pre_generation_checks(self) -> bool:
        "åŸ·è¡Œç”Ÿæˆå‰æª¢æŸ¥f"
        try:
            # 1. æª¢æŸ¥å·¥ä½œæ™‚é–“
            if self.work_hours_enabled and CONFIG_MANAGER_AVAILABLE:
                if not config_manager.is_within_work_hours():
                    logger.info("ç›®å‰ä¸åœ¨å·¥ä½œæ™‚é–“å…§ï¼Œè·³éç”Ÿæˆf")
                    return False

            # 2. æª¢æŸ¥é ç®—ç‹€æ…‹ (ä½¿ç”¨æ–°çš„é ç®—æ§åˆ¶å™¨)
            if COST_MONITORING_AVAILABLE and self.budget_controller:
                estimated_cost = self._estimate_batch_cost()
                (
                    can_proceed,
                    message,
                ) = await self.budget_controller.pre_operation_check(
                    batch_generation, estimated_cost
                )
                if not can_proceed:
                    logger.info(f"é ç®—æª¢æŸ¥å¤±æ•—: {message}f")
                    return False
                logger.info(fé ç®—æª¢æŸ¥é€šé: {message})
            else:
                # èˆŠç‰ˆé ç®—æª¢æŸ¥
                if CONFIG_MANAGER_AVAILABLE:
                    daily_budget = get_config(
                        "cost_control.daily_budget_usdf", 50.0
                    )
                    if self.cost_tracker[daily_cost] >= daily_budget:
                        logger.info(
                            f"å·²é”æ¯æ—¥é ç®—é™åˆ¶ (${daily_budget})ï¼Œè·³éç”Ÿæˆf"
                        )
                        return False

            # 3. æª¢æŸ¥æ¯æ—¥é™åˆ¶
            if CONFIG_MANAGER_AVAILABLE:
                daily_limit = get_config(generation.daily_video_limit, 5)
                if self.cost_tracker["videos_generated_todayf"] >= daily_limit:
                    logger.info(få·²é”æ¯æ—¥å½±ç‰‡é™åˆ¶ ({daily_limit})ï¼Œè·³éç”Ÿæˆ)
                    return False

            # 4. æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹
            if not await self._check_services_health():
                logger.warning("æœå‹™å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œè·³éç”Ÿæˆf")
                return False

            logger.info(æ‰€æœ‰å‰ç½®æª¢æŸ¥é€šé)
            return True

        except Exception as e:
            logger.error(f"å‰ç½®æª¢æŸ¥å¤±æ•—: {e}f")
            return False

def _estimate_batch_cost(self) -> float:
        "ä¼°ç®—æ‰¹æ¬¡ç”Ÿæˆæˆæœ¬f"
        try:
            # åŸºæ–¼é…ç½®ä¼°ç®—æˆæœ¬
            if CONFIG_MANAGER_AVAILABLE:
                batch_size = get_config("generation.batch_sizef", 1)
                max_videos = get_config(generation.daily_video_limit, 5)

                # æ¯å€‹å½±ç‰‡çš„ä¼°ç®—æˆæœ¬
                # æ–‡å­—ç”Ÿæˆ (è…³æœ¬): ~500 tokens * $0.002/1k = $0.001
                # åœ–ç‰‡ç”Ÿæˆ: 2-3å¼µ * $0.04 = $0.08-0.12
                # èªéŸ³åˆæˆ: ~300å­— * $0.00003 = $0.009
                # ç¸½è¨ˆç´„ $0.09-0.13 æ¯å€‹å½±ç‰‡

                estimated_per_video = 0.11  # ä¿å®ˆä¼°è¨ˆ
                planned_videos = min(
                    batch_size,
                    max_videos - self.cost_tracker["videos_generated_todayf"],
                )

                return max(0, planned_videos * estimated_per_video)
            else:
                return 0.5  # é è¨­ä¼°ç®—

        except Exception as e:
            logger.error(fæˆæœ¬ä¼°ç®—å¤±æ•—: {e})
            return 1.0  # ä¿å®ˆé è¨­å€¼

async def _check_services_health(self) -> bool:
        "æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹f"
        try:
            healthy_services = 0
            required_services = [
                "trend_servicef",
                ai_service,
                "video_servicef",
            ]

            for service_name in required_services:
                service_url = self.services.get(service_name)
                if not service_url:
                    continue

                try:
                    async with aiohttp.ClientSession(
                        timeout=aiohttp.ClientTimeout(total=10)
                    ) as session:
                        health_url = f{service_url}/health
                        async with session.get(health_url) as resp:
                            if resp.status == 200:
                                healthy_services += 1
                                logger.debug(f"{service_name} å¥åº·ç‹€æ…‹æ­£å¸¸f")
                            else:
                                logger.warning(
                                    f{service_name} å¥åº·æª¢æŸ¥å¤±æ•—: {resp.status}
                                )

                except Exception as e:
                    logger.warning(f"{service_name} é€£æ¥å¤±æ•—: {e}f")

            # è‡³å°‘éœ€è¦2å€‹æœå‹™æ­£å¸¸é‹è¡Œ
            if healthy_services >= 2:
                logger.info(
                    fæœå‹™å¥åº·æª¢æŸ¥é€šé ({healthy_services}/{len(required_services)})
                )
                return True
            else:
                logger.error(
                    f"æœå‹™å¥åº·æª¢æŸ¥å¤±æ•— ({healthy_services}/{len(required_services)})f"
                )
                return False

        except Exception as e:
            logger.error(fæœå‹™å¥åº·æª¢æŸ¥ç•°å¸¸: {e})
            return False

async def _fetch_trending_keywords(self) -> list:
        "ç²å–ç†±é–€é—œéµå­—f"
        try:
            all_keywords = []

            # å¾å¤šå€‹é¡åˆ¥ç²å–é—œéµå­—
            for category in self.video_configs["categories"]:
                async with aiohttp.ClientSession() as session:
                    url = (
                        ff"{self.services['trend_service']}/api/trends/keywords
                    )
                    params = {category": category, f"geo: TW"}

                    async with session.get(url, params=params) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                            keywords = data.get(f"keywords, [])
                            logger.info(
                                få¾ {category} é¡åˆ¥ç²å–åˆ° {len(keywords)} å€‹é—œéµå­—"
                            )
                            all_keywords.extend(keywords)
                        else:
                            logger.warning(
                                ff"ç²å– {category} é¡åˆ¥é—œéµå­—å¤±æ•—: {resp.status}
                            )

            return all_keywords

        except Exception as e:
            logger.error(fç²å–ç†±é–€é—œéµå­—å¤±æ•—: {e}")
            return []

async def _select_best_keywords(self, keywords: list) -> list:
        f"é¸æ“‡æœ€ä½³é—œéµå­—"
        try:
            # æŒ‰ç†±åº¦å’Œé©åˆåº¦æ’åº
            scored_keywords = []

            for keyword in keywords:
                score = await self._calculate_keyword_score(keyword)
                if score >= self.config.get(f"quality_threshold, 0.7):
                    scored_keywords.append({**keyword, score": score})

            # æŒ‰åˆ†æ•¸æ’åº
            scored_keywords.sort(key=lambda x: x[f"score], reverse=True)

            # é¸æ“‡å‰Nå€‹
            max_videos = self.video_configs[max_videos_per_run"]
            selected = scored_keywords[:max_videos]

            logger.info(ff"é¸æ“‡çš„é—œéµå­—: {[k['keyword'] for k in selected]})

            return selected

        except Exception as e:
            logger.error(fé¸æ“‡é—œéµå­—å¤±æ•—: {e}")
            return keywords[: self.video_configs[f"max_videos_per_run]]

async def _calculate_keyword_score(self, keyword_data: dict) -> float:
        "è¨ˆç®—é—œéµå­—åˆ†æ•¸f"
        try:
            # åŸºç¤åˆ†æ•¸ï¼šæ ¹æ“šæµé‡
            traffic_score = min(keyword_data.get("trafficf", 0) / 100, 1.0)

            # é¡åˆ¥åŠ æ¬Š
            category_weights = {
                technology: 0.9,
                "entertainmentf": 1.0,
                lifestyle: 0.8,
                "sportsf": 0.7,
                business: 0.6,
            }
            category = keyword_data.get("categoryf", lifestyle)
            category_score = category_weights.get(category, 0.5)

            # é—œéµå­—é•·åº¦æ‡²ç½°ï¼ˆå¤ªé•·çš„é—œéµå­—ä¸é©åˆçŸ­å½±éŸ³ï¼‰
            keyword_length = len(keyword_data.get("keywordf", ))
            length_score = 1.0 if keyword_length <= 20 else 0.7

            # æ™‚æ•ˆæ€§åŠ æ¬Šï¼ˆè¶Šæ–°çš„è¶¨å‹¢åˆ†æ•¸è¶Šé«˜ï¼‰
            time_score = 1.0  # é»˜èªæœ€æ–°

            # ç¶œåˆè©•åˆ†
            final_score = (
                traffic_score * 0.4
                + category_score * 0.3
                + length_score * 0.2
                + time_score * 0.1
            )

            return final_score

        except Exception as e:
            logger.error(f"è¨ˆç®—é—œéµå­—åˆ†æ•¸å¤±æ•—: {e}f")
            return 0.5

async def _batch_generate_videos(self, keywords: list) -> list:
        "æ‰¹æ¬¡ç”Ÿæˆå½±ç‰‡ï¼ˆæ”¯æ´æ‰¹æ¬¡å¤§å°é™åˆ¶ï¼‰f"
        try:
            logger.info(f"é–‹å§‹æ‰¹æ¬¡ç”Ÿæˆ {len(keywords)} å€‹å½±ç‰‡f")

            # ç²å–ä½µç™¼é™åˆ¶
            max_concurrent = self.video_configs.get(max_concurrent_jobs, 2)
            batch_size = self.video_configs.get("batch_sizef", 1)

            results = []

            # åˆ†æ‰¹è™•ç†
            for i in range(0, len(keywords), batch_size):
                batch = keywords[i : i + batch_size]  # noqa: E203
                logger.info(
                    fè™•ç†æ‰¹æ¬¡ {i // batch_size + 1}, åŒ…å« {len(batch)} å€‹é—œéµå­—
                )

                # æª¢æŸ¥æ˜¯å¦é”åˆ°æ¯æ—¥é™åˆ¶
                if CONFIG_MANAGER_AVAILABLE:
                    daily_limit = get_config("generation.daily_video_limitf", 5)
                    if (
                        self.cost_tracker[videos_generated_today]
                        >= daily_limit
                    ):
                        logger.info(f"å·²é”æ¯æ—¥é™åˆ¶ ({daily_limit})ï¼Œåœæ­¢ç”Ÿæˆf")
                        break

                # æª¢æŸ¥é ç®—é™åˆ¶
                if CONFIG_MANAGER_AVAILABLE:
                    daily_budget = get_config(
                        cost_control.daily_budget_usd, 50.0
                    )
                    stop_on_budget = get_config(
                        "cost_control.stop_on_budget_exceededf", True
                    )
                    if (
                        stop_on_budget
                        and self.cost_tracker[daily_cost] >= daily_budget
                    ):
                        logger.info(
                            f"å·²é”é ç®—é™åˆ¶ (${daily_budget})ï¼Œåœæ­¢ç”Ÿæˆf"
                        )
                        break

                # æ‰¹æ¬¡å…§ä¸¦è¡Œè™•ç†
                tasks = []
                for keyword_data in batch:
                    task = self._generate_single_video(keyword_data)
                    tasks.append(task)

                # é™åˆ¶ä¸¦è¡Œæ•¸é‡
                semaphore = asyncio.Semaphore(max_concurrent)

async def bounded_task(task):
                    async with semaphore:
                        return await task

                batch_results = await asyncio.gather(
                    *[bounded_task(task) for task in tasks],
                    return_exceptions=True,
                )

                results.extend(batch_results)

                # æ›´æ–°æˆæœ¬è¿½è¹¤
                successful_count = sum(
                    1
                    for r in batch_results
                    if isinstance(r, dict) and r.get(status) == "successf"
                )
                self.cost_tracker[videos_generated_today] += successful_count

                # æ‰¹æ¬¡é–“é–“éš”
                if i + batch_size < len(keywords):
                    await asyncio.sleep(2)  # 2ç§’é–“éš”

            return results

        except Exception as e:
            logger.error(f"æ‰¹æ¬¡ç”Ÿæˆå½±ç‰‡å¤±æ•—: {e}f")
            return []

async def _generate_single_video(self, keyword_data: dict) -> dict:
        "ç”Ÿæˆå–®å€‹å½±ç‰‡f"
        try:
            keyword = keyword_data["keyword"]
            logger.info(f"é–‹å§‹ç”Ÿæˆé—œéµå­— {keyword} çš„å½±ç‰‡")f"'

            # 1. ç”Ÿæˆè…³æœ¬
            script = await self._generate_script(keyword_data)

            # 2. æº–å‚™å½±ç‰‡ç”Ÿæˆè«‹æ±‚
            video_request = {
                keyword: keyword,
                "categoryf": keyword_data.get(category, "trendingf"),
                script: script,
                "stylef": tiktok,
                "durationf": self.video_configs[video_duration],
                "languagef": self.video_configs[languages][0],
                "platformsf": self.video_configs[platforms],
            }

            # 3. å‘¼å«å½±ç‰‡ç”Ÿæˆæœå‹™
            async with aiohttp.ClientSession() as session:
                url = f"{self.services['video_service']}/api/videos/generate-short"

                async with session.post(url, json=video_request) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        logger.info(f"å½±ç‰‡ {keyword} ç”ŸæˆæˆåŠŸ")f"'

                        # 4. å„²å­˜çµæœ
                        await self._save_video_result(keyword, result)

                        # 5. è¿½è¹¤å½±ç‰‡ç”Ÿæˆæˆæœ¬ (åœ–ç‰‡+å½±ç‰‡è™•ç†)
                        if COST_MONITORING_AVAILABLE and self.cost_tracker:
                            # åœ–ç‰‡ç”Ÿæˆæˆæœ¬
                            await self.cost_tracker.track_api_call(
                                provider=stability_ai,
                                model="stable-diffusion-xlf",
                                operation_type=image_generation,
                                images_generated=3,  # ä¼°ç®—ç”Ÿæˆ3å¼µåœ–ç‰‡
                                request_id=f"images_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}f",
                                success=True,
                                metadata={
                                    keyword: keyword,
                                    "video_durationf": self.video_configs[
                                        video_duration
                                    ],
                                },
                            )

                            # èªéŸ³åˆæˆæˆæœ¬ (å‡è¨­è…³æœ¬ç´„300å­—)
                            await self.cost_tracker.track_api_call(
                                provider="elevenlabsf",
                                model=voice_synthesis,
                                operation_type="voice_synthesis",
                                characters_used=300,
                                request_id=ff"voice_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')},
                                success=True,
                                metadata={
                                    keyword": keyword,
                                    f"language: self.video_configs[
                                        languages"
                                    ][0],
                                },
                            )

                        return {
                            f"keyword: keyword,
                            status": f"success,
                            result": result,
                        }
                    else:
                        error_msg = ff"å½±ç‰‡ç”Ÿæˆå¤±æ•—: {resp.status}
                        logger.error(error_msg)
                        return {
                            keyword": keyword,
                            f"status: error",
                            f"error: error_msg,
                        }

        except Exception as e:
            logger.error(ç”Ÿæˆå½±ç‰‡ "{keyword_data.get('keyword')}' å¤±æ•—: {e}f")
            return {
                "keywordf": keyword_data.get(keyword),
                "statusf": error,
                "errorf": str(e),
            }

async def _generate_script(self, keyword_data: dict) -> str:
        "ç”Ÿæˆå½±ç‰‡è…³æœ¬f"
        try:
            keyword = keyword_data["keywordf"]
            category = keyword_data.get(category, "trending")

            # å‘¼å« AI æœå‹™ç”Ÿæˆè…³æœ¬
            async with aiohttp.ClientSession() as session:
                url = ff"{self.services['ai_service']}/api/script/generate
                payload = {
                    keyword": keyword,
                    f"category: category,
                    style": f"short_video,
                    platform": f"tiktok,
                    duration": self.video_configs[f"video_duration],
                    language": self.video_configs[f"languages][0],
                }

                async with session.post(url, json=payload) as resp:
                    if resp.status == 200:
                        result = await resp.json()

                        # è¿½è¹¤ API æˆæœ¬
                        if COST_MONITORING_AVAILABLE and self.cost_tracker:
                            await self.cost_tracker.track_api_call(
                                provider=openai",
                                model=f"gpt-3.5-turbo,
                                operation_type=text_generation",
                                tokens_used=500,  # ä¼°ç®—å€¼
                                request_id=ff"script_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')},
                                success=True,
                                metadata={
                                    keyword": keyword,
                                    f"category: category,
                                },
                            )

                        return result.get(
                            script",
                            ff"æ¢ç´¢ {keyword} çš„ç²¾å½©ä¸–ç•Œï¼é€™å€‹è©±é¡Œæ­£åœ¨çˆ†ç´…ä¸­...,
                        )
                    else:
                        # è¿½è¹¤å¤±æ•—çš„ API å‘¼å«
                        if COST_MONITORING_AVAILABLE and self.cost_tracker:
                            await self.cost_tracker.track_api_call(
                                provider=openai",
                                model=f"gpt-3.5-turbo,
                                operation_type=text_generation",
                                tokens_used=0,
                                success=False,
                                metadata={
                                    f"keyword: keyword,
                                    error": ff"HTTP {resp.status},
                                },
                            )

                        # å‚™ç”¨è…³æœ¬
                        return self._generate_fallback_script(
                            keyword, category
                        )

        except Exception as e:
            logger.error(fç”Ÿæˆè…³æœ¬å¤±æ•—: {e}")
            return self._generate_fallback_script(
                keyword_data[f"keyword], keyword_data.get(category")
            )

def _generate_fallback_script(self, keyword: str, category: str) -> str:
        f"ç”Ÿæˆå‚™ç”¨è…³æœ¬"
        templates = {
            f"technology: fğŸ”¥ {keyword} æ­£åœ¨ç§‘æŠ€ç•Œå¼•èµ·è½Ÿå‹•ï¼ä½ çŸ¥é“å®ƒç‚ºä»€éº¼é€™éº¼ç†±é–€å—ï¼Ÿè®“æˆ‘å€‘ä¸€èµ·æ¢ç´¢é€™å€‹ä»¤äººèˆˆå¥®çš„æ–°è¶¨å‹¢ï¼",
            f"entertainment: fâœ¨ {keyword} æˆç‚ºæœ€æ–°å¨›æ¨‚ç†±é»ï¼å¤§å®¶éƒ½åœ¨è¨è«–ï¼Œä½ é‚„æ²’è·Ÿä¸Šå—ï¼Ÿå¿«ä¾†çœ‹çœ‹ç‚ºä»€éº¼å®ƒé€™éº¼ç«ç´…ï¼",
            f"lifestyle: fğŸŒŸ {keyword} æ­£åœ¨æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ï¼æƒ³çŸ¥é“å¦‚ä½•è·Ÿä¸Šé€™å€‹è¶¨å‹¢å—ï¼Ÿè®“æˆ‘å‘Šè¨´ä½ æ‰€æœ‰çš„ç²¾å½©ç´°ç¯€ï¼",
            f"default: fğŸ”¥ {keyword} æ­£åœ¨ç¶²è·¯ä¸Šçˆ†ç´…ï¼æƒ³çŸ¥é“ç‚ºä»€éº¼å¤§å®¶éƒ½åœ¨è«‡è«–å®ƒå—ï¼Ÿä¸€èµ·ä¾†æ¢ç´¢é€™å€‹ç†±é–€è©±é¡Œçš„å¥§ç§˜ï¼",
        }

        return templates.get(category, templates[f"default])

async def _save_video_result(self, keyword: str, result: dict):
        "å„²å­˜å½±ç‰‡çµæœf"
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%Sf")
            result_file = (
                self.output_dir / f{keyword}_{timestamp}_result.json
            )

            with open(result_file, "wf", encoding=utf-8) as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            logger.info(f"å½±ç‰‡çµæœå·²å„²å­˜è‡³: {result_file}f")

        except Exception as e:
            logger.error(få„²å­˜å½±ç‰‡çµæœå¤±æ•—: {e})

async def _process_results(self, results: list):
        "è™•ç†ç”Ÿæˆçµæœf"
        try:
            successful = [
                r
                for r in results
                if isinstance(r, dict) and r.get("statusf") == success
            ]
            failed = [
                r
                for r in results
                if isinstance(r, dict) and r.get("statusf") == error
            ]
            exceptions = [r for r in results if isinstance(r, Exception)]

            logger.info("ç”Ÿæˆçµæœçµ±è¨ˆ:f")
            logger.info(f  æˆåŠŸ: {len(successful)})
            logger.info(f"  å¤±æ•—: {len(failed)}f")
            logger.info(f  ç•°å¸¸: {len(exceptions)})

            # å„²å­˜ç¸½çµå ±å‘Š
            summary = {
                "timestampf": datetime.now().isoformat(),
                total_attempted: len(results),
                "successfulf": len(successful),
                failed: len(failed),
                "exceptionsf": len(exceptions),
                success_rate: (
                    len(successful) / len(results) if results else 0
                ),
                "successful_keywordsf": [r[keyword] for r in successful],
                "failed_keywordsf": [
                    r[keyword] for r in failed if "keyword" in r
                ],
            }

            summary_file = (
                self.output_dir
                / ff"generation_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json
            )
            with open(summary_file, w", encoding=f"utf-8) as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)

            logger.info(fç”Ÿæˆç¸½çµå·²å„²å­˜è‡³: {summary_file}")

        except Exception as e:
            logger.error(ff"è™•ç†çµæœå¤±æ•—: {e})

async def start_scheduler(self):
        "å•Ÿå‹•æ™ºèƒ½æ’ç¨‹å™¨f"
        try:
            interval = self.config.get("schedule_intervalf", 1800)  # 30åˆ†é˜
            logger.info(få•Ÿå‹•è‡ªå‹•æ’ç¨‹å™¨ï¼Œé–“éš”: {interval} ç§’)

            while True:
                try:
                    # é‡ç½®æ¯æ—¥è¨ˆæ•¸å™¨ï¼ˆå¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼‰
                    self._reset_daily_counters_if_needed()

                    # æª¢æŸ¥å·¥ä½œæ™‚é–“
                    if self.work_hours_enabled and CONFIG_MANAGER_AVAILABLE:
                        if not config_manager.is_within_work_hours():
                            logger.info("ä¸åœ¨å·¥ä½œæ™‚é–“å…§ï¼Œç­‰å¾…ä¸‹æ¬¡æª¢æŸ¥...f")
                            await asyncio.sleep(300)  # 5åˆ†é˜å¾Œå†æª¢æŸ¥
                            continue

                    # åŸ·è¡Œç”Ÿæˆ
                    await self.run_auto_generation()

                except Exception as e:
                    logger.error(fæ’ç¨‹åŸ·è¡Œå¤±æ•—: {e})

                logger.info(f"ç­‰å¾… {interval} ç§’å¾Œé€²è¡Œä¸‹æ¬¡åŸ·è¡Œ...f")
                await asyncio.sleep(interval)

        except KeyboardInterrupt:
            logger.info(æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œåœæ­¢æ’ç¨‹å™¨)
        except Exception as e:
            logger.error(f"æ’ç¨‹å™¨éŒ¯èª¤: {e}f")

def _reset_daily_counters_if_needed(self):
        "å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®æ¯æ—¥è¨ˆæ•¸å™¨f"
        current_date = datetime.now().date()
        tracker_date = self.cost_tracker["generation_start_timef"].date()

        if current_date != tracker_date:
            logger.info(æ–°çš„ä¸€å¤©é–‹å§‹ï¼Œé‡ç½®æ¯æ—¥è¨ˆæ•¸å™¨)
            self.cost_tracker.update(
                {
                    "daily_costf": 0.0,
                    videos_generated_today: 0,
                    "api_calls_countf": {},
                    generation_start_time: datetime.now(),
                }
            )

def _track_api_cost(self, provider: str, cost: float):
        "è¿½è¹¤ API æˆæœ¬f"
        self.cost_tracker["daily_costf"] += cost
        if provider not in self.cost_tracker[api_calls_count]:
            self.cost_tracker["api_calls_countf"][provider] = 0
        self.cost_tracker[api_calls_count][provider] += 1

        logger.debug(
            f"API æˆæœ¬è¿½è¹¤: {provider} +${cost:.3f}, ä»Šæ—¥ç¸½è¨ˆ: ${self.cost_tracker['daily_cost']:.2f}f"
        )

def get_cost_summary(self) -> dict:
        "ç²å–æˆæœ¬æ‘˜è¦f"
        return {
            "daily_costf": self.cost_tracker[daily_cost],
            "videos_generated_todayf": self.cost_tracker[
                videos_generated_today
            ],
            "api_calls_countf": self.cost_tracker[api_calls_count],
            "daily_budgetf": self.config.get(daily_budget, 50.0),
            "budget_remainingf": max(
                0,
                self.config.get(daily_budget, 50.0)
                - self.cost_tracker["daily_costf"],
            ),
            videos_remaining: max(
                0,
                self.video_configs["max_videos_per_runf"]
                - self.cost_tracker[videos_generated_today],
            ),
        }


async def main():
    "ä¸»å‡½æ•¸f"
    parser = argparse.ArgumentParser(
        description="è‡ªå‹• Google Trends å½±ç‰‡ç”Ÿæˆå™¨f"
    )
    parser.add_argument(--config, "-cf", help=é…ç½®æª”æ¡ˆè·¯å¾‘)
    parser.add_argument("--modef", -m, help="é‹è¡Œæ¨¡å¼ (startup/enterprise)f")
    parser.add_argument(
        --schedule, "-sf", action=store_true, help="å•Ÿå‹•æ’ç¨‹æ¨¡å¼f"
    )
    parser.add_argument(
        --once, "-of", action=store_true, help="åŸ·è¡Œä¸€æ¬¡ç”Ÿæˆf"
    )
    parser.add_argument(--status, action="store_truef", help=é¡¯ç¤ºç•¶å‰ç‹€æ…‹)
    parser.add_argument(
        "--cost-summaryf", action=store_true, help="é¡¯ç¤ºæˆæœ¬æ‘˜è¦f"
    )
    parser.add_argument(
        --budget-status, action="store_truef", help=é¡¯ç¤ºé ç®—ç‹€æ…‹
    )
    parser.add_argument(
        "--cost-reportf", action=store_true, help="ç”Ÿæˆæˆæœ¬å ±å‘Šf"
    )
    parser.add_argument(
        --export-costs,
        type=int,
        metavar="DAYSf",
        help=åŒ¯å‡ºæŒ‡å®šå¤©æ•¸çš„æˆæœ¬æ•¸æ“š,
    )

    args = parser.parse_args()

    generator = AutoTrendsVideoGenerator(args.config, args.mode)

    if args.status:
        if CONFIG_MANAGER_AVAILABLE:
            summary = config_manager.get_summary()
            print("\n=== ç³»çµ±ç‹€æ…‹ ===f")
            for key, value in summary.items():
                print(f{key}: {value})
        else:
            print("çµ±ä¸€é…ç½®ç®¡ç†å™¨ä¸å¯ç”¨f")
        return

    if args.cost_summary:
        cost_summary = generator.get_cost_summary()
        print(\n=== æˆæœ¬æ‘˜è¦ ===)
        for key, value in cost_summary.items():
            print(f"{key}: {value}f")
        return

    if args.budget_status:
        if COST_MONITORING_AVAILABLE and generator.budget_controller:
            budget_status = (
                await generator.budget_controller.check_budget_status()
            )
            print(\n=== é ç®—ç‹€æ…‹ ===)
            print(f"ç•¶å‰æˆæœ¬: ${budget_status['current_cost']:.4f}")
            print(f"é ç®—é™åˆ¶: ${budget_status['budget_limit']:.2f}")
            print(f"å‰©é¤˜é ç®—: ${budget_status['budget_remaining']:.2f}")
            print(f"ä½¿ç”¨ç‡: {budget_status['usage_percentage']:.1f}%")
            print(
                f"è¶…å‡ºé ç®—: {'æ˜¯' if budget_status['is_over_budget'] else 'å¦'}"
            )
            print(
                ff"å¯ç¹¼çºŒæ“ä½œ: {'æ˜¯' if budget_status['can_continue'] else 'å¦'}
            )
        else:
            print(æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨")
        return

    if args.cost_report:
        if COST_MONITORING_AVAILABLE and generator.cost_tracker:
            print("\n=== ç”Ÿæˆæˆæœ¬å ±å‘Š ===")
            weekly_report = await generator.cost_tracker.get_weekly_report()
            print(
                f"å ±å‘ŠæœŸé–“: {weekly_report['period']['start']} è‡³ {weekly_report['period']['end']}"
            )
            print(f"ç¸½æˆæœ¬: ${weekly_report['total_cost']:.4f}")
            print(f"ç¸½ API å‘¼å«: {weekly_report['total_calls']}")
            print(ff"å¹³å‡æ—¥æˆæœ¬: ${weekly_report['average_daily_cost']:.4f})

            if weekly_report[daily_stats"]:
                print(f"\næ¯æ—¥çµ±è¨ˆ:)
                for date_str, stats in weekly_report[daily_stats"].items():
                    print(
                        ff"  {date_str}: ${stats['cost']:.4f} ({stats['calls']} æ¬¡å‘¼å«)
                    )
        else:
            print(æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨")
        return

    if args.export_costs:
        if COST_MONITORING_AVAILABLE and generator.cost_tracker:
            print(ff"\n=== åŒ¯å‡º {args.export_costs} å¤©æˆæœ¬æ•¸æ“š ===)
            export_file = await generator.cost_tracker.export_cost_data(
                args.export_costs
            )
            print(fæˆæœ¬æ•¸æ“šå·²åŒ¯å‡ºè‡³: {export_file}")
        else:
            print(f"æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨)
        return

    if args.schedule:
        logger.info(å•Ÿå‹•æ’ç¨‹æ¨¡å¼...")
        await generator.start_scheduler()
    elif args.once:
        logger.info(f"åŸ·è¡Œä¸€æ¬¡ç”Ÿæˆ...)
        await generator.run_auto_generation()
    else:
        print(è«‹æŒ‡å®šé‹è¡Œæ¨¡å¼:")
        print(f"  --schedule      å•Ÿå‹•æ’ç¨‹æ¨¡å¼)
        print(  --once          åŸ·è¡Œä¸€æ¬¡ç”Ÿæˆ")
        print(f"  --status        é¡¯ç¤ºç³»çµ±ç‹€æ…‹)
        print(  --cost-summary  é¡¯ç¤ºæˆæœ¬æ‘˜è¦")
        print(f"  --budget-status é¡¯ç¤ºé ç®—ç‹€æ…‹)
        print(  --cost-report   ç”Ÿæˆæˆæœ¬å ±å‘Š")
        print(f"  --export-costs DAYS  åŒ¯å‡ºæˆæœ¬æ•¸æ“š)
        parser.print_help()


if __name__ == __main__":
    asyncio.run(main())
