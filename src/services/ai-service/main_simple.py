#!/usr/bin/env python3
"""
AI Service - ç°¡åŒ–ç‰ˆå¯¦ç¾
æ•´åˆOpenAIã€Geminiç­‰AIæœå‹™ï¼Œæä¾›è…³æœ¬ç”Ÿæˆã€TTSèªéŸ³åˆæˆç­‰åŠŸèƒ½
"""

import os
import logging
import hashlib
from datetime import datetime
from typing import Optional, Dict, Any
import asyncio
import aiohttp

import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å‰µå»ºFastAPIæ‡‰ç”¨
app = FastAPI(
    title="AI Service - Simplified",
    version="1.0.0",
    description="AI-powered content generation service",
)

# CORSè¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:5173", 
        "http://localhost:8000",
        "http://127.0.0.1:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:8000",
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

# APIé‡‘é‘°é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")

# Pydanticæ¨¡å‹
class ScriptGenerationRequest(BaseModel):
    topic: str
    platform: str = "youtube"
    style: str = "educational"
    duration: int = 60
    language: str = "zh-TW"
    target_audience: str = "general"

class ImageGenerationRequest(BaseModel):
    prompt: str
    style: str = "realistic"
    resolution: str = "1024x1024"
    quantity: int = 1

class VoiceGenerationRequest(BaseModel):
    text: str
    voice_id: str = "alloy"
    speed: float = 1.0
    language: str = "zh-TW"

class MusicGenerationRequest(BaseModel):
    prompt: str
    style: str = "background"
    duration: int = 30
    mood: str = "upbeat"

# OpenAI API èª¿ç”¨å‡½æ•¸
async def call_openai_api(endpoint: str, data: dict, headers: dict) -> dict:
    """èª¿ç”¨OpenAI APIçš„é€šç”¨å‡½æ•¸"""
    async with aiohttp.ClientSession() as session:
        async with session.post(
            f"https://api.openai.com/v1/{endpoint}",
            json=data,
            headers=headers,
            timeout=aiohttp.ClientTimeout(total=30)
        ) as response:
            if response.status == 200:
                return await response.json()
            else:
                error_text = await response.text()
                raise HTTPException(
                    status_code=response.status, 
                    detail=f"OpenAI API error: {error_text}"
                )

# DeepSeek API èª¿ç”¨å‡½æ•¸  
async def call_deepseek_api(messages: list) -> dict:
    """èª¿ç”¨DeepSeek APIç”Ÿæˆè…³æœ¬"""
    if not DEEPSEEK_API_KEY:
        return None
        
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "deepseek-chat",
        "messages": messages,
        "max_tokens": 1000,
        "temperature": 0.7
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.deepseek.com/v1/chat/completions",
                json=data,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result
                else:
                    logger.error(f"DeepSeek API error: {response.status}")
                    return None
    except Exception as e:
        logger.error(f"DeepSeek API call failed: {e}")
        return None

# å¥åº·æª¢æŸ¥ç«¯é»
@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    api_keys_status = {
        "openai": "configured" if OPENAI_API_KEY and len(OPENAI_API_KEY) > 10 else "missing",
        "deepseek": "configured" if DEEPSEEK_API_KEY and len(DEEPSEEK_API_KEY) > 10 else "missing", 
        "gemini": "configured" if GEMINI_API_KEY and len(GEMINI_API_KEY) > 10 else "missing",
    }
    
    return {
        "status": "healthy",
        "service": "ai-service",
        "version": "1.0.0", 
        "timestamp": datetime.utcnow().isoformat(),
        "api_keys": api_keys_status,
        "features": [
            "Script Generation (DeepSeek/OpenAI)",
            "Voice Synthesis (OpenAI TTS)",
            "Image Generation (Placeholder)",
            "Music Generation (Placeholder)"
        ]
    }

@app.get("/")
async def root():
    """æ ¹ç«¯é»"""
    return {
        "message": "AI Service - Content Generation Platform",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health",
    }

# è…³æœ¬ç”Ÿæˆç«¯é»
@app.post("/api/v1/generate/script")
async def generate_script(request: ScriptGenerationRequest):
    """ç”Ÿæˆå½±ç‰‡è…³æœ¬"""
    logger.info(f"Generating script for topic: {request.topic}")
    
    # æ§‹å»ºç³»çµ±æç¤º
    platform_guide = {
        "youtube": "é©åˆYouTubeé•·å½±ç‰‡ï¼Œéœ€è¦è©³ç´°è§£èªªå’Œæ•™è‚²æ€§å…§å®¹",
        "tiktok": "é©åˆTikTokçŸ­å½±ç‰‡ï¼Œéœ€è¦å¿«ç¯€å¥å’Œå¸å¼•æ³¨æ„åŠ›",
        "instagram": "é©åˆInstagram Reelsï¼Œéœ€è¦è¦–è¦ºåŒ–å’Œæ™‚å°šæ„Ÿ"
    }
    
    style_guide = {
        "educational": "æ•™è‚²æ€§é¢¨æ ¼ï¼Œæä¾›æœ‰åƒ¹å€¼çš„çŸ¥è­˜å’Œè¦‹è§£",
        "entertaining": "å¨›æ¨‚æ€§é¢¨æ ¼ï¼Œè¼•é¬†å¹½é»˜ï¼Œå®¹æ˜“ç†è§£",
        "promotional": "æ¨å»£æ€§é¢¨æ ¼ï¼Œçªå‡ºç”¢å“å„ªå‹¢å’Œåƒ¹å€¼"
    }
    
    system_prompt = f"""
    ä½ æ˜¯å°ˆæ¥­çš„{request.platform}å…§å®¹å‰µä½œè€…ã€‚è«‹ç‚ºä¸»é¡Œã€Œ{request.topic}ã€å‰µä½œä¸€å€‹{request.style}é¢¨æ ¼çš„å½±ç‰‡è…³æœ¬ã€‚
    
    è¦æ±‚ï¼š
    1. {platform_guide.get(request.platform, 'å‰µä½œé«˜å“è³ªå…§å®¹')}
    2. {style_guide.get(request.style, 'ä¿æŒå°ˆæ¥­é¢¨æ ¼')}
    3. ç›®æ¨™è§€çœ¾ï¼š{request.target_audience}
    4. é æœŸæ™‚é•·ï¼š{request.duration}ç§’
    5. èªè¨€ï¼š{request.language}
    6. åŒ…å«å¸å¼•äººçš„é–‹å ´ã€ä¸»è¦å…§å®¹å’Œå¼·æœ‰åŠ›çš„çµå°¾
    
    è«‹ç›´æ¥è¼¸å‡ºè…³æœ¬å…§å®¹ï¼Œä½¿ç”¨è‡ªç„¶çš„å£èªåŒ–è¡¨é”ã€‚
    """
    
    user_message = f"è«‹ç‚ºã€Œ{request.topic}ã€å‰µä½œä¸€å€‹{request.platform}å¹³å°çš„{request.style}é¢¨æ ¼å½±ç‰‡è…³æœ¬ï¼Œæ™‚é•·ç´„{request.duration}ç§’ã€‚"
    
    # å˜—è©¦ä½¿ç”¨DeepSeek API
    script_content = None
    generation_source = "fallback"
    
    if DEEPSEEK_API_KEY and len(DEEPSEEK_API_KEY) > 10:
        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ]
            
            deepseek_result = await call_deepseek_api(messages)
            if deepseek_result and "choices" in deepseek_result:
                script_content = deepseek_result["choices"][0]["message"]["content"]
                generation_source = "deepseek"
                logger.info("Script generated using DeepSeek API")
        except Exception as e:
            logger.error(f"DeepSeek API failed: {e}")
    
    # å¦‚æœDeepSeekå¤±æ•—ï¼Œå˜—è©¦OpenAI
    if not script_content and OPENAI_API_KEY and len(OPENAI_API_KEY) > 10:
        try:
            headers = {
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            openai_result = await call_openai_api("chat/completions", data, headers)
            if openai_result and "choices" in openai_result:
                script_content = openai_result["choices"][0]["message"]["content"]
                generation_source = "openai"
                logger.info("Script generated using OpenAI API")
        except Exception as e:
            logger.error(f"OpenAI API failed: {e}")
    
    # å›é€€åˆ°æœ¬åœ°ç”Ÿæˆ
    if not script_content:
        logger.info("Using fallback script generation")
        script_content = f"""ã€{request.topic}ã€‘å½±ç‰‡è…³æœ¬

ğŸ¬ é–‹å ´ (0-5ç§’)
å—¨å¤§å®¶å¥½ï¼ä»Šå¤©æˆ‘å€‘è¦ä¾†èŠèŠ{request.topic}ï¼Œé€™æ˜¯ä¸€å€‹éå¸¸æœ‰è¶£ä¸”å¯¦ç”¨çš„è©±é¡Œã€‚

ğŸ“– ä¸»è¦å…§å®¹ (5-{request.duration-10}ç§’)
é¦–å…ˆï¼Œè®“æˆ‘å€‘äº†è§£ä»€éº¼æ˜¯{request.topic}ã€‚{request.topic}åœ¨ç¾ä»£ç”Ÿæ´»ä¸­æ‰®æ¼”è‘—é‡è¦çš„è§’è‰²ï¼Œå®ƒå¯ä»¥å¹«åŠ©æˆ‘å€‘...

æ¥ä¸‹ä¾†ï¼Œæˆ‘æƒ³å’Œå¤§å®¶åˆ†äº«å¹¾å€‹é—œæ–¼{request.topic}çš„é‡è¦è§€é»ï¼š

1. ç¬¬ä¸€å€‹é‡é»æ˜¯...
2. ç¬¬äºŒå€‹è¦æ³¨æ„çš„æ˜¯...
3. æœ€å¾Œä¸€å€‹é—œéµå› ç´ ...

ğŸ’¡ å¯¦ç”¨å»ºè­°
åŸºæ–¼æˆ‘çš„ç¶“é©—ï¼Œæˆ‘å»ºè­°å¤§å®¶åœ¨è™•ç†{request.topic}ç›¸é—œå•é¡Œæ™‚ï¼Œè¦è¨˜ä½é€™å¹¾å€‹è¦é»...

ğŸ¯ çµå°¾ ({request.duration-10}-{request.duration}ç§’)
ç¸½çµä¾†èªªï¼Œ{request.topic}ç¢ºå¯¦å€¼å¾—æˆ‘å€‘æ·±å…¥äº†è§£ã€‚å¸Œæœ›ä»Šå¤©çš„åˆ†äº«å°ä½ æœ‰å¹«åŠ©ï¼Œå¦‚æœå–œæ­¡é€™å€‹å…§å®¹ï¼Œè¨˜å¾—é»è®šè¨‚é–±ï¼Œæˆ‘å€‘ä¸‹æ¬¡è¦‹ï¼

#è¨˜å¾—æ ¹æ“šå¯¦éš›å…§å®¹èª¿æ•´æ™‚é–“åˆ†é…å’Œè©³ç´°ç¨‹åº¦#
"""
        generation_source = "template"
    
    # ä¼°ç®—æ™‚é•· (å‡è¨­æ¯åˆ†é˜150å€‹ä¸­æ–‡å­—)
    word_count = len(script_content)
    estimated_duration = round((word_count / 150) * 60)
    
    return {
        "success": True,
        "data": {
            "script": script_content,
            "word_count": word_count,
            "estimated_duration_seconds": estimated_duration,
            "platform": request.platform,
            "style": request.style,
            "language": request.language,
            "generation_source": generation_source,
            "generated_at": datetime.utcnow().isoformat(),
        }
    }

# èªéŸ³åˆæˆç«¯é»  
@app.post("/api/v1/generate/voice")
async def generate_voice(request: VoiceGenerationRequest):
    """ä½¿ç”¨OpenAI TTSç”ŸæˆèªéŸ³"""
    logger.info(f"Generating voice for text: {request.text[:50]}...")
    
    if not OPENAI_API_KEY or len(OPENAI_API_KEY) < 10:
        logger.warning("OpenAI API key not configured, using placeholder")
        return await generate_voice_placeholder(request)
    
    try:
        # æº–å‚™OpenAI TTSè«‹æ±‚
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # æ˜ å°„èªè¨€
        voice_mapping = {
            "zh-TW": request.voice_id,  # ä½¿ç”¨æŒ‡å®šçš„è²éŸ³
            "zh-CN": request.voice_id,
            "en-US": request.voice_id,
        }
        
        data = {
            "model": "tts-1",
            "input": request.text,
            "voice": voice_mapping.get(request.language, request.voice_id),
            "speed": request.speed
        }
        
        # èª¿ç”¨OpenAI TTS API
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.openai.com/v1/audio/speech",
                json=data,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=60)
            ) as response:
                if response.status == 200:
                    # ä¿å­˜éŸ³é »æ–‡ä»¶
                    import tempfile
                    import base64
                    
                    audio_data = await response.read()
                    
                    # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
                    temp_file = tempfile.NamedTemporaryFile(
                        delete=False, 
                        suffix=".mp3",
                        dir="./uploads/dev" if os.path.exists("./uploads/dev") else None
                    )
                    temp_file.write(audio_data)
                    temp_file.close()
                    
                    # ä¼°ç®—æ™‚é•·
                    char_count = len(request.text)
                    estimated_duration = round((char_count / 200) * 60, 1)
                    
                    return {
                        "success": True,
                        "data": {
                            "audio_url": f"/static/{os.path.basename(temp_file.name)}",
                            "audio_file": temp_file.name,
                            "text": request.text,
                            "voice_id": request.voice_id,
                            "language": request.language,
                            "speed": request.speed,
                            "duration_seconds": estimated_duration,
                            "character_count": char_count,
                            "generation_source": "openai_tts",
                            "generated_at": datetime.utcnow().isoformat(),
                        }
                    }
                else:
                    error_text = await response.text()
                    logger.error(f"OpenAI TTS API error: {error_text}")
                    return await generate_voice_placeholder(request)
                    
    except Exception as e:
        logger.error(f"Voice generation failed: {e}")
        return await generate_voice_placeholder(request)

async def generate_voice_placeholder(request: VoiceGenerationRequest):
    """èªéŸ³ç”Ÿæˆçš„Placeholderå¯¦ç¾"""
    char_count = len(request.text)
    estimated_duration = round((char_count / 200) * 60, 1)
    
    return {
        "success": True,
        "data": {
            "audio_url": "#",  # Placeholder - å¯¦éš›æ‡‰è©²æ˜¯éŸ³é »æ–‡ä»¶URL
            "text": request.text,
            "voice_id": request.voice_id,
            "language": request.language,
            "speed": request.speed,
            "duration_seconds": estimated_duration,
            "character_count": char_count,
            "generation_source": "placeholder",
            "generated_at": datetime.utcnow().isoformat(),
            "note": "Voice synthesis requires valid OpenAI API key"
        }
    }

# åœ–ç‰‡ç”Ÿæˆç«¯é»
@app.post("/api/v1/generate/image")
async def generate_image(request: ImageGenerationRequest):
    """ç”Ÿæˆåœ–ç‰‡ (ç›®å‰ä½¿ç”¨é«˜å“è³ªplaceholder)"""
    logger.info(f"Generating image for prompt: {request.prompt}")
    
    try:
        # å¦‚æœæœ‰DALL-E APIé‡‘é‘°ï¼Œå¯ä»¥èª¿ç”¨çœŸå¯¦API
        if OPENAI_API_KEY and len(OPENAI_API_KEY) > 10:
            # TODO: å¯¦ç¾DALL-E APIèª¿ç”¨
            pass
        
        # ä½¿ç”¨é«˜å“è³ªplaceholder
        prompt_hash = hashlib.md5(request.prompt.encode()).hexdigest()[:8]
        seed = int(prompt_hash, 16) % 1000
        width, height = request.resolution.split("x")
        
        images = []
        for i in range(request.quantity):
            image_url = f"https://picsum.photos/{width}/{height}?random={seed + i}"
            images.append({
                "url": image_url,
                "prompt": request.prompt,
                "style": request.style,
                "resolution": request.resolution,
                "seed": seed + i,
            })
        
        return {
            "success": True,
            "data": {
                "images": images,
                "prompt": request.prompt,
                "style": request.style,
                "resolution": request.resolution,
                "quantity": request.quantity,
                "generation_source": "placeholder",
                "generated_at": datetime.utcnow().isoformat(),
                "note": "Using high-quality placeholder images. Integrate DALL-E for production."
            }
        }
        
    except Exception as e:
        logger.error(f"Image generation error: {e}")
        raise HTTPException(status_code=500, detail=f"Image generation failed: {str(e)}")

# éŸ³æ¨‚ç”Ÿæˆç«¯é»
@app.post("/api/v1/generate/music") 
async def generate_music(request: MusicGenerationRequest):
    """ç”ŸæˆèƒŒæ™¯éŸ³æ¨‚ (placeholderå¯¦ç¾)"""
    logger.info(f"Generating music for prompt: {request.prompt}")
    
    return {
        "success": True,
        "data": {
            "audio_url": "#",  # PlaceholderéŸ³æ¨‚URL
            "prompt": request.prompt,
            "style": request.style, 
            "duration": request.duration,
            "mood": request.mood,
            "generation_source": "placeholder",
            "generated_at": datetime.utcnow().isoformat(),
            "note": "Music generation requires Suno AI or similar service integration"
        }
    }

# æ‰¹é‡ç”Ÿæˆç«¯é»
@app.post("/api/v1/generate/batch")
async def generate_batch(
    script_request: Optional[ScriptGenerationRequest] = None,
    image_request: Optional[ImageGenerationRequest] = None,
    voice_request: Optional[VoiceGenerationRequest] = None,
    music_request: Optional[MusicGenerationRequest] = None,
):
    """æ‰¹é‡ç”Ÿæˆå¤šç¨®å…§å®¹"""
    logger.info("Starting batch generation")
    
    results = {}
    
    try:
        if script_request:
            script_result = await generate_script(script_request)
            results["script"] = script_result["data"]
            
        if image_request:
            image_result = await generate_image(image_request)
            results["images"] = image_result["data"]
            
        if voice_request:
            voice_result = await generate_voice(voice_request)
            results["voice"] = voice_result["data"]
            
        if music_request:
            music_result = await generate_music(music_request)
            results["music"] = music_result["data"]
        
        return {
            "success": True,
            "data": results,
            "generated_at": datetime.utcnow().isoformat(),
            "batch_id": f"batch_{int(datetime.utcnow().timestamp())}",
        }
        
    except Exception as e:
        logger.error(f"Batch generation error: {e}")
        raise HTTPException(status_code=500, detail=f"Batch generation failed: {str(e)}")

if __name__ == "__main__":
    print("ğŸ¤– Starting AI Service (Simplified)...")
    print("ğŸ”§ Features:")
    print("   - Script Generation (DeepSeek/OpenAI)")
    print("   - Voice Synthesis (OpenAI TTS)")  
    print("   - Image Generation (Placeholder)")
    print("   - Music Generation (Placeholder)")
    print(f"   - Docs: http://localhost:8005/docs")
    print(f"   - Health: http://localhost:8005/health")
    
    print("\nğŸ”‘ API Keys Status:")
    print(f"   - OpenAI: {'âœ…' if OPENAI_API_KEY and len(OPENAI_API_KEY) > 10 else 'âŒ'}")
    print(f"   - DeepSeek: {'âœ…' if DEEPSEEK_API_KEY and len(DEEPSEEK_API_KEY) > 10 else 'âŒ'}")
    print(f"   - Gemini: {'âœ…' if GEMINI_API_KEY and len(GEMINI_API_KEY) > 10 else 'âŒ'}")
    
    if not any([
        OPENAI_API_KEY and len(OPENAI_API_KEY) > 10,
        DEEPSEEK_API_KEY and len(DEEPSEEK_API_KEY) > 10
    ]):
        print("\nâš ï¸  Warning: No valid API keys configured. Using placeholder responses.")
        print("   è«‹åœ¨ .env.local ä¸­é…ç½®çœŸå¯¦çš„APIé‡‘é‘°ä»¥å•Ÿç”¨å®Œæ•´åŠŸèƒ½")
    
    uvicorn.run(
        "main_simple:app",
        host="0.0.0.0",
        port=8005,
        reload=True,
        log_level="info",
    )