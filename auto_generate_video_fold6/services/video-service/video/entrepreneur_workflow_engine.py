"""
å‰µæ¥­è€…æ¨¡å¼è‡ªå‹•å½±ç‰‡ç”Ÿæˆå·¥ä½œæµç¨‹å¼•æ“
å°ˆç‚ºå‰µæ¥­è€…è‡ªå‹•åŒ–å…§å®¹ç”Ÿæˆå’Œç²åˆ©å„ªåŒ–è¨­è¨ˆ

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è‡ªå‹•è¶¨å‹¢åˆ†æå’Œé—œéµå­—é¸æ“‡
2. è…³æœ¬ç”Ÿæˆå’Œå…§å®¹æœ€ä½³åŒ–
3. å¤šåª’é«”è³‡ç”¢ç”Ÿæˆï¼ˆåœ–åƒã€èªéŸ³ã€å½±ç‰‡ï¼‰
4. å¹³å°å„ªåŒ–å’Œè‡ªå‹•ç™¼å¸ƒ
5. æˆæœ¬æ§åˆ¶å’Œ ROI è¿½è¹¤
"""

import asyncio
import uuid
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


class WorkflowStage(Enum):
    """å·¥ä½œæµç¨‹éšæ®µæšèˆ‰"""

    INITIALIZATION = "initialization"
    TREND_ANALYSIS = "trend_analysis"
    KEYWORD_SELECTION = "keyword_selection"
    SCRIPT_GENERATION = "script_generation"
    ASSET_GENERATION = "asset_generation"
    VIDEO_COMPOSITION = "video_composition"
    PLATFORM_OPTIMIZATION = "platform_optimization"
    PUBLISHING = "publishing"
    ANALYTICS_TRACKING = "analytics_tracking"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class WorkflowStatus(Enum):
    """å·¥ä½œæµç¨‹ç‹€æ…‹æšèˆ‰"""

    PENDING = "pending"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class EntrepreneurWorkflowConfig:
    """å‰µæ¥­è€…å·¥ä½œæµç¨‹é…ç½®"""

    # å…§å®¹è¨­å®š
    daily_video_count: int = 3
    target_categories: List[str] = field(
        default_factory=lambda: ["technology", "entertainment", "lifestyle"]
    )
    target_platforms: List[str] = field(
        default_factory=lambda: ["tiktok", "youtube-shorts"]
    )
    video_duration: int = 30  # ç§’
    language: str = "zh-TW"

    # å“è³ªæ§åˆ¶
    min_trend_score: float = 0.7
    content_quality_threshold: float = 0.8
    monetization_threshold: float = 0.6

    # æˆæœ¬æ§åˆ¶
    daily_budget: float = 10.0
    cost_per_video_limit: float = 5.0
    stop_on_budget_exceeded: bool = True

    # æ™‚é–“æ§åˆ¶
    operating_hours: Dict[str, str] = field(
        default_factory=lambda: {"start": "09:00", "end": "18:00"}
    )
    max_workflow_duration: int = 1800  # 30åˆ†é˜

    # ç™¼å¸ƒè¨­å®š
    auto_publish: bool = False
    scheduled_publishing: bool = True
    optimal_publishing_times: List[str] = field(
        default_factory=lambda: ["10:00", "14:00", "18:00"]
    )

    # é€²éšè¨­å®š
    retry_attempts: int = 3
    parallel_workflows: int = 2
    quality_check_enabled: bool = True


@dataclass
class WorkflowMetrics:
    """å·¥ä½œæµç¨‹æŒ‡æ¨™"""

    start_time: datetime = field(default_factory=datetime.utcnow)
    end_time: Optional[datetime] = None
    total_duration: Optional[timedelta] = None
    stage_durations: Dict[str, float] = field(default_factory=dict)
    cost_breakdown: Dict[str, float] = field(default_factory=dict)
    total_cost: float = 0.0
    success_rate: float = 0.0
    quality_score: float = 0.0
    monetization_potential: float = 0.0


@dataclass
class GeneratedAssets:
    """ç”Ÿæˆçš„è³‡ç”¢"""

    script: Optional[str] = None
    images: List[str] = field(default_factory=list)
    audio_file: Optional[str] = None
    video_file: Optional[str] = None
    thumbnail: Optional[str] = None
    captions: Optional[str] = None
    hashtags: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class EntrepreneurWorkflowRequest:
    """å‰µæ¥­è€…å·¥ä½œæµç¨‹è«‹æ±‚"""

    user_id: str
    workflow_type: str = "entrepreneur_auto"
    config: EntrepreneurWorkflowConfig = field(
        default_factory=EntrepreneurWorkflowConfig
    )
    priority: int = 1  # 1=é«˜, 2=ä¸­, 3=ä½
    tags: List[str] = field(default_factory=list)
    custom_requirements: Dict[str, Any] = field(default_factory=dict)


@dataclass
class EntrepreneurWorkflowResult:
    """å‰µæ¥­è€…å·¥ä½œæµç¨‹çµæœ"""

    workflow_id: str
    request: EntrepreneurWorkflowRequest
    status: WorkflowStatus = WorkflowStatus.PENDING
    current_stage: WorkflowStage = WorkflowStage.INITIALIZATION
    progress_percentage: int = 0
    estimated_completion: Optional[datetime] = None
    generated_assets: GeneratedAssets = field(default_factory=GeneratedAssets)
    metrics: WorkflowMetrics = field(default_factory=WorkflowMetrics)
    error_message: Optional[str] = None
    stage_outputs: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)


class EntrepreneurWorkflowEngine:
    """å‰µæ¥­è€…æ¨¡å¼å·¥ä½œæµç¨‹å¼•æ“"""

    def __init__(self):
        self.workflows: Dict[str, EntrepreneurWorkflowResult] = {}
        self.running_workflows: Dict[str, asyncio.Task] = {}
        self.stage_handlers: Dict[WorkflowStage, Callable] = {}
        self.daily_stats = {
            "videos_generated": 0,
            "total_cost": 0.0,
            "success_count": 0,
            "failure_count": 0,
        }

        # è¨»å†Šéšæ®µè™•ç†å™¨
        self._register_stage_handlers()

        logger.info("å‰µæ¥­è€…å·¥ä½œæµç¨‹å¼•æ“å·²åˆå§‹åŒ–")

    def _register_stage_handlers(self):
        """è¨»å†Šå„éšæ®µè™•ç†å™¨"""
        self.stage_handlers = {
            WorkflowStage.INITIALIZATION: self._handle_initialization,
            WorkflowStage.TREND_ANALYSIS: self._handle_trend_analysis,
            WorkflowStage.KEYWORD_SELECTION: self._handle_keyword_selection,
            WorkflowStage.SCRIPT_GENERATION: self._handle_script_generation,
            WorkflowStage.ASSET_GENERATION: self._handle_asset_generation,
            WorkflowStage.VIDEO_COMPOSITION: self._handle_video_composition,
            WorkflowStage.PLATFORM_OPTIMIZATION: self._handle_platform_optimization,
            WorkflowStage.PUBLISHING: self._handle_publishing,
            WorkflowStage.ANALYTICS_TRACKING: self._handle_analytics_tracking,
        }

    async def create_workflow(
        self, request: EntrepreneurWorkflowRequest
    ) -> str:
        """å‰µå»ºæ–°çš„å·¥ä½œæµç¨‹"""
        try:
            workflow_id = str(uuid.uuid4())

            # é ä¼°å®Œæˆæ™‚é–“
            estimated_duration = request.config.max_workflow_duration
            estimated_completion = datetime.utcnow() + timedelta(
                seconds=estimated_duration
            )

            result = EntrepreneurWorkflowResult(
                workflow_id=workflow_id,
                request=request,
                estimated_completion=estimated_completion,
            )

            self.workflows[workflow_id] = result

            logger.info(f"å‰µå»ºå‰µæ¥­è€…å·¥ä½œæµç¨‹: {workflow_id}")

            return workflow_id

        except Exception as e:
            logger.error(f"å‰µå»ºå·¥ä½œæµç¨‹å¤±æ•—: {e}")
            raise

    async def execute_workflow(self, workflow_id: str) -> None:
        """åŸ·è¡Œå·¥ä½œæµç¨‹ï¼ˆç•°æ­¥ï¼‰"""
        if workflow_id not in self.workflows:
            raise ValueError(f"å·¥ä½œæµç¨‹ä¸å­˜åœ¨: {workflow_id}")

        # æª¢æŸ¥æ˜¯å¦å·²åœ¨åŸ·è¡Œ
        if workflow_id in self.running_workflows:
            logger.warning(f"å·¥ä½œæµç¨‹å·²åœ¨åŸ·è¡Œä¸­: {workflow_id}")
            return

        # å‰µå»ºç•°æ­¥ä»»å‹™
        task = asyncio.create_task(self._execute_workflow_async(workflow_id))
        self.running_workflows[workflow_id] = task

        try:
            await task
        finally:
            # æ¸…ç†åŸ·è¡Œä¸­çš„ä»»å‹™
            if workflow_id in self.running_workflows:
                del self.running_workflows[workflow_id]

    async def _execute_workflow_async(self, workflow_id: str) -> None:
        """ç•°æ­¥åŸ·è¡Œå·¥ä½œæµç¨‹"""
        result = self.workflows[workflow_id]

        try:
            result.status = WorkflowStatus.RUNNING
            result.metrics.start_time = datetime.utcnow()

            # åŸ·è¡Œå„å€‹éšæ®µ
            stages = [
                WorkflowStage.INITIALIZATION,
                WorkflowStage.TREND_ANALYSIS,
                WorkflowStage.KEYWORD_SELECTION,
                WorkflowStage.SCRIPT_GENERATION,
                WorkflowStage.ASSET_GENERATION,
                WorkflowStage.VIDEO_COMPOSITION,
                WorkflowStage.PLATFORM_OPTIMIZATION,
            ]

            # æ ¹æ“šé…ç½®æ±ºå®šæ˜¯å¦åŒ…å«ç™¼å¸ƒéšæ®µ
            if result.request.config.auto_publish:
                stages.append(WorkflowStage.PUBLISHING)

            stages.append(WorkflowStage.ANALYTICS_TRACKING)

            total_stages = len(stages)

            for i, stage in enumerate(stages):
                result.current_stage = stage
                result.progress_percentage = int((i / total_stages) * 100)
                result.updated_at = datetime.utcnow()

                logger.info(
                    f"åŸ·è¡Œéšæ®µ {stage.value} - å·¥ä½œæµç¨‹: {workflow_id}"
                )

                stage_start_time = datetime.utcnow()

                # åŸ·è¡Œéšæ®µè™•ç†å™¨
                if stage in self.stage_handlers:
                    await self.stage_handlers[stage](result)
                else:
                    logger.warning(f"æœªæ‰¾åˆ°éšæ®µè™•ç†å™¨: {stage.value}")

                # è¨˜éŒ„éšæ®µåŸ·è¡Œæ™‚é–“
                stage_duration = (
                    datetime.utcnow() - stage_start_time
                ).total_seconds()
                result.metrics.stage_durations[stage.value] = stage_duration

                # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                if result.status == WorkflowStatus.CANCELLED:
                    logger.info(f"å·¥ä½œæµç¨‹å·²è¢«å–æ¶ˆ: {workflow_id}")
                    return

                # æª¢æŸ¥é ç®—é™åˆ¶
                if result.request.config.stop_on_budget_exceeded:
                    if (
                        result.metrics.total_cost
                        > result.request.config.daily_budget
                    ):
                        result.status = WorkflowStatus.FAILED
                        result.error_message = "è¶…å‡ºé ç®—é™åˆ¶"
                        logger.warning(f"å·¥ä½œæµç¨‹è¶…å‡ºé ç®—: {workflow_id}")
                        return

            # å·¥ä½œæµç¨‹å®Œæˆ
            result.status = WorkflowStatus.COMPLETED
            result.current_stage = WorkflowStage.COMPLETED
            result.progress_percentage = 100
            result.metrics.end_time = datetime.utcnow()
            result.metrics.total_duration = (
                result.metrics.end_time - result.metrics.start_time
            )

            # æ›´æ–°çµ±è¨ˆ
            self.daily_stats["videos_generated"] += 1
            self.daily_stats["total_cost"] += result.metrics.total_cost
            self.daily_stats["success_count"] += 1

            logger.info(f"å·¥ä½œæµç¨‹å®Œæˆ: {workflow_id}")

        except Exception as e:
            result.status = WorkflowStatus.FAILED
            result.current_stage = WorkflowStage.FAILED
            result.error_message = str(e)
            result.metrics.end_time = datetime.utcnow()

            self.daily_stats["failure_count"] += 1

            logger.error(f"å·¥ä½œæµç¨‹åŸ·è¡Œå¤±æ•—: {workflow_id} - {e}")

    async def _handle_initialization(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†åˆå§‹åŒ–éšæ®µ"""
        try:
            # é©—è­‰é…ç½®
            config = result.request.config

            # æª¢æŸ¥æ¯æ—¥é™åˆ¶
            if (
                self.daily_stats["videos_generated"]
                >= config.daily_video_count
            ):
                raise Exception("å·²é”æ¯æ—¥å½±ç‰‡ç”Ÿæˆé™åˆ¶")

            # æª¢æŸ¥é ç®—
            if self.daily_stats["total_cost"] >= config.daily_budget:
                raise Exception("å·²é”æ¯æ—¥é ç®—é™åˆ¶")

            # åˆå§‹åŒ–è³‡ç”¢çµæ§‹
            result.generated_assets = GeneratedAssets()

            # è¨˜éŒ„åˆå§‹åŒ–ä¿¡æ¯
            result.stage_outputs["initialization"] = {
                "config_validated": True,
                "daily_quota_available": config.daily_video_count
                - self.daily_stats["videos_generated"],
                "budget_remaining": config.daily_budget
                - self.daily_stats["total_cost"],
                "timestamp": datetime.utcnow().isoformat(),
            }

            logger.info(f"åˆå§‹åŒ–å®Œæˆ - å·¥ä½œæµç¨‹: {result.workflow_id}")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–éšæ®µå¤±æ•—: {e}")
            raise

    async def _handle_trend_analysis(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†è¶¨å‹¢åˆ†æéšæ®µ"""
        try:
            # æ¨¡æ“¬è¶¨å‹¢åˆ†æ API èª¿ç”¨
            await asyncio.sleep(2)  # æ¨¡æ“¬ API å»¶é²

            # æ¨¡æ“¬ç²å–ç†±é–€è¶¨å‹¢
            trending_topics = [
                {
                    "keyword": "AI è‡ªå‹•åŒ–å·¥å…·",
                    "category": "technology",
                    "trend_score": 0.85,
                    "monetization_potential": 0.9,
                    "competition_level": "medium",
                },
                {
                    "keyword": "çŸ­å½±éŸ³å‰µä½œæŠ€å·§",
                    "category": "entertainment",
                    "trend_score": 0.78,
                    "monetization_potential": 0.85,
                    "competition_level": "low",
                },
                {
                    "keyword": "å±…å®¶å·¥ä½œæ•ˆç‡",
                    "category": "lifestyle",
                    "trend_score": 0.72,
                    "monetization_potential": 0.7,
                    "competition_level": "medium",
                },
            ]

            # ç¯©é¸ç¬¦åˆæ¢ä»¶çš„è¶¨å‹¢
            qualified_trends = [
                trend
                for trend in trending_topics
                if trend["trend_score"]
                >= result.request.config.min_trend_score
                and trend["monetization_potential"]
                >= result.request.config.monetization_threshold
            ]

            result.stage_outputs["trend_analysis"] = {
                "total_trends_analyzed": len(trending_topics),
                "qualified_trends": qualified_trends,
                "analysis_timestamp": datetime.utcnow().isoformat(),
            }

            # ä¼°ç®—æˆæœ¬
            api_cost = 0.002  # $0.002 for trend analysis API
            result.metrics.cost_breakdown["trend_analysis"] = api_cost
            result.metrics.total_cost += api_cost

            logger.info(
                f"è¶¨å‹¢åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(qualified_trends)} å€‹åˆæ ¼è¶¨å‹¢"
            )

        except Exception as e:
            logger.error(f"è¶¨å‹¢åˆ†æéšæ®µå¤±æ•—: {e}")
            raise

    async def _handle_keyword_selection(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†é—œéµå­—é¸æ“‡éšæ®µ"""
        try:
            qualified_trends = result.stage_outputs["trend_analysis"][
                "qualified_trends"
            ]

            if not qualified_trends:
                raise Exception("æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è¶¨å‹¢é—œéµå­—")

            # é¸æ“‡æœ€ä½³é—œéµå­—ï¼ˆæŒ‰ç²åˆ©æ½›åŠ›æ’åºï¼‰
            selected_trend = max(
                qualified_trends, key=lambda x: x["monetization_potential"]
            )

            result.stage_outputs["keyword_selection"] = {
                "selected_keyword": selected_trend["keyword"],
                "selected_category": selected_trend["category"],
                "trend_score": selected_trend["trend_score"],
                "monetization_potential": selected_trend[
                    "monetization_potential"
                ],
                "competition_level": selected_trend["competition_level"],
                "selection_timestamp": datetime.utcnow().isoformat(),
            }

            result.metrics.monetization_potential = selected_trend[
                "monetization_potential"
            ]

            logger.info(f"é¸æ“‡é—œéµå­—: {selected_trend['keyword']}")

        except Exception as e:
            logger.error(f"é—œéµå­—é¸æ“‡éšæ®µå¤±æ•—: {e}")
            raise

    async def _handle_script_generation(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†è…³æœ¬ç”Ÿæˆéšæ®µ"""
        try:
            keyword_data = result.stage_outputs["keyword_selection"]
            keyword = keyword_data["selected_keyword"]
            category = keyword_data["selected_category"]

            # æ¨¡æ“¬ AI è…³æœ¬ç”Ÿæˆ
            await asyncio.sleep(3)  # æ¨¡æ“¬ AI API å»¶é²

            # ç”Ÿæˆè…³æœ¬å…§å®¹
            script_templates = {
                "technology": f"ğŸ”¥ {keyword} \
                    æ­£åœ¨ç§‘æŠ€ç•Œæ€èµ·é©å‘½ï¼æƒ³çŸ¥é“å®ƒå¦‚ä½•æ”¹è®Šæˆ‘å€‘çš„æœªä¾†å—ï¼Ÿé€™å€‹è¦–é »å°‡å¸¶ä½ æ·±å…¥äº†è§£æœ€æ–°æŠ€è¡“è¶¨å‹¢ï¼Œè®“ä½ èµ°åœ¨æ™‚ä»£å‰ç«¯ï¼",
                "entertainment": f"âœ¨ æœ€æ–°ç†±é–€è©±é¡Œ {keyword} \
                    ä¾†äº†ï¼å¤§å®¶éƒ½åœ¨è¨è«–çš„å…§å®¹ï¼Œä½ é‚„æ²’è·Ÿä¸Šå—ï¼Ÿè®“æˆ‘å€‘ä¸€èµ·æ¢ç´¢é€™å€‹å¼•çˆ†å…¨ç¶²çš„ç²¾å½©å…§å®¹ï¼",
                "lifestyle": f"ğŸŒŸ {keyword} \
                    æ­£åœ¨æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ï¼æƒ³è¦æå‡ç”Ÿæ´»å“è³ªå—ï¼Ÿé€™äº›å¯¦ç”¨æŠ€å·§å’Œå»ºè­°ï¼Œçµ•å°è®“ä½ çš„æ—¥å¸¸æ›´åŠ ç²¾å½©ï¼",
            }

            script = script_templates.get(
                category, f"æ¢ç´¢ {keyword} çš„å¥§ç§˜ï¼Œç™¼ç¾æ›´å¤šç²¾å½©å…§å®¹ï¼"
            )

            # ç”Ÿæˆç›¸é—œæ¨™ç±¤
            hashtags = [
                f"#{keyword.replace(' ', '')}",
                f"#{category}",
                "#ç†±é–€è¶‹åŠ¿",
                "#å¿…çœ‹å†…å®¹",
                "#æ¶¨çŸ¥è¯†",
            ]

            result.generated_assets.script = script
            result.generated_assets.hashtags = hashtags

            result.stage_outputs["script_generation"] = {
                "script_length": len(script),
                "hashtags_count": len(hashtags),
                "quality_score": 0.85,  # æ¨¡æ“¬å“è³ªåˆ†æ•¸
                "generation_timestamp": datetime.utcnow().isoformat(),
            }

            # ä¼°ç®—æˆæœ¬ï¼ˆåŸºæ–¼ tokensï¼‰
            estimated_tokens = len(script) // 4  # ç²—ç•¥ä¼°ç®—
            script_cost = estimated_tokens * 0.000002  # GPT-3.5 pricing
            result.metrics.cost_breakdown["script_generation"] = script_cost
            result.metrics.total_cost += script_cost

            result.metrics.quality_score = 0.85

            logger.info(f"è…³æœ¬ç”Ÿæˆå®Œæˆï¼Œé•·åº¦: {len(script)} å­—ç¬¦")

        except Exception as e:
            logger.error(f"è…³æœ¬ç”Ÿæˆéšæ®µå¤±æ•—: {e}")
            raise

    async def _handle_asset_generation(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†è³‡ç”¢ç”Ÿæˆéšæ®µï¼ˆåœ–åƒã€èªéŸ³ï¼‰"""
        try:
            keyword_data = result.stage_outputs["keyword_selection"]
            keyword = keyword_data["selected_keyword"]

            # æ¨¡æ“¬ä¸¦è¡Œç”Ÿæˆåœ–åƒå’ŒèªéŸ³
            image_task = self._generate_images(keyword, result)
            audio_task = self._generate_audio(
                result.generated_assets.script, result
            )

            await asyncio.gather(image_task, audio_task)

            result.stage_outputs["asset_generation"] = {
                "images_generated": len(result.generated_assets.images),
                "audio_generated": result.generated_assets.audio_file
                is not None,
                "generation_timestamp": datetime.utcnow().isoformat(),
            }

            logger.info("å¤šåª’é«”è³‡ç”¢ç”Ÿæˆå®Œæˆ")

        except Exception as e:
            logger.error(f"è³‡ç”¢ç”Ÿæˆéšæ®µå¤±æ•—: {e}")
            raise

    async def _generate_images(
        self, keyword: str, result: EntrepreneurWorkflowResult
    ) -> None:
        """ç”Ÿæˆåœ–åƒè³‡ç”¢"""
        try:
            # æ¨¡æ“¬åœ–åƒç”Ÿæˆ API
            await asyncio.sleep(5)  # æ¨¡æ“¬ç”Ÿæˆæ™‚é–“

            # ç”Ÿæˆ 3 å¼µåœ–åƒ
            images = []
            for i in range(3):
                image_url = f"https://generated-images.example \
                    .com/{keyword}_{i + 1}_{result.workflow_id}.jpg"
                images.append(image_url)

            result.generated_assets.images = images

            # ä¼°ç®—åœ–åƒç”Ÿæˆæˆæœ¬
            image_cost = 3 * 0.04  # Stable Diffusion ä¼°ç®—åƒ¹æ ¼
            result.metrics.cost_breakdown["image_generation"] = image_cost
            result.metrics.total_cost += image_cost

            logger.info(f"ç”Ÿæˆ {len(images)} å¼µåœ–åƒ")

        except Exception as e:
            logger.error(f"åœ–åƒç”Ÿæˆå¤±æ•—: {e}")
            raise

    async def _generate_audio(
        self, script: str, result: EntrepreneurWorkflowResult
    ) -> None:
        """ç”ŸæˆèªéŸ³è³‡ç”¢"""
        try:
            # æ¨¡æ“¬èªéŸ³åˆæˆ API
            await asyncio.sleep(4)  # æ¨¡æ“¬ç”Ÿæˆæ™‚é–“

            audio_url = f"https://generated-audio.example \
                .com/audio_{result.workflow_id}.mp3"
            result.generated_assets.audio_file = audio_url

            # ä¼°ç®—èªéŸ³åˆæˆæˆæœ¬
            character_count = len(script)
            audio_cost = character_count * 0.000015  # ElevenLabs ä¼°ç®—åƒ¹æ ¼
            result.metrics.cost_breakdown["audio_generation"] = audio_cost
            result.metrics.total_cost += audio_cost

            logger.info(f"ç”ŸæˆèªéŸ³æª”æ¡ˆï¼Œå­—ç¬¦æ•¸: {character_count}")

        except Exception as e:
            logger.error(f"èªéŸ³ç”Ÿæˆå¤±æ•—: {e}")
            raise

    async def _handle_video_composition(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†å½±ç‰‡åˆæˆéšæ®µ"""
        try:
            # æ¨¡æ“¬å½±ç‰‡åˆæˆ
            await asyncio.sleep(6)  # æ¨¡æ“¬åˆæˆæ™‚é–“

            video_url = f"https://generated-videos.example \
                .com/video_{result.workflow_id}.mp4"
            thumbnail_url = f"https://generated-videos.example \
                .com/thumb_{result.workflow_id}.jpg"

            result.generated_assets.video_file = video_url
            result.generated_assets.thumbnail = thumbnail_url

            # ç”Ÿæˆå­—å¹•
            result.generated_assets.captions = result.generated_assets.script

            result.stage_outputs["video_composition"] = {
                "video_duration": result.request.config.video_duration,
                "video_url": video_url,
                "thumbnail_url": thumbnail_url,
                "composition_timestamp": datetime.utcnow().isoformat(),
            }

            # ä¼°ç®—å½±ç‰‡è™•ç†æˆæœ¬
            video_cost = 0.05  # å½±ç‰‡è™•ç†ä¼°ç®—æˆæœ¬
            result.metrics.cost_breakdown["video_composition"] = video_cost
            result.metrics.total_cost += video_cost

            logger.info("å½±ç‰‡åˆæˆå®Œæˆ")

        except Exception as e:
            logger.error(f"å½±ç‰‡åˆæˆéšæ®µå¤±æ•—: {e}")
            raise

    async def _handle_platform_optimization(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†å¹³å°å„ªåŒ–éšæ®µ"""
        try:
            platforms = result.request.config.target_platforms

            platform_optimizations = {}

            for platform in platforms:
                optimization = await self._optimize_for_platform(
                    platform, result
                )
                platform_optimizations[platform] = optimization

            result.stage_outputs["platform_optimization"] = {
                "optimized_platforms": list(platforms),
                "optimizations": platform_optimizations,
                "optimization_timestamp": datetime.utcnow().isoformat(),
            }

            logger.info(f"å¹³å°å„ªåŒ–å®Œæˆï¼Œè¦†è“‹ {len(platforms)} å€‹å¹³å°")

        except Exception as e:
            logger.error(f"å¹³å°å„ªåŒ–éšæ®µå¤±æ•—: {e}")
            raise

    async def _optimize_for_platform(
        self, platform: str, result: EntrepreneurWorkflowResult
    ) -> Dict[str, Any]:
        """ç‚ºç‰¹å®šå¹³å°å„ªåŒ–å…§å®¹"""

        platform_specs = {
            "tiktok": {
                "aspect_ratio": "9:16",
                "max_duration": 60,
                "hashtag_limit": 10,
                "title_length": 150,
            },
            "youtube-shorts": {
                "aspect_ratio": "9:16",
                "max_duration": 60,
                "hashtag_limit": 15,
                "title_length": 100,
            },
            "instagram-reels": {
                "aspect_ratio": "9:16",
                "max_duration": 90,
                "hashtag_limit": 30,
                "title_length": 125,
            },
        }

        specs = platform_specs.get(platform, platform_specs["tiktok"])

        # èª¿æ•´æ¨™é¡Œå’Œæ¨™ç±¤
        keyword_data = result.stage_outputs["keyword_selection"]
        title = f"{keyword_data['selected_keyword']} - å¿…çœ‹è¶¨å‹¢è§£æ"

        hashtags = result.generated_assets.hashtags[: specs["hashtag_limit"]]

        return {
            "platform": platform,
            "title": title[: specs["title_length"]],
            "hashtags": hashtags,
            "aspect_ratio": specs["aspect_ratio"],
            "duration": min(
                result.request.config.video_duration, specs["max_duration"]
            ),
        }

    async def _handle_publishing(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†ç™¼å¸ƒéšæ®µ"""
        if not result.request.config.auto_publish:
            return

        try:
            platforms = result.request.config.target_platforms
            published_platforms = []

            for platform in platforms:
                # æ¨¡æ“¬ç™¼å¸ƒ API èª¿ç”¨
                await asyncio.sleep(2)

                # æ¨¡æ“¬ç™¼å¸ƒæˆåŠŸ
                published_platforms.append(platform)
                logger.info(f"æˆåŠŸç™¼å¸ƒåˆ° {platform}")

            result.stage_outputs["publishing"] = {
                "published_platforms": published_platforms,
                "publishing_timestamp": datetime.utcnow().isoformat(),
                "auto_published": True,
            }

        except Exception as e:
            logger.error(f"ç™¼å¸ƒéšæ®µå¤±æ•—: {e}")
            # ç™¼å¸ƒå¤±æ•—ä¸å½±éŸ¿æ•´å€‹å·¥ä½œæµç¨‹
            result.stage_outputs["publishing"] = {
                "published_platforms": [],
                "error": str(e),
                "auto_published": False,
            }

    async def _handle_analytics_tracking(
        self, result: EntrepreneurWorkflowResult
    ) -> None:
        """è™•ç†åˆ†æè¿½è¹¤éšæ®µ"""
        try:
            # è¨­ç½®åˆ†æè¿½è¹¤
            tracking_data = {
                "workflow_id": result.workflow_id,
                "keyword": result.stage_outputs["keyword_selection"][
                    "selected_keyword"
                ],
                "platforms": result.request.config.target_platforms,
                "tracking_start": datetime.utcnow().isoformat(),
                "metrics_to_track": [
                    "views",
                    "likes",
                    "shares",
                    "comments",
                    "ctr",
                    "revenue",
                ],
            }

            result.stage_outputs["analytics_tracking"] = tracking_data

            logger.info("åˆ†æè¿½è¹¤è¨­ç½®å®Œæˆ")

        except Exception as e:
            logger.error(f"åˆ†æè¿½è¹¤éšæ®µå¤±æ•—: {e}")
            raise

    def get_workflow_status(
        self, workflow_id: str
    ) -> Optional[EntrepreneurWorkflowResult]:
        """ç²å–å·¥ä½œæµç¨‹ç‹€æ…‹"""
        return self.workflows.get(workflow_id)

    def get_daily_stats(self) -> Dict[str, Any]:
        """ç²å–æ¯æ—¥çµ±è¨ˆ"""
        return {
            **self.daily_stats,
            "success_rate": (
                self.daily_stats["success_count"]
                / max(
                    self.daily_stats["success_count"]
                    + self.daily_stats["failure_count"],
                    1,
                )
            )
            * 100,
            "average_cost_per_video": (
                self.daily_stats["total_cost"]
                / max(self.daily_stats["videos_generated"], 1)
            ),
            "last_updated": datetime.utcnow().isoformat(),
        }

    async def cancel_workflow(self, workflow_id: str) -> bool:
        """å–æ¶ˆå·¥ä½œæµç¨‹"""
        if workflow_id not in self.workflows:
            return False

        result = self.workflows[workflow_id]
        result.status = WorkflowStatus.CANCELLED
        result.updated_at = datetime.utcnow()

        # å–æ¶ˆåŸ·è¡Œä¸­çš„ä»»å‹™
        if workflow_id in self.running_workflows:
            task = self.running_workflows[workflow_id]
            task.cancel()
            del self.running_workflows[workflow_id]

        logger.info(f"å·¥ä½œæµç¨‹å·²å–æ¶ˆ: {workflow_id}")
        return True

    def cleanup_completed_workflows(self, max_age_hours: int = 24) -> int:
        """æ¸…ç†å·²å®Œæˆçš„å·¥ä½œæµç¨‹"""
        cutoff_time = datetime.utcnow() - timedelta(hours=max_age_hours)

        workflows_to_remove = [
            workflow_id
            for workflow_id, result in self.workflows.items()
            if result.status
            in [
                WorkflowStatus.COMPLETED,
                WorkflowStatus.FAILED,
                WorkflowStatus.CANCELLED,
            ]
            and result.updated_at < cutoff_time
        ]

        for workflow_id in workflows_to_remove:
            del self.workflows[workflow_id]

        logger.info(f"æ¸…ç†äº† {len(workflows_to_remove)} å€‹èˆŠå·¥ä½œæµç¨‹")
        return len(workflows_to_remove)
