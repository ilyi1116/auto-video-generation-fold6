#!/usr/bin/env python3
"""
è‡ªå‹• Google Trends é—œéµå­—æ¡é›†ä¸¦ç”ŸæˆçŸ­å½±éŸ³è…³æœ¬
æ•´åˆé—œéµå­—æ¡é›†èˆ‡å½±ç‰‡ç”Ÿæˆçš„å®Œæ•´è‡ªå‹•åŒ–æµç¨‹
æ”¯æ´çµ±ä¸€é…ç½®ç®¡ç†èˆ‡å›ºå®šæ•¸é‡é™åˆ¶
"""

import asyncio
import logging
import argparse
import json
from datetime import datetime, timedelta
from pathlib import Path
import aiohttp
import os
import sys

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from config.config_manager import config_manager, get_config
    CONFIG_MANAGER_AVAILABLE = True
except ImportError:
    CONFIG_MANAGER_AVAILABLE = False
    logging.warning("çµ±ä¸€é…ç½®ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨èˆŠç‰ˆé…ç½®æ–¹å¼")

try:
    from monitoring.cost_tracker import get_cost_tracker
    from monitoring.budget_controller import get_budget_controller
    COST_MONITORING_AVAILABLE = True
except ImportError:
    COST_MONITORING_AVAILABLE = False
    logging.warning("æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨")

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AutoTrendsVideoGenerator:
    """è‡ªå‹•è¶¨å‹¢å½±ç‰‡ç”Ÿæˆå™¨"""
    
    def __init__(self, config_file: str = None, mode: str = None):
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        if CONFIG_MANAGER_AVAILABLE:
            if mode:
                config_manager.set_mode(mode)
            self.config = self._load_unified_config()
            logger.info(f"ä½¿ç”¨çµ±ä¸€é…ç½®ç®¡ç†å™¨ï¼Œç•¶å‰æ¨¡å¼: {config_manager.current_mode}")
        else:
            self.config = self._load_legacy_config(config_file)
            logger.info("ä½¿ç”¨å‚³çµ±é…ç½®æ–¹å¼")
        
        # è¨­ç½®æœå‹™ URL
        self.services = self._setup_services()
        
        # è¨­ç½®è¼¸å‡ºç›®éŒ„
        self.output_dir = Path(self.config.get('output_dir', './generated_videos'))
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å½±ç‰‡ç”Ÿæˆè¨­å®š
        self.video_configs = self._setup_video_configs()
        
        # æˆæœ¬æ§åˆ¶èˆ‡é™åˆ¶
        self.cost_tracker = {
            'daily_cost': 0.0,
            'videos_generated_today': 0,
            'api_calls_count': {},
            'generation_start_time': datetime.now()
        }
        
        # å·¥ä½œæ™‚é–“æª¢æŸ¥
        self.work_hours_enabled = self._is_work_hours_enabled()
        
        # åˆå§‹åŒ–æˆæœ¬ç›£æ§
        if COST_MONITORING_AVAILABLE:
            self.cost_tracker = get_cost_tracker(config_manager if CONFIG_MANAGER_AVAILABLE else None)
            self.budget_controller = get_budget_controller(config_manager if CONFIG_MANAGER_AVAILABLE else None)
            logger.info("æˆæœ¬ç›£æ§ç³»çµ±å·²å•Ÿç”¨")
        else:
            self.cost_tracker = None
            self.budget_controller = None
        
        logger.info(f"å½±ç‰‡ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¯æ—¥é™åˆ¶: {self.video_configs['max_videos_per_run']}")
        
    def _setup_services(self) -> dict:
        """è¨­ç½®æœå‹™é…ç½®"""
        if CONFIG_MANAGER_AVAILABLE:
            return {
                'trend_service': get_config('services.trend_service.url', 'http://localhost:8001'),
                'video_service': get_config('services.video_service.url', 'http://localhost:8002'),
                'ai_service': get_config('services.ai_service.url', 'http://localhost:8003'),
                'social_service': get_config('services.social_service.url', 'http://localhost:8004')
            }
        else:
            return {
                'trend_service': self.config.get('trend_service_url', 'http://localhost:8001'),
                'video_service': self.config.get('video_service_url', 'http://localhost:8002'),
                'ai_service': self.config.get('ai_service_url', 'http://localhost:8003')
            }
            
    def _setup_video_configs(self) -> dict:
        """è¨­ç½®å½±ç‰‡ç”Ÿæˆé…ç½®"""
        if CONFIG_MANAGER_AVAILABLE:
            generation_config = get_config('generation', {})
            return {
                'max_videos_per_run': generation_config.get('daily_video_limit', 5),
                'batch_size': generation_config.get('batch_size', 1),
                'max_concurrent_jobs': generation_config.get('max_concurrent_jobs', 2),
                'video_duration': generation_config.get('duration_range', [30, 60])[0],  # å–æœ€å°å€¼
                'platforms': generation_config.get('platforms', ['tiktok']),
                'categories': get_config('content.content_categories', ['technology', 'entertainment', 'lifestyle']),
                'languages': [get_config('content.language', 'zh-TW')],
                'quality_preset': generation_config.get('quality_preset', 'medium')
            }
        else:
            return {
                'max_videos_per_run': self.config.get('max_videos_per_run', 5),
                'batch_size': 1,
                'max_concurrent_jobs': 2,
                'video_duration': self.config.get('video_duration', 30),
                'platforms': self.config.get('target_platforms', ['tiktok']),
                'categories': self.config.get('categories', ['technology', 'entertainment']),
                'languages': self.config.get('languages', ['zh-TW']),
                'quality_preset': 'medium'
            }
            
    def _is_work_hours_enabled(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦å•Ÿç”¨å·¥ä½œæ™‚é–“é™åˆ¶"""
        if CONFIG_MANAGER_AVAILABLE:
            return get_config('scheduling.work_hours.start') is not None
        return False
        
    def _load_unified_config(self) -> dict:
        """è¼‰å…¥çµ±ä¸€é…ç½®"""
        return {
            'output_dir': get_config('storage.output_dir', './generated_videos'),
            'quality_threshold': get_config('generation.quality_threshold', 0.7),
            'schedule_interval': 1800,  # é»˜èª30åˆ†é˜
            'daily_budget': get_config('cost_control.daily_budget_usd', 50.0),
            'stop_on_budget_exceeded': get_config('cost_control.stop_on_budget_exceeded', True)
        }
    
    def _load_legacy_config(self, config_file: str) -> dict:
        """è¼‰å…¥é…ç½®æª”æ¡ˆ"""
        default_config = {
            'trend_service_url': 'http://localhost:8001',
            'video_service_url': 'http://localhost:8002',
            'ai_service_url': 'http://localhost:8003',
            'output_dir': './generated_videos',
            'max_videos_per_run': 5,
            'video_duration': 30,
            'target_platforms': ['tiktok'],
            'categories': ['technology', 'entertainment', 'lifestyle'],
            'languages': ['zh-TW'],
            'schedule_interval': 1800,  # 30åˆ†é˜
            'quality_threshold': 0.7
        }
        
        if config_file and os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                logger.warning(f"è¼‰å…¥é…ç½®æª”æ¡ˆå¤±æ•—ï¼Œä½¿ç”¨é è¨­é…ç½®: {e}")
        
        return default_config
    
    async def run_auto_generation(self):
        """åŸ·è¡Œè‡ªå‹•ç”Ÿæˆæµç¨‹"""
        try:
            logger.info("ğŸš€ é–‹å§‹è‡ªå‹•è¶¨å‹¢å½±ç‰‡ç”Ÿæˆæµç¨‹")
            
            # å‰ç½®æª¢æŸ¥
            if not await self._pre_generation_checks():
                return
            
            # 1. ç²å–ç†±é–€é—œéµå­—
            trending_keywords = await self._fetch_trending_keywords()
            
            if not trending_keywords:
                logger.warning("æœªæ‰¾åˆ°ç†±é–€é—œéµå­—ï¼Œè·³éæ­¤æ¬¡ç”Ÿæˆ")
                return
            
            logger.info(f"æ‰¾åˆ° {len(trending_keywords)} å€‹ç†±é–€é—œéµå­—")
            
            # 2. é¸æ“‡æœ€ä½³é—œéµå­—
            selected_keywords = await self._select_best_keywords(trending_keywords)
            
            logger.info(f"é¸æ“‡äº† {len(selected_keywords)} å€‹é—œéµå­—é€²è¡Œå½±ç‰‡ç”Ÿæˆ")
            
            # 3. æ‰¹æ¬¡ç”Ÿæˆå½±ç‰‡
            generation_results = await self._batch_generate_videos(selected_keywords)
            
            # 4. è™•ç†çµæœ
            await self._process_results(generation_results)
            
            logger.info("âœ… è‡ªå‹•ç”Ÿæˆæµç¨‹å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è‡ªå‹•ç”Ÿæˆæµç¨‹å¤±æ•—: {e}")
            raise
    
    async def _pre_generation_checks(self) -> bool:
        """åŸ·è¡Œç”Ÿæˆå‰æª¢æŸ¥"""
        try:
            # 1. æª¢æŸ¥å·¥ä½œæ™‚é–“
            if self.work_hours_enabled and CONFIG_MANAGER_AVAILABLE:
                if not config_manager.is_within_work_hours():
                    logger.info("ç›®å‰ä¸åœ¨å·¥ä½œæ™‚é–“å…§ï¼Œè·³éç”Ÿæˆ")
                    return False
            
            # 2. æª¢æŸ¥é ç®—ç‹€æ…‹ (ä½¿ç”¨æ–°çš„é ç®—æ§åˆ¶å™¨)
            if COST_MONITORING_AVAILABLE and self.budget_controller:
                estimated_cost = self._estimate_batch_cost()
                can_proceed, message = await self.budget_controller.pre_operation_check("batch_generation", estimated_cost)
                if not can_proceed:
                    logger.info(f"é ç®—æª¢æŸ¥å¤±æ•—: {message}")
                    return False
                logger.info(f"é ç®—æª¢æŸ¥é€šé: {message}")
            else:
                # èˆŠç‰ˆé ç®—æª¢æŸ¥
                if CONFIG_MANAGER_AVAILABLE:
                    daily_budget = get_config('cost_control.daily_budget_usd', 50.0)
                    if self.cost_tracker['daily_cost'] >= daily_budget:
                        logger.info(f"å·²é”æ¯æ—¥é ç®—é™åˆ¶ (${daily_budget})ï¼Œè·³éç”Ÿæˆ")
                        return False
            
            # 3. æª¢æŸ¥æ¯æ—¥é™åˆ¶
            if CONFIG_MANAGER_AVAILABLE:
                daily_limit = get_config('generation.daily_video_limit', 5)
                if self.cost_tracker['videos_generated_today'] >= daily_limit:
                    logger.info(f"å·²é”æ¯æ—¥å½±ç‰‡é™åˆ¶ ({daily_limit})ï¼Œè·³éç”Ÿæˆ")
                    return False
            
            # 4. æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹
            if not await self._check_services_health():
                logger.warning("æœå‹™å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œè·³éç”Ÿæˆ")
                return False
            
            logger.info("æ‰€æœ‰å‰ç½®æª¢æŸ¥é€šé")
            return True
            
        except Exception as e:
            logger.error(f"å‰ç½®æª¢æŸ¥å¤±æ•—: {e}")
            return False

    def _estimate_batch_cost(self) -> float:
        """ä¼°ç®—æ‰¹æ¬¡ç”Ÿæˆæˆæœ¬"""
        try:
            # åŸºæ–¼é…ç½®ä¼°ç®—æˆæœ¬
            if CONFIG_MANAGER_AVAILABLE:
                batch_size = get_config('generation.batch_size', 1)
                max_videos = get_config('generation.daily_video_limit', 5)
                
                # æ¯å€‹å½±ç‰‡çš„ä¼°ç®—æˆæœ¬
                # æ–‡å­—ç”Ÿæˆ (è…³æœ¬): ~500 tokens * $0.002/1k = $0.001
                # åœ–ç‰‡ç”Ÿæˆ: 2-3å¼µ * $0.04 = $0.08-0.12
                # èªéŸ³åˆæˆ: ~300å­— * $0.00003 = $0.009
                # ç¸½è¨ˆç´„ $0.09-0.13 æ¯å€‹å½±ç‰‡
                
                estimated_per_video = 0.11  # ä¿å®ˆä¼°è¨ˆ
                planned_videos = min(batch_size, max_videos - self.cost_tracker['videos_generated_today'])
                
                return max(0, planned_videos * estimated_per_video)
            else:
                return 0.5  # é è¨­ä¼°ç®—
                
        except Exception as e:
            logger.error(f"æˆæœ¬ä¼°ç®—å¤±æ•—: {e}")
            return 1.0  # ä¿å®ˆé è¨­å€¼
    
    async def _check_services_health(self) -> bool:
        """æª¢æŸ¥æœå‹™å¥åº·ç‹€æ…‹"""
        try:
            healthy_services = 0
            required_services = ['trend_service', 'ai_service', 'video_service']
            
            for service_name in required_services:
                service_url = self.services.get(service_name)
                if not service_url:
                    continue
                    
                try:
                    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                        health_url = f"{service_url}/health"
                        async with session.get(health_url) as resp:
                            if resp.status == 200:
                                healthy_services += 1
                                logger.debug(f"{service_name} å¥åº·ç‹€æ…‹æ­£å¸¸")
                            else:
                                logger.warning(f"{service_name} å¥åº·æª¢æŸ¥å¤±æ•—: {resp.status}")
                                
                except Exception as e:
                    logger.warning(f"{service_name} é€£æ¥å¤±æ•—: {e}")
            
            # è‡³å°‘éœ€è¦2å€‹æœå‹™æ­£å¸¸é‹è¡Œ
            if healthy_services >= 2:
                logger.info(f"æœå‹™å¥åº·æª¢æŸ¥é€šé ({healthy_services}/{len(required_services)})")
                return True
            else:
                logger.error(f"æœå‹™å¥åº·æª¢æŸ¥å¤±æ•— ({healthy_services}/{len(required_services)})")
                return False
                
        except Exception as e:
            logger.error(f"æœå‹™å¥åº·æª¢æŸ¥ç•°å¸¸: {e}")
            return False
    
    async def _fetch_trending_keywords(self) -> list:
        """ç²å–ç†±é–€é—œéµå­—"""
        try:
            all_keywords = []
            
            # å¾å¤šå€‹é¡åˆ¥ç²å–é—œéµå­—
            for category in self.video_configs['categories']:
                async with aiohttp.ClientSession() as session:
                    url = f"{self.services['trend_service']}/api/trends/keywords"
                    params = {
                        'category': category,
                        'geo': 'TW'
                    }
                    
                    async with session.get(url, params=params) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                            keywords = data.get('keywords', [])
                            logger.info(f"å¾ {category} é¡åˆ¥ç²å–åˆ° {len(keywords)} å€‹é—œéµå­—")
                            all_keywords.extend(keywords)
                        else:
                            logger.warning(f"ç²å– {category} é¡åˆ¥é—œéµå­—å¤±æ•—: {resp.status}")
            
            return all_keywords
            
        except Exception as e:
            logger.error(f"ç²å–ç†±é–€é—œéµå­—å¤±æ•—: {e}")
            return []
    
    async def _select_best_keywords(self, keywords: list) -> list:
        """é¸æ“‡æœ€ä½³é—œéµå­—"""
        try:
            # æŒ‰ç†±åº¦å’Œé©åˆåº¦æ’åº
            scored_keywords = []
            
            for keyword in keywords:
                score = await self._calculate_keyword_score(keyword)
                if score >= self.config.get('quality_threshold', 0.7):
                    scored_keywords.append({
                        **keyword,
                        'score': score
                    })
            
            # æŒ‰åˆ†æ•¸æ’åº
            scored_keywords.sort(key=lambda x: x['score'], reverse=True)
            
            # é¸æ“‡å‰Nå€‹
            max_videos = self.video_configs['max_videos_per_run']
            selected = scored_keywords[:max_videos]
            
            logger.info(f"é¸æ“‡çš„é—œéµå­—: {[k['keyword'] for k in selected]}")
            
            return selected
            
        except Exception as e:
            logger.error(f"é¸æ“‡é—œéµå­—å¤±æ•—: {e}")
            return keywords[:self.video_configs['max_videos_per_run']]
    
    async def _calculate_keyword_score(self, keyword_data: dict) -> float:
        """è¨ˆç®—é—œéµå­—åˆ†æ•¸"""
        try:
            # åŸºç¤åˆ†æ•¸ï¼šæ ¹æ“šæµé‡
            traffic_score = min(keyword_data.get('traffic', 0) / 100, 1.0)
            
            # é¡åˆ¥åŠ æ¬Š
            category_weights = {
                'technology': 0.9,
                'entertainment': 1.0,
                'lifestyle': 0.8,
                'sports': 0.7,
                'business': 0.6
            }
            category = keyword_data.get('category', 'lifestyle')
            category_score = category_weights.get(category, 0.5)
            
            # é—œéµå­—é•·åº¦æ‡²ç½°ï¼ˆå¤ªé•·çš„é—œéµå­—ä¸é©åˆçŸ­å½±éŸ³ï¼‰
            keyword_length = len(keyword_data.get('keyword', ''))
            length_score = 1.0 if keyword_length <= 20 else 0.7
            
            # æ™‚æ•ˆæ€§åŠ æ¬Šï¼ˆè¶Šæ–°çš„è¶¨å‹¢åˆ†æ•¸è¶Šé«˜ï¼‰
            time_score = 1.0  # é»˜èªæœ€æ–°
            
            # ç¶œåˆè©•åˆ†
            final_score = traffic_score * 0.4 + category_score * 0.3 + length_score * 0.2 + time_score * 0.1
            
            return final_score
            
        except Exception as e:
            logger.error(f"è¨ˆç®—é—œéµå­—åˆ†æ•¸å¤±æ•—: {e}")
            return 0.5
    
    async def _batch_generate_videos(self, keywords: list) -> list:
        """æ‰¹æ¬¡ç”Ÿæˆå½±ç‰‡ï¼ˆæ”¯æ´æ‰¹æ¬¡å¤§å°é™åˆ¶ï¼‰"""
        try:
            logger.info(f"é–‹å§‹æ‰¹æ¬¡ç”Ÿæˆ {len(keywords)} å€‹å½±ç‰‡")
            
            # ç²å–ä½µç™¼é™åˆ¶
            max_concurrent = self.video_configs.get('max_concurrent_jobs', 2)
            batch_size = self.video_configs.get('batch_size', 1)
            
            results = []
            
            # åˆ†æ‰¹è™•ç†
            for i in range(0, len(keywords), batch_size):
                batch = keywords[i:i + batch_size]
                logger.info(f"è™•ç†æ‰¹æ¬¡ {i//batch_size + 1}, åŒ…å« {len(batch)} å€‹é—œéµå­—")
                
                # æª¢æŸ¥æ˜¯å¦é”åˆ°æ¯æ—¥é™åˆ¶
                if CONFIG_MANAGER_AVAILABLE:
                    daily_limit = get_config('generation.daily_video_limit', 5)
                    if self.cost_tracker['videos_generated_today'] >= daily_limit:
                        logger.info(f"å·²é”æ¯æ—¥é™åˆ¶ ({daily_limit})ï¼Œåœæ­¢ç”Ÿæˆ")
                        break
                
                # æª¢æŸ¥é ç®—é™åˆ¶
                if CONFIG_MANAGER_AVAILABLE:
                    daily_budget = get_config('cost_control.daily_budget_usd', 50.0)
                    stop_on_budget = get_config('cost_control.stop_on_budget_exceeded', True)
                    if stop_on_budget and self.cost_tracker['daily_cost'] >= daily_budget:
                        logger.info(f"å·²é”é ç®—é™åˆ¶ (${daily_budget})ï¼Œåœæ­¢ç”Ÿæˆ")
                        break
                
                # æ‰¹æ¬¡å…§ä¸¦è¡Œè™•ç†
                tasks = []
                for keyword_data in batch:
                    task = self._generate_single_video(keyword_data)
                    tasks.append(task)
                
                # é™åˆ¶ä¸¦è¡Œæ•¸é‡
                semaphore = asyncio.Semaphore(max_concurrent)
                
                async def bounded_task(task):
                    async with semaphore:
                        return await task
                
                batch_results = await asyncio.gather(
                    *[bounded_task(task) for task in tasks],
                    return_exceptions=True
                )
                
                results.extend(batch_results)
                
                # æ›´æ–°æˆæœ¬è¿½è¹¤
                successful_count = sum(1 for r in batch_results 
                                     if isinstance(r, dict) and r.get('status') == 'success')
                self.cost_tracker['videos_generated_today'] += successful_count
                
                # æ‰¹æ¬¡é–“é–“éš”
                if i + batch_size < len(keywords):
                    await asyncio.sleep(2)  # 2ç§’é–“éš”
            
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹æ¬¡ç”Ÿæˆå½±ç‰‡å¤±æ•—: {e}")
            return []
    
    async def _generate_single_video(self, keyword_data: dict) -> dict:
        """ç”Ÿæˆå–®å€‹å½±ç‰‡"""
        try:
            keyword = keyword_data['keyword']
            logger.info(f"é–‹å§‹ç”Ÿæˆé—œéµå­— '{keyword}' çš„å½±ç‰‡")
            
            # 1. ç”Ÿæˆè…³æœ¬
            script = await self._generate_script(keyword_data)
            
            # 2. æº–å‚™å½±ç‰‡ç”Ÿæˆè«‹æ±‚
            video_request = {
                'keyword': keyword,
                'category': keyword_data.get('category', 'trending'),
                'script': script,
                'style': 'tiktok',
                'duration': self.video_configs['video_duration'],
                'language': self.video_configs['languages'][0],
                'platforms': self.video_configs['platforms']
            }
            
            # 3. å‘¼å«å½±ç‰‡ç”Ÿæˆæœå‹™
            async with aiohttp.ClientSession() as session:
                url = f"{self.services['video_service']}/api/videos/generate-short"
                
                async with session.post(url, json=video_request) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        logger.info(f"å½±ç‰‡ '{keyword}' ç”ŸæˆæˆåŠŸ")
                        
                        # 4. å„²å­˜çµæœ
                        await self._save_video_result(keyword, result)
                        
                        # 5. è¿½è¹¤å½±ç‰‡ç”Ÿæˆæˆæœ¬ (åœ–ç‰‡+å½±ç‰‡è™•ç†)
                        if COST_MONITORING_AVAILABLE and self.cost_tracker:
                            # åœ–ç‰‡ç”Ÿæˆæˆæœ¬
                            await self.cost_tracker.track_api_call(
                                provider="stability_ai",
                                model="stable-diffusion-xl",
                                operation_type="image_generation",
                                images_generated=3,  # ä¼°ç®—ç”Ÿæˆ3å¼µåœ–ç‰‡
                                request_id=f"images_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                                success=True,
                                metadata={"keyword": keyword, "video_duration": self.video_configs['video_duration']}
                            )
                            
                            # èªéŸ³åˆæˆæˆæœ¬ (å‡è¨­è…³æœ¬ç´„300å­—)
                            await self.cost_tracker.track_api_call(
                                provider="elevenlabs",
                                model="voice_synthesis",
                                operation_type="voice_synthesis",
                                characters_used=300,
                                request_id=f"voice_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                                success=True,
                                metadata={"keyword": keyword, "language": self.video_configs['languages'][0]}
                            )
                        
                        return {
                            'keyword': keyword,
                            'status': 'success',
                            'result': result
                        }
                    else:
                        error_msg = f"å½±ç‰‡ç”Ÿæˆå¤±æ•—: {resp.status}"
                        logger.error(error_msg)
                        return {
                            'keyword': keyword,
                            'status': 'error',
                            'error': error_msg
                        }
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå½±ç‰‡ '{keyword_data.get('keyword')}' å¤±æ•—: {e}")
            return {
                'keyword': keyword_data.get('keyword'),
                'status': 'error',
                'error': str(e)
            }
    
    async def _generate_script(self, keyword_data: dict) -> str:
        """ç”Ÿæˆå½±ç‰‡è…³æœ¬"""
        try:
            keyword = keyword_data['keyword']
            category = keyword_data.get('category', 'trending')
            
            # å‘¼å« AI æœå‹™ç”Ÿæˆè…³æœ¬
            async with aiohttp.ClientSession() as session:
                url = f"{self.services['ai_service']}/api/script/generate"
                payload = {
                    'keyword': keyword,
                    'category': category,
                    'style': 'short_video',
                    'platform': 'tiktok',
                    'duration': self.video_configs['video_duration'],
                    'language': self.video_configs['languages'][0]
                }
                
                async with session.post(url, json=payload) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        
                        # è¿½è¹¤ API æˆæœ¬
                        if COST_MONITORING_AVAILABLE and self.cost_tracker:
                            await self.cost_tracker.track_api_call(
                                provider="openai",
                                model="gpt-3.5-turbo",
                                operation_type="text_generation",
                                tokens_used=500,  # ä¼°ç®—å€¼
                                request_id=f"script_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                                success=True,
                                metadata={"keyword": keyword, "category": category}
                            )
                        
                        return result.get('script', f"æ¢ç´¢ {keyword} çš„ç²¾å½©ä¸–ç•Œï¼é€™å€‹è©±é¡Œæ­£åœ¨çˆ†ç´…ä¸­...")
                    else:
                        # è¿½è¹¤å¤±æ•—çš„ API å‘¼å«
                        if COST_MONITORING_AVAILABLE and self.cost_tracker:
                            await self.cost_tracker.track_api_call(
                                provider="openai",
                                model="gpt-3.5-turbo", 
                                operation_type="text_generation",
                                tokens_used=0,
                                success=False,
                                metadata={"keyword": keyword, "error": f"HTTP {resp.status}"}
                            )
                        
                        # å‚™ç”¨è…³æœ¬
                        return self._generate_fallback_script(keyword, category)
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆè…³æœ¬å¤±æ•—: {e}")
            return self._generate_fallback_script(keyword_data['keyword'], keyword_data.get('category'))
    
    def _generate_fallback_script(self, keyword: str, category: str) -> str:
        """ç”Ÿæˆå‚™ç”¨è…³æœ¬"""
        templates = {
            'technology': f"ğŸ”¥ {keyword} æ­£åœ¨ç§‘æŠ€ç•Œå¼•èµ·è½Ÿå‹•ï¼ä½ çŸ¥é“å®ƒç‚ºä»€éº¼é€™éº¼ç†±é–€å—ï¼Ÿè®“æˆ‘å€‘ä¸€èµ·æ¢ç´¢é€™å€‹ä»¤äººèˆˆå¥®çš„æ–°è¶¨å‹¢ï¼",
            'entertainment': f"âœ¨ {keyword} æˆç‚ºæœ€æ–°å¨›æ¨‚ç†±é»ï¼å¤§å®¶éƒ½åœ¨è¨è«–ï¼Œä½ é‚„æ²’è·Ÿä¸Šå—ï¼Ÿå¿«ä¾†çœ‹çœ‹ç‚ºä»€éº¼å®ƒé€™éº¼ç«ç´…ï¼",
            'lifestyle': f"ğŸŒŸ {keyword} æ­£åœ¨æ”¹è®Šæˆ‘å€‘çš„ç”Ÿæ´»æ–¹å¼ï¼æƒ³çŸ¥é“å¦‚ä½•è·Ÿä¸Šé€™å€‹è¶¨å‹¢å—ï¼Ÿè®“æˆ‘å‘Šè¨´ä½ æ‰€æœ‰çš„ç²¾å½©ç´°ç¯€ï¼",
            'default': f"ğŸ”¥ {keyword} æ­£åœ¨ç¶²è·¯ä¸Šçˆ†ç´…ï¼æƒ³çŸ¥é“ç‚ºä»€éº¼å¤§å®¶éƒ½åœ¨è«‡è«–å®ƒå—ï¼Ÿä¸€èµ·ä¾†æ¢ç´¢é€™å€‹ç†±é–€è©±é¡Œçš„å¥§ç§˜ï¼"
        }
        
        return templates.get(category, templates['default'])
    
    async def _save_video_result(self, keyword: str, result: dict):
        """å„²å­˜å½±ç‰‡çµæœ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_file = self.output_dir / f"{keyword}_{timestamp}_result.json"
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"å½±ç‰‡çµæœå·²å„²å­˜è‡³: {result_file}")
            
        except Exception as e:
            logger.error(f"å„²å­˜å½±ç‰‡çµæœå¤±æ•—: {e}")
    
    async def _process_results(self, results: list):
        """è™•ç†ç”Ÿæˆçµæœ"""
        try:
            successful = [r for r in results if isinstance(r, dict) and r.get('status') == 'success']
            failed = [r for r in results if isinstance(r, dict) and r.get('status') == 'error']
            exceptions = [r for r in results if isinstance(r, Exception)]
            
            logger.info(f"ç”Ÿæˆçµæœçµ±è¨ˆ:")
            logger.info(f"  æˆåŠŸ: {len(successful)}")
            logger.info(f"  å¤±æ•—: {len(failed)}")
            logger.info(f"  ç•°å¸¸: {len(exceptions)}")
            
            # å„²å­˜ç¸½çµå ±å‘Š
            summary = {
                'timestamp': datetime.now().isoformat(),
                'total_attempted': len(results),
                'successful': len(successful),
                'failed': len(failed),
                'exceptions': len(exceptions),
                'success_rate': len(successful) / len(results) if results else 0,
                'successful_keywords': [r['keyword'] for r in successful],
                'failed_keywords': [r['keyword'] for r in failed if 'keyword' in r]
            }
            
            summary_file = self.output_dir / f"generation_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ç”Ÿæˆç¸½çµå·²å„²å­˜è‡³: {summary_file}")
            
        except Exception as e:
            logger.error(f"è™•ç†çµæœå¤±æ•—: {e}")
    
    async def start_scheduler(self):
        """å•Ÿå‹•æ™ºèƒ½æ’ç¨‹å™¨"""
        try:
            interval = self.config.get('schedule_interval', 1800)  # 30åˆ†é˜
            logger.info(f"å•Ÿå‹•è‡ªå‹•æ’ç¨‹å™¨ï¼Œé–“éš”: {interval} ç§’")
            
            while True:
                try:
                    # é‡ç½®æ¯æ—¥è¨ˆæ•¸å™¨ï¼ˆå¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼‰
                    self._reset_daily_counters_if_needed()
                    
                    # æª¢æŸ¥å·¥ä½œæ™‚é–“
                    if self.work_hours_enabled and CONFIG_MANAGER_AVAILABLE:
                        if not config_manager.is_within_work_hours():
                            logger.info("ä¸åœ¨å·¥ä½œæ™‚é–“å…§ï¼Œç­‰å¾…ä¸‹æ¬¡æª¢æŸ¥...")
                            await asyncio.sleep(300)  # 5åˆ†é˜å¾Œå†æª¢æŸ¥
                            continue
                    
                    # åŸ·è¡Œç”Ÿæˆ
                    await self.run_auto_generation()
                    
                except Exception as e:
                    logger.error(f"æ’ç¨‹åŸ·è¡Œå¤±æ•—: {e}")
                
                logger.info(f"ç­‰å¾… {interval} ç§’å¾Œé€²è¡Œä¸‹æ¬¡åŸ·è¡Œ...")
                await asyncio.sleep(interval)
                
        except KeyboardInterrupt:
            logger.info("æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œåœæ­¢æ’ç¨‹å™¨")
        except Exception as e:
            logger.error(f"æ’ç¨‹å™¨éŒ¯èª¤: {e}")
    
    def _reset_daily_counters_if_needed(self):
        """å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®æ¯æ—¥è¨ˆæ•¸å™¨"""
        current_date = datetime.now().date()
        tracker_date = self.cost_tracker['generation_start_time'].date()
        
        if current_date != tracker_date:
            logger.info("æ–°çš„ä¸€å¤©é–‹å§‹ï¼Œé‡ç½®æ¯æ—¥è¨ˆæ•¸å™¨")
            self.cost_tracker.update({
                'daily_cost': 0.0,
                'videos_generated_today': 0,
                'api_calls_count': {},
                'generation_start_time': datetime.now()
            })
    
    def _track_api_cost(self, provider: str, cost: float):
        """è¿½è¹¤ API æˆæœ¬"""
        self.cost_tracker['daily_cost'] += cost
        if provider not in self.cost_tracker['api_calls_count']:
            self.cost_tracker['api_calls_count'][provider] = 0
        self.cost_tracker['api_calls_count'][provider] += 1
        
        logger.debug(f"API æˆæœ¬è¿½è¹¤: {provider} +${cost:.3f}, ä»Šæ—¥ç¸½è¨ˆ: ${self.cost_tracker['daily_cost']:.2f}")
    
    def get_cost_summary(self) -> dict:
        """ç²å–æˆæœ¬æ‘˜è¦"""
        return {
            'daily_cost': self.cost_tracker['daily_cost'],
            'videos_generated_today': self.cost_tracker['videos_generated_today'],
            'api_calls_count': self.cost_tracker['api_calls_count'],
            'daily_budget': self.config.get('daily_budget', 50.0),
            'budget_remaining': max(0, self.config.get('daily_budget', 50.0) - self.cost_tracker['daily_cost']),
            'videos_remaining': max(0, self.video_configs['max_videos_per_run'] - self.cost_tracker['videos_generated_today'])
        }

async def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='è‡ªå‹• Google Trends å½±ç‰‡ç”Ÿæˆå™¨')
    parser.add_argument('--config', '-c', help='é…ç½®æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--mode', '-m', help='é‹è¡Œæ¨¡å¼ (startup/enterprise)')
    parser.add_argument('--schedule', '-s', action='store_true', help='å•Ÿå‹•æ’ç¨‹æ¨¡å¼')
    parser.add_argument('--once', '-o', action='store_true', help='åŸ·è¡Œä¸€æ¬¡ç”Ÿæˆ')
    parser.add_argument('--status', action='store_true', help='é¡¯ç¤ºç•¶å‰ç‹€æ…‹')
    parser.add_argument('--cost-summary', action='store_true', help='é¡¯ç¤ºæˆæœ¬æ‘˜è¦')
    parser.add_argument('--budget-status', action='store_true', help='é¡¯ç¤ºé ç®—ç‹€æ…‹')
    parser.add_argument('--cost-report', action='store_true', help='ç”Ÿæˆæˆæœ¬å ±å‘Š')
    parser.add_argument('--export-costs', type=int, metavar='DAYS', help='åŒ¯å‡ºæŒ‡å®šå¤©æ•¸çš„æˆæœ¬æ•¸æ“š')
    
    args = parser.parse_args()
    
    generator = AutoTrendsVideoGenerator(args.config, args.mode)
    
    if args.status:
        if CONFIG_MANAGER_AVAILABLE:
            summary = config_manager.get_summary()
            print("\n=== ç³»çµ±ç‹€æ…‹ ===")
            for key, value in summary.items():
                print(f"{key}: {value}")
        else:
            print("çµ±ä¸€é…ç½®ç®¡ç†å™¨ä¸å¯ç”¨")
        return
    
    if args.cost_summary:
        cost_summary = generator.get_cost_summary()
        print("\n=== æˆæœ¬æ‘˜è¦ ===")
        for key, value in cost_summary.items():
            print(f"{key}: {value}")
        return
    
    if args.budget_status:
        if COST_MONITORING_AVAILABLE and generator.budget_controller:
            budget_status = await generator.budget_controller.check_budget_status()
            print("\n=== é ç®—ç‹€æ…‹ ===")
            print(f"ç•¶å‰æˆæœ¬: ${budget_status['current_cost']:.4f}")
            print(f"é ç®—é™åˆ¶: ${budget_status['budget_limit']:.2f}")
            print(f"å‰©é¤˜é ç®—: ${budget_status['budget_remaining']:.2f}")
            print(f"ä½¿ç”¨ç‡: {budget_status['usage_percentage']:.1f}%")
            print(f"è¶…å‡ºé ç®—: {'æ˜¯' if budget_status['is_over_budget'] else 'å¦'}")
            print(f"å¯ç¹¼çºŒæ“ä½œ: {'æ˜¯' if budget_status['can_continue'] else 'å¦'}")
        else:
            print("æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨")
        return
    
    if args.cost_report:
        if COST_MONITORING_AVAILABLE and generator.cost_tracker:
            print("\n=== ç”Ÿæˆæˆæœ¬å ±å‘Š ===")
            weekly_report = await generator.cost_tracker.get_weekly_report()
            print(f"å ±å‘ŠæœŸé–“: {weekly_report['period']['start']} è‡³ {weekly_report['period']['end']}")
            print(f"ç¸½æˆæœ¬: ${weekly_report['total_cost']:.4f}")
            print(f"ç¸½ API å‘¼å«: {weekly_report['total_calls']}")
            print(f"å¹³å‡æ—¥æˆæœ¬: ${weekly_report['average_daily_cost']:.4f}")
            
            if weekly_report['daily_stats']:
                print("\næ¯æ—¥çµ±è¨ˆ:")
                for date_str, stats in weekly_report['daily_stats'].items():
                    print(f"  {date_str}: ${stats['cost']:.4f} ({stats['calls']} æ¬¡å‘¼å«)")
        else:
            print("æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨")
        return
    
    if args.export_costs:
        if COST_MONITORING_AVAILABLE and generator.cost_tracker:
            print(f"\n=== åŒ¯å‡º {args.export_costs} å¤©æˆæœ¬æ•¸æ“š ===")
            export_file = await generator.cost_tracker.export_cost_data(args.export_costs)
            print(f"æˆæœ¬æ•¸æ“šå·²åŒ¯å‡ºè‡³: {export_file}")
        else:
            print("æˆæœ¬ç›£æ§ç³»çµ±ä¸å¯ç”¨")
        return
    
    if args.schedule:
        logger.info("å•Ÿå‹•æ’ç¨‹æ¨¡å¼...")
        await generator.start_scheduler()
    elif args.once:
        logger.info("åŸ·è¡Œä¸€æ¬¡ç”Ÿæˆ...")
        await generator.run_auto_generation()
    else:
        print("è«‹æŒ‡å®šé‹è¡Œæ¨¡å¼:")
        print("  --schedule      å•Ÿå‹•æ’ç¨‹æ¨¡å¼")
        print("  --once          åŸ·è¡Œä¸€æ¬¡ç”Ÿæˆ")
        print("  --status        é¡¯ç¤ºç³»çµ±ç‹€æ…‹")
        print("  --cost-summary  é¡¯ç¤ºæˆæœ¬æ‘˜è¦")
        print("  --budget-status é¡¯ç¤ºé ç®—ç‹€æ…‹")
        print("  --cost-report   ç”Ÿæˆæˆæœ¬å ±å‘Š")
        print("  --export-costs DAYS  åŒ¯å‡ºæˆæœ¬æ•¸æ“š")
        parser.print_help()

if __name__ == "__main__":
    asyncio.run(main())