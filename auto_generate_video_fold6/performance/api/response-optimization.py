"""
Auto Video System API å›æ‡‰æ™‚é–“å„ªåŒ–
åŒ…å«å„ç¨®æ•ˆèƒ½å„ªåŒ–æŠ€è¡“å’Œä¸­ä»‹è»Ÿé«”
"""

import time
import gzip
import asyncio
import functools
from typing import Any, Callable, Optional, Dict, List
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request, Response, HTTPException
from fastapi.middleware.base import BaseHTTPMiddleware
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from starlette.responses import JSONResponse
import json
import logging
from datetime import datetime, timedelta
import uuid

logger = logging.getLogger(__name__)


class PerformanceMiddleware(BaseHTTPMiddleware):
    """æ•ˆèƒ½ç›£æ§ä¸­ä»‹è»Ÿé«”"""

    def __init__(self, app, enable_detailed_logging: bool = False):
        super().__init__(app)
        self.enable_detailed_logging = enable_detailed_logging
        self.request_times = []

    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        request_id = str(uuid.uuid4())[:8]

        # æ·»åŠ è«‹æ±‚ ID åˆ°æ¨™é ­
        request.state.request_id = request_id

        # è¨˜éŒ„è«‹æ±‚é–‹å§‹
        if self.enable_detailed_logging:
            logger.info(
                f"[{request_id}] {request.method} {request.url.path} started"
            )

        try:
            response = await call_next(request)

            # è¨ˆç®—è™•ç†æ™‚é–“
            process_time = time.time() - start_time

            # æ·»åŠ æ•ˆèƒ½æ¨™é ­
            response.headers["X-Process-Time"] = str(process_time)
            response.headers["X-Request-ID"] = request_id

            # è¨˜éŒ„è«‹æ±‚å®Œæˆ
            if self.enable_detailed_logging:
                logger.info(
                    f"[{request_id}] {request.method} {request.url.path} "
                    f"completed in {process_time:.3f}s - Status: {response.status_code}"
                )

            # æ”¶é›†æ•ˆèƒ½æ•¸æ“š
            self._collect_metrics(request, response, process_time)

            return response

        except Exception as e:
            process_time = time.time() - start_time
            logger.error(
                f"[{request_id}] {request.method} {request.url.path} "
                f"failed in {process_time:.3f}s - Error: {str(e)}"
            )
            raise

    def _collect_metrics(
        self, request: Request, response: Response, process_time: float
    ):
        """æ”¶é›†æ•ˆèƒ½æŒ‡æ¨™"""
        metric = {
            "method": request.method,
            "path": request.url.path,
            "status_code": response.status_code,
            "process_time": process_time,
            "timestamp": datetime.now().isoformat(),
        }

        # ä¿æŒæœ€è¿‘ 1000 å€‹è«‹æ±‚çš„è¨˜éŒ„
        self.request_times.append(metric)
        if len(self.request_times) > 1000:
            self.request_times.pop(0)


class CompressionMiddleware(BaseHTTPMiddleware):
    """æ™ºæ…§å£“ç¸®ä¸­ä»‹è»Ÿé«”"""

    def __init__(
        self, app, minimum_size: int = 1024, compression_level: int = 6
    ):
        super().__init__(app)
        self.minimum_size = minimum_size
        self.compression_level = compression_level

    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)

        # æª¢æŸ¥æ˜¯å¦éœ€è¦å£“ç¸®
        if not self._should_compress(request, response):
            return response

        # åŸ·è¡Œå£“ç¸®
        return await self._compress_response(response)

    def _should_compress(self, request: Request, response: Response) -> bool:
        """åˆ¤æ–·æ˜¯å¦éœ€è¦å£“ç¸®"""
        # æª¢æŸ¥ Accept-Encoding æ¨™é ­
        accept_encoding = request.headers.get("accept-encoding", "")
        if "gzip" not in accept_encoding:
            return False

        # æª¢æŸ¥ Content-Type
        content_type = response.headers.get("content-type", "")
        compressible_types = [
            "application/json",
            "text/plain",
            "text/html",
            "text/css",
            "application/javascript",
            "text/javascript",
        ]

        return any(ct in content_type for ct in compressible_types)

    async def _compress_response(self, response: Response) -> Response:
        """å£“ç¸®å›æ‡‰"""
        # å–å¾—å›æ‡‰å…§å®¹
        body = b""
        async for chunk in response.body_iterator:
            body += chunk

        # æª¢æŸ¥å…§å®¹å¤§å°
        if len(body) < self.minimum_size:
            return response

        # åŸ·è¡Œ gzip å£“ç¸®
        compressed_body = gzip.compress(
            body, compresslevel=self.compression_level
        )

        # æ›´æ–°æ¨™é ­
        response.headers["content-encoding"] = "gzip"
        response.headers["content-length"] = str(len(compressed_body))

        # å‰µå»ºæ–°çš„å›æ‡‰
        return Response(
            content=compressed_body,
            status_code=response.status_code,
            headers=response.headers,
            media_type=response.media_type,
        )


class CacheMiddleware(BaseHTTPMiddleware):
    """HTTP å¿«å–ä¸­ä»‹è»Ÿé«”"""

    def __init__(self, app, cache_manager=None, default_ttl: int = 300):
        super().__init__(app)
        self.cache_manager = cache_manager
        self.default_ttl = default_ttl

    async def dispatch(self, request: Request, call_next):
        # åªå¿«å– GET è«‹æ±‚
        if request.method != "GET" or not self.cache_manager:
            return await call_next(request)

        # ç”Ÿæˆå¿«å–éµ
        cache_key = self._generate_cache_key(request)

        # å˜—è©¦å¾å¿«å–ç²å–
        cached_response = await self.cache_manager.get(cache_key)
        if cached_response:
            logger.debug(f"Cache hit for {request.url.path}")
            return JSONResponse(
                content=cached_response["content"],
                status_code=cached_response["status_code"],
                headers={
                    **cached_response["headers"],
                    "X-Cache": "HIT",
                    "X-Cache-Key": cache_key[:16],
                },
            )

        # åŸ·è¡Œè«‹æ±‚
        response = await call_next(request)

        # æª¢æŸ¥æ˜¯å¦æ‡‰è©²å¿«å–
        if self._should_cache(request, response):
            await self._cache_response(cache_key, response)
            response.headers["X-Cache"] = "MISS"
            response.headers["X-Cache-Key"] = cache_key[:16]

        return response

    def _generate_cache_key(self, request: Request) -> str:
        """ç”Ÿæˆå¿«å–éµ"""
        import hashlib

        key_parts = [
            request.method,
            str(request.url),
            request.headers.get("accept", ""),
            request.headers.get("accept-language", ""),
        ]

        key_string = ":".join(key_parts)
        return f"http_cache:{hashlib.sha256(key_string.encode()).hexdigest()}"

    def _should_cache(self, request: Request, response: Response) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²å¿«å–"""
        # åªå¿«å–æˆåŠŸçš„å›æ‡‰
        if response.status_code != 200:
            return False

        # æª¢æŸ¥ Cache-Control æ¨™é ­
        cache_control = response.headers.get("cache-control", "")
        if "no-cache" in cache_control or "no-store" in cache_control:
            return False

        # å¯å¿«å–çš„è·¯å¾‘
        cacheable_paths = [
            "/api/trends",
            "/api/user/profile",
            "/api/analytics",
            "/api/models/list",
        ]

        return any(path in request.url.path for path in cacheable_paths)

    async def _cache_response(self, cache_key: str, response: Response):
        """å¿«å–å›æ‡‰"""
        try:
            # è®€å–å›æ‡‰å…§å®¹
            body = b""
            async for chunk in response.body_iterator:
                body += chunk

            # è§£æ JSON å…§å®¹
            content = json.loads(body.decode())

            cache_data = {
                "content": content,
                "status_code": response.status_code,
                "headers": dict(response.headers),
            }

            await self.cache_manager.set(
                cache_key, cache_data, self.default_ttl
            )
            logger.debug(f"Cached response for key {cache_key[:16]}")

        except Exception as e:
            logger.error(f"Failed to cache response: {e}")


class RateLimitMiddleware(BaseHTTPMiddleware):
    """é€Ÿç‡é™åˆ¶ä¸­ä»‹è»Ÿé«”"""

    def __init__(self, app, rate_limiter=None):
        super().__init__(app)
        self.rate_limiter = rate_limiter

    async def dispatch(self, request: Request, call_next):
        if not self.rate_limiter:
            return await call_next(request)

        # å¾ Authorization æ¨™é ­ç²å–ç”¨æˆ¶ ID
        user_id = self._extract_user_id(request)
        if not user_id:
            return await call_next(request)

        # æª¢æŸ¥é€Ÿç‡é™åˆ¶
        endpoint = request.url.path
        allowed, current_count = await self.rate_limiter.check_rate_limit(
            user_id, endpoint, limit=100, window=60
        )

        if not allowed:
            return JSONResponse(
                status_code=429,
                content={
                    "error": "Rate limit exceeded",
                    "retry_after": 60,
                    "current_count": current_count,
                },
                headers={"Retry-After": "60"},
            )

        response = await call_next(request)

        # æ·»åŠ é€Ÿç‡é™åˆ¶æ¨™é ­
        response.headers["X-RateLimit-Limit"] = "100"
        response.headers["X-RateLimit-Remaining"] = str(100 - current_count)
        response.headers["X-RateLimit-Reset"] = str(int(time.time() + 60))

        return response

    def _extract_user_id(self, request: Request) -> Optional[int]:
        """å¾è«‹æ±‚ä¸­æå–ç”¨æˆ¶ ID"""
        # é€™è£¡æ‡‰è©²æ ¹æ“šå¯¦éš›çš„èªè­‰æ–¹å¼å¯¦ç¾
        auth_header = request.headers.get("authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return None

        # ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›éœ€è¦è§£æ JWT
        try:
            # å‡è¨­ token ä¸­åŒ…å«ç”¨æˆ¶ ID
            # å¯¦éš›å¯¦ç¾éœ€è¦è§£æ JWT token
            return 1  # ç¤ºä¾‹ç”¨æˆ¶ ID
        except:
            return None


def create_optimized_app(
    cache_manager=None,
    rate_limiter=None,
    enable_compression: bool = True,
    enable_performance_logging: bool = True,
) -> FastAPI:
    """å‰µå»ºå„ªåŒ–çš„ FastAPI æ‡‰ç”¨"""

    @asynccontextmanager
    async def lifespan(app: FastAPI):
        # å•Ÿå‹•æ™‚çš„åˆå§‹åŒ–
        logger.info("ğŸš€ Starting optimized Auto Video API")
        yield
        # é—œé–‰æ™‚çš„æ¸…ç†
        logger.info("ğŸ›‘ Shutting down Auto Video API")

    app = FastAPI(
        title="Auto Video API",
        description="Optimized voice cloning and video generation API",
        version="1.0.0",
        lifespan=lifespan,
    )

    # CORS ä¸­ä»‹è»Ÿé«”
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰è©²é™åˆ¶
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # æ•ˆèƒ½ç›£æ§ä¸­ä»‹è»Ÿé«”
    if enable_performance_logging:
        app.add_middleware(
            PerformanceMiddleware,
            enable_detailed_logging=enable_performance_logging,
        )

    # å¿«å–ä¸­ä»‹è»Ÿé«”
    if cache_manager:
        app.add_middleware(
            CacheMiddleware, cache_manager=cache_manager, default_ttl=300
        )

    # é€Ÿç‡é™åˆ¶ä¸­ä»‹è»Ÿé«”
    if rate_limiter:
        app.add_middleware(RateLimitMiddleware, rate_limiter=rate_limiter)

    # å£“ç¸®ä¸­ä»‹è»Ÿé«”
    if enable_compression:
        app.add_middleware(
            CompressionMiddleware, minimum_size=1024, compression_level=6
        )

    return app


# æ•ˆèƒ½å„ªåŒ–å·¥å…·å‡½æ•¸
def async_cache(ttl: int = 300):
    """éåŒæ­¥å‡½æ•¸å¿«å–è£é£¾å™¨"""

    def decorator(func: Callable):
        cache = {}
        cache_times = {}

        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆå¿«å–éµ
            cache_key = f"{func.__name__}:{hash(str(args) + str(sorted(kwargs.items())))}"

            # æª¢æŸ¥å¿«å–
            now = time.time()
            if cache_key in cache:
                cached_time = cache_times.get(cache_key, 0)
                if now - cached_time < ttl:
                    logger.debug(f"Cache hit for {func.__name__}")
                    return cache[cache_key]

            # åŸ·è¡Œå‡½æ•¸
            result = await func(*args, **kwargs)

            # å­˜å…¥å¿«å–
            cache[cache_key] = result
            cache_times[cache_key] = now

            # æ¸…ç†éæœŸå¿«å–
            if len(cache) > 1000:  # é™åˆ¶å¿«å–å¤§å°
                expired_keys = [
                    k for k, t in cache_times.items() if now - t > ttl
                ]
                for k in expired_keys:
                    cache.pop(k, None)
                    cache_times.pop(k, None)

            logger.debug(f"Cache miss for {func.__name__}, result cached")
            return result

        return wrapper

    return decorator


def batch_processor(batch_size: int = 10, timeout: float = 1.0):
    """æ‰¹æ¬¡è™•ç†è£é£¾å™¨"""

    def decorator(func: Callable):
        pending_requests = []

        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            # å‰µå»ºè«‹æ±‚é …ç›®
            future = asyncio.Future()
            request_item = (args, kwargs, future)
            pending_requests.append(request_item)

            # å¦‚æœé”åˆ°æ‰¹æ¬¡å¤§å°ï¼Œç«‹å³è™•ç†
            if len(pending_requests) >= batch_size:
                await _process_batch(func, pending_requests.copy())
                pending_requests.clear()
            else:
                # è¨­ç½®è¶…æ™‚è™•ç†
                asyncio.create_task(
                    _timeout_handler(func, pending_requests, timeout)
                )

            return await future

        return wrapper

    async def _process_batch(func: Callable, batch: List):
        """è™•ç†æ‰¹æ¬¡è«‹æ±‚"""
        try:
            # æº–å‚™æ‰¹æ¬¡æ•¸æ“š
            batch_args = [item[0] for item in batch]
            batch_kwargs = [item[1] for item in batch]
            futures = [item[2] for item in batch]

            # åŸ·è¡Œæ‰¹æ¬¡è™•ç†
            results = await func(batch_args, batch_kwargs)

            # è¨­ç½®çµæœ
            for future, result in zip(futures, results):
                if not future.done():
                    future.set_result(result)

        except Exception as e:
            # è¨­ç½®ç•°å¸¸
            for _, _, future in batch:
                if not future.done():
                    future.set_exception(e)

    async def _timeout_handler(func: Callable, pending: List, timeout: float):
        """è¶…æ™‚è™•ç†å™¨"""
        await asyncio.sleep(timeout)
        if pending:
            await _process_batch(func, pending.copy())
            pending.clear()

    return decorator


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # å‰µå»ºå„ªåŒ–çš„æ‡‰ç”¨
    app = create_optimized_app(
        enable_compression=True, enable_performance_logging=True
    )

    @app.get("/api/health")
    async def health_check():
        return {"status": "healthy", "timestamp": datetime.now().isoformat()}

    @app.get("/api/test-cache")
    @async_cache(ttl=60)
    async def test_cache():
        # æ¨¡æ“¬æ…¢é€Ÿæ“ä½œ
        await asyncio.sleep(1)
        return {
            "data": "cached_result",
            "timestamp": datetime.now().isoformat(),
        }

    logger.info("API optimization configured successfully")
