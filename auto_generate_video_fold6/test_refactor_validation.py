#!/usr/bin/env python3
"""
TDD Refactor éšæ®µé©—è­‰æ¸¬è©¦
ç¢ºä¿é‡æ§‹å¾Œçš„ç³»çµ±ä¿æŒæ‰€æœ‰åŠŸèƒ½ä¸¦æå‡å“è³ª
"""

import asyncio
import pytest
import time
import sys
from pathlib import Path
from typing import Dict, Any
import logging

# æ·»åŠ è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent / "services" / "common"))

from base_service import (
    BaseService, ServiceState, ServiceError, MetricsCollector, 
    StructuredLogger, TraceContext, trace_span
)
from workflow_engine_refactored import (
    WorkflowEngine, WorkflowTemplate, WorkflowStep, WorkflowContext,
    WorkflowState, StepState, StepResult
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MockService(BaseService):
    """æ¸¬è©¦ç”¨æ¨¡æ“¬æœå‹™"""
    
    def __init__(self, config: Dict[str, Any] = None):
        super().__init__("mock_service", "1.0.0", config)
        self.initialized = False
        self.started = False
    
    async def _initialize(self):
        await asyncio.sleep(0.1)  # æ¨¡æ“¬åˆå§‹åŒ–å»¶é²
        self.initialized = True
    
    async def _startup(self):
        await asyncio.sleep(0.1)  # æ¨¡æ“¬å•Ÿå‹•å»¶é²
        self.started = True
    
    async def _shutdown(self):
        await asyncio.sleep(0.1)  # æ¨¡æ“¬é—œé–‰å»¶é²
        self.started = False

class MockWorkflowStep(WorkflowStep):
    """æ¸¬è©¦ç”¨å·¥ä½œæµç¨‹æ­¥é©Ÿ"""
    
    def __init__(self, step_name: str, delay: float = 0.1, should_fail: bool = False, **kwargs):
        super().__init__(step_name, **kwargs)
        self.delay = delay
        self.should_fail = should_fail
        self.execution_count = 0
    
    async def _execute_step(self, context: WorkflowContext) -> Dict[str, Any]:
        self.execution_count += 1
        await asyncio.sleep(self.delay)
        
        if self.should_fail:
            raise Exception(f"Mock step {self.step_name} failed")
        
        return {
            "step_name": self.step_name,
            "execution_count": self.execution_count,
            "timestamp": time.time()
        }

class RefactorValidationTest:
    """é‡æ§‹é©—è­‰æ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self):
        self.results = {
            "tests_passed": 0,
            "tests_failed": 0,
            "errors": []
        }
    
    def _record_result(self, test_name: str, success: bool, error: str = None):
        """è¨˜éŒ„æ¸¬è©¦çµæœ"""
        if success:
            self.results["tests_passed"] += 1
            logger.info(f"âœ… {test_name} é€šé")
        else:
            self.results["tests_failed"] += 1 
            self.results["errors"].append(f"{test_name}: {error}")
            logger.error(f"âŒ {test_name} å¤±æ•—: {error}")
    
    async def test_base_service_lifecycle(self):
        """æ¸¬è©¦åŸºç¤æœå‹™ç”Ÿå‘½é€±æœŸ"""
        try:
            service = MockService({"test_config": "value"})
            
            # æ¸¬è©¦åˆå§‹ç‹€æ…‹
            assert service.state == ServiceState.INITIALIZING
            assert not service.initialized
            assert not service.started
            
            # æ¸¬è©¦å•Ÿå‹•
            await service.start()
            assert service.state == ServiceState.HEALTHY
            assert service.initialized
            assert service.started
            
            # æ¸¬è©¦å¥åº·æª¢æŸ¥
            health = await service.health_check()
            assert health.status == ServiceState.HEALTHY
            
            # æ¸¬è©¦åœæ­¢
            await service.stop()
            assert service.state == ServiceState.STOPPED
            assert not service.started
            
            self._record_result("base_service_lifecycle", True)
            
        except Exception as e:
            self._record_result("base_service_lifecycle", False, str(e))
    
    async def test_base_service_context_manager(self):
        """æ¸¬è©¦åŸºç¤æœå‹™ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        try:
            async with MockService() as service:
                assert service.state == ServiceState.HEALTHY
                assert service.started
            
            # æœå‹™æ‡‰è©²è‡ªå‹•åœæ­¢
            assert service.state == ServiceState.STOPPED
            
            self._record_result("base_service_context_manager", True)
            
        except Exception as e:
            self._record_result("base_service_context_manager", False, str(e))
    
    async def test_metrics_collection(self):
        """æ¸¬è©¦æŒ‡æ¨™æ”¶é›†"""
        try:
            metrics = MetricsCollector()
            
            # æ¸¬è©¦è¨ˆæ•¸å™¨
            await metrics.increment_counter("test_counter", {"type": "test"})
            await metrics.increment_counter("test_counter", {"type": "test"}, 2)
            
            # æ¸¬è©¦é‡è¡¨
            await metrics.set_gauge("test_gauge", 42.5, {"unit": "percent"})
            
            # æ¸¬è©¦ç›´æ–¹åœ–
            await metrics.record_histogram("test_histogram", 1.5)
            await metrics.record_histogram("test_histogram", 2.5)
            await metrics.record_histogram("test_histogram", 3.5)
            
            # ç²å–æŒ‡æ¨™
            all_metrics = await metrics.get_metrics()
            assert len(all_metrics) > 0
            
            # é©—è­‰æŒ‡æ¨™é¡å‹
            counter_metrics = [m for m in all_metrics if "counter" in m["name"] or "_total" in m["name"]]
            gauge_metrics = [m for m in all_metrics if "gauge" in m["name"]]
            histogram_metrics = [m for m in all_metrics if "histogram" in m["name"]]
            
            assert len(counter_metrics) > 0
            assert len(gauge_metrics) > 0  
            assert len(histogram_metrics) > 0
            
            self._record_result("metrics_collection", True)
            
        except Exception as e:
            self._record_result("metrics_collection", False, str(e))
    
    async def test_structured_logging(self):
        """æ¸¬è©¦çµæ§‹åŒ–æ—¥èªŒ"""
        try:
            logger = StructuredLogger("test_service", "1.0.0")
            
            # æ¸¬è©¦ä¸åŒç´šåˆ¥çš„æ—¥èªŒ
            logger.info("Test info message", extra_field="value")
            logger.error("Test error message", error_code="TEST_ERROR")
            logger.warning("Test warning message", warning_type="validation")
            logger.debug("Test debug message", debug_info={"key": "value"})
            
            # å¦‚æœæ²’æœ‰ç•°å¸¸ï¼Œèªç‚ºæˆåŠŸ
            self._record_result("structured_logging", True)
            
        except Exception as e:
            self._record_result("structured_logging", False, str(e))
    
    async def test_trace_context(self):
        """æ¸¬è©¦åˆ†æ•£å¼è¿½è¹¤"""
        try:
            # å‰µå»ºè¿½è¹¤ä¸Šä¸‹æ–‡
            trace = TraceContext()
            assert trace.trace_id is not None
            assert trace.span_id is not None
            
            # æ·»åŠ æ¨™ç±¤å’Œæ—¥èªŒ
            trace.add_tag("operation", "test")
            trace.log("Test log message")
            
            # æ¸¬è©¦è¿½è¹¤ span
            logger = StructuredLogger("test", "1.0.0")
            async with trace_span("test_operation", trace, logger) as span:
                span.add_tag("test_tag", "test_value")
                span.log("Operation started")
                await asyncio.sleep(0.1)
            
            # é©—è­‰ span æ•¸æ“š
            span_data = span.to_dict()
            assert "trace_id" in span_data
            assert "span_id" in span_data
            assert "tags" in span_data
            assert "logs" in span_data
            
            self._record_result("trace_context", True)
            
        except Exception as e:
            self._record_result("trace_context", False, str(e))
    
    async def test_workflow_engine_basic(self):
        """æ¸¬è©¦å·¥ä½œæµç¨‹å¼•æ“åŸºæœ¬åŠŸèƒ½"""
        try:
            engine = WorkflowEngine()
            
            # å•Ÿå‹•å¼•æ“
            await engine.start()
            assert engine.state == ServiceState.HEALTHY
            
            # å‰µå»ºç°¡å–®å·¥ä½œæµç¨‹ç¯„æœ¬
            step1 = MockWorkflowStep("step1", delay=0.1)
            step2 = MockWorkflowStep("step2", delay=0.1)
            step1.next_step = step2
            
            template = WorkflowTemplate(
                name="test_workflow",
                description="Test workflow template",
                first_step=step1,
                timeout=10.0
            )
            
            # è¨»å†Šç¯„æœ¬
            engine.register_workflow_template(template)
            
            # å•Ÿå‹•å·¥ä½œæµç¨‹
            workflow_id = await engine.start_workflow(
                "test_workflow",
                "test_user",
                {"test_input": "value"}
            )
            
            assert workflow_id is not None
            
            # ç­‰å¾…å·¥ä½œæµç¨‹å®Œæˆ
            await asyncio.sleep(1.0)
            
            # æª¢æŸ¥ç‹€æ…‹
            status = await engine.get_workflow_status(workflow_id)
            if status:  # å¯èƒ½å·²ç¶“å®Œæˆä¸¦æ¸…ç†
                assert status["state"] in [WorkflowState.COMPLETED.value, WorkflowState.RUNNING.value]
            
            # ç²å–å¼•æ“çµ±è¨ˆ
            stats = await engine.get_engine_stats()
            assert stats["stats"]["total_workflows"] >= 1
            
            await engine.stop()
            
            self._record_result("workflow_engine_basic", True)
            
        except Exception as e:
            self._record_result("workflow_engine_basic", False, str(e))
    
    async def test_workflow_step_chain(self):
        """æ¸¬è©¦å·¥ä½œæµç¨‹æ­¥é©Ÿéˆ"""
        try:
            # å‰µå»ºæ­¥é©Ÿéˆ
            step1 = MockWorkflowStep("step1", delay=0.05)
            step2 = MockWorkflowStep("step2", delay=0.05, required_steps=["step1"])
            step3 = MockWorkflowStep("step3", delay=0.05, required_steps=["step2"])
            
            step1.next_step = step2
            step2.next_step = step3
            
            # å‰µå»ºåŸ·è¡Œä¸Šä¸‹æ–‡
            context = WorkflowContext(
                workflow_id="test_workflow",
                user_id="test_user",
                input_data={"test": "data"}
            )
            
            # åŸ·è¡Œæ­¥é©Ÿéˆ
            result_context = await step1.process(context)
            
            # é©—è­‰æ‰€æœ‰æ­¥é©Ÿéƒ½åŸ·è¡Œäº†
            assert "step1" in result_context.step_results
            assert "step2" in result_context.step_results
            assert "step3" in result_context.step_results
            
            # é©—è­‰æ­¥é©Ÿç‹€æ…‹
            for step_name in ["step1", "step2", "step3"]:
                result = result_context.step_results[step_name]
                assert result.state == StepState.COMPLETED
                assert result.duration is not None
                assert result.duration > 0
            
            # é©—è­‰æ­¥é©ŸåŸ·è¡Œé †åº
            step1_time = result_context.step_results["step1"].start_time
            step2_time = result_context.step_results["step2"].start_time  
            step3_time = result_context.step_results["step3"].start_time
            
            assert step1_time < step2_time < step3_time
            
            self._record_result("workflow_step_chain", True)
            
        except Exception as e:
            self._record_result("workflow_step_chain", False, str(e))
    
    async def test_workflow_error_handling(self):
        """æ¸¬è©¦å·¥ä½œæµç¨‹éŒ¯èª¤è™•ç†"""
        try:
            # å‰µå»ºæœƒå¤±æ•—çš„æ­¥é©Ÿ
            failing_step = MockWorkflowStep("failing_step", should_fail=True)
            
            context = WorkflowContext(
                workflow_id="test_error_workflow",
                user_id="test_user", 
                input_data={}
            )
            
            # åŸ·è¡Œæ‡‰è©²å¤±æ•—çš„æ­¥é©Ÿ
            result = await failing_step.execute(context)
            
            # é©—è­‰å¤±æ•—ç‹€æ…‹
            assert result.state == StepState.FAILED
            assert result.error is not None
            assert "failed" in result.error
            
            self._record_result("workflow_error_handling", True)
            
        except Exception as e:
            self._record_result("workflow_error_handling", False, str(e))
    
    async def test_workflow_prerequisites(self):
        """æ¸¬è©¦å·¥ä½œæµç¨‹å‰ç½®æ¢ä»¶"""
        try:
            # å‰µå»ºæœ‰å‰ç½®æ¢ä»¶çš„æ­¥é©Ÿ
            step_with_prereq = MockWorkflowStep("step_with_prereq", 
                                              required_steps=["missing_step"])
            
            context = WorkflowContext(
                workflow_id="test_prereq_workflow",
                user_id="test_user",
                input_data={}
            )
            
            # åŸ·è¡Œæ‡‰è©²è¢«è·³éçš„æ­¥é©Ÿ
            result = await step_with_prereq.execute(context)
            
            # é©—è­‰è·³éç‹€æ…‹
            assert result.state == StepState.SKIPPED
            assert "Prerequisites not met" in result.error
            
            self._record_result("workflow_prerequisites", True)
            
        except Exception as e:
            self._record_result("workflow_prerequisites", False, str(e))
    
    async def test_performance_metrics(self):
        """æ¸¬è©¦æ•ˆèƒ½æŒ‡æ¨™"""
        try:
            start_time = time.time()
            
            # å‰µå»ºæœå‹™ä¸¦åŸ·è¡Œæ“ä½œ
            async with MockService() as service:
                # è¨˜éŒ„ä¸€äº›æŒ‡æ¨™
                await service.metrics.increment_counter("operations", {"type": "test"})
                await service.metrics.set_gauge("cpu_usage", 45.2)
                await service.metrics.record_histogram("response_time", 0.123)
                
                # åŸ·è¡Œè¿½è¹¤æ“ä½œ
                async with service.trace_operation("performance_test") as span:
                    await asyncio.sleep(0.1)
                    span.add_tag("test_metric", "value")
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            # é©—è­‰åŸ·è¡Œæ™‚é–“åˆç†ï¼ˆæ‡‰è©²å°æ–¼1ç§’ï¼‰
            assert execution_time < 1.0
            
            # ç²å–æŒ‡æ¨™
            metrics = await service.metrics.get_metrics()
            assert len(metrics) > 0
            
            self._record_result("performance_metrics", True)
            
        except Exception as e:
            self._record_result("performance_metrics", False, str(e))
    
    def print_results(self):
        """æ‰“å°æ¸¬è©¦çµæœ"""
        total_tests = self.results["tests_passed"] + self.results["tests_failed"]
        success_rate = (self.results["tests_passed"] / total_tests * 100) if total_tests > 0 else 0
        
        logger.info("=" * 60)
        logger.info("ğŸ” TDD Refactor é©—è­‰æ¸¬è©¦çµæœ")
        logger.info("=" * 60)
        logger.info(f"âœ… é€šéæ¸¬è©¦: {self.results['tests_passed']}")
        logger.info(f"âŒ å¤±æ•—æ¸¬è©¦: {self.results['tests_failed']}")
        logger.info(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
        
        if self.results["errors"]:
            logger.info("\nğŸš¨ å¤±æ•—æ¸¬è©¦è©³æƒ…:")
            for error in self.results["errors"]:
                logger.info(f"  - {error}")
        
        # é‡æ§‹å“è³ªè©•ä¼°
        if success_rate >= 95:
            logger.info("\nğŸ† é‡æ§‹å“è³ª: å„ªç§€ - æ‰€æœ‰åŠŸèƒ½å®Œæ•´ä¿ç•™ä¸¦å¢å¼·")
        elif success_rate >= 85:
            logger.info("\nâœ… é‡æ§‹å“è³ª: è‰¯å¥½ - å¤§éƒ¨åˆ†åŠŸèƒ½æ­£å¸¸ï¼Œå°‘é‡å•é¡Œ")
        elif success_rate >= 70:
            logger.info("\nâš ï¸ é‡æ§‹å“è³ª: ä¸€èˆ¬ - å­˜åœ¨ä¸€äº›å•é¡Œéœ€è¦ä¿®å¾©")
        else:
            logger.info("\nâŒ é‡æ§‹å“è³ª: ä¸ä½³ - å­˜åœ¨é‡å¤§å•é¡Œï¼Œéœ€è¦é‡æ–°æª¢è¦–")
        
        return success_rate >= 85  # 85% ä»¥ä¸Šç®—é€šé

async def main():
    """åŸ·è¡Œé‡æ§‹é©—è­‰æ¸¬è©¦"""
    logger.info("ğŸš€ é–‹å§‹ TDD Refactor éšæ®µé©—è­‰æ¸¬è©¦")
    logger.info("ç›®æ¨™: ç¢ºä¿é‡æ§‹å¾Œç³»çµ±åŠŸèƒ½å®Œæ•´ä¸”å“è³ªæå‡")
    logger.info("=" * 60)
    
    test_suite = RefactorValidationTest()
    
    try:
        # åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦
        await test_suite.test_base_service_lifecycle()
        await test_suite.test_base_service_context_manager()
        await test_suite.test_metrics_collection()
        await test_suite.test_structured_logging()
        await test_suite.test_trace_context()
        await test_suite.test_workflow_engine_basic()
        await test_suite.test_workflow_step_chain()
        await test_suite.test_workflow_error_handling()
        await test_suite.test_workflow_prerequisites()
        await test_suite.test_performance_metrics()
        
        # æ‰“å°çµæœ
        success = test_suite.print_results()
        
        if success:
            logger.info("\nğŸ‰ TDD Refactor éšæ®µé©—è­‰æˆåŠŸï¼")
            logger.info("âœ¨ ç³»çµ±æ¶æ§‹å·²å„ªåŒ–ï¼Œå“è³ªé¡¯è‘—æå‡")
            logger.info("ğŸ¯ æº–å‚™é€²å…¥ç”Ÿç”¢ç´šéƒ¨ç½²éšæ®µ")
        else:
            logger.error("\nğŸ’¥ TDD Refactor éšæ®µé©—è­‰å¤±æ•—ï¼")
            logger.error("ğŸ”§ éœ€è¦ä¿®å¾©å•é¡Œå¾Œé‡æ–°é©—è­‰")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ é©—è­‰æ¸¬è©¦åŸ·è¡Œç•°å¸¸: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    
    if success:
        logger.info("ğŸ TDD Refactor éšæ®µå®Œæˆ - ç³»çµ±é‡æ§‹æˆåŠŸ")
        sys.exit(0)
    else:
        logger.error("ğŸ›‘ TDD Refactor éšæ®µå¤±æ•— - éœ€è¦ä¿®å¾©å•é¡Œ")
        sys.exit(1)