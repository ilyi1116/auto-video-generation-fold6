# ğŸš€ Auto Video éƒ¨ç½²æŒ‡å—

## ğŸ“– éƒ¨ç½²æ¦‚è¦½

æœ¬æŒ‡å—å°‡è©³ç´°èªªæ˜å¦‚ä½•åœ¨ä¸åŒç’°å¢ƒä¸­éƒ¨ç½² Auto Video ç³»çµ±ï¼ŒåŒ…æ‹¬é–‹ç™¼ã€æ¸¬è©¦ã€é ç”Ÿç”¢å’Œç”Ÿç”¢ç’°å¢ƒçš„å®Œæ•´éƒ¨ç½²æµç¨‹ã€‚

## ğŸ¯ éƒ¨ç½²æ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "Load Balancer Layer"
        LB[Nginx Load Balancer]
    end
    
    subgraph "Application Layer"
        GW[API Gateway]
        FE[Frontend]
        
        subgraph "Microservices"
            AUTH[Auth Service]
            VIDEO[Video Service]
            AI[AI Service]
            SOCIAL[Social Service]
            ANALYTICS[Analytics Service]
        end
    end
    
    subgraph "Data Layer"
        PG[PostgreSQL]
        REDIS[Redis]
        S3[Object Storage]
    end
    
    subgraph "Monitoring Layer"
        PROM[Prometheus]
        GRAF[Grafana]
        ALERT[Alertmanager]
    end
    
    LB --> GW
    LB --> FE
    GW --> AUTH
    GW --> VIDEO
    GW --> AI
    GW --> SOCIAL
    GW --> ANALYTICS
    
    AUTH --> PG
    AUTH --> REDIS
    VIDEO --> PG
    VIDEO --> S3
    AI --> S3
    
    PROM --> AUTH
    PROM --> VIDEO
    PROM --> AI
    GRAF --> PROM
    ALERT --> PROM
```

## ğŸ› ï¸ ç’°å¢ƒæº–å‚™

### ç³»çµ±è¦æ±‚

#### æœ€ä½é…ç½®
- **CPU**: 4 æ ¸å¿ƒ
- **è¨˜æ†¶é«”**: 16GB RAM
- **å„²å­˜**: 100GB SSD
- **ç¶²è·¯**: 100Mbps

#### æ¨è–¦é…ç½®ï¼ˆç”Ÿç”¢ç’°å¢ƒï¼‰
- **CPU**: 8+ æ ¸å¿ƒ
- **è¨˜æ†¶é«”**: 32GB+ RAM
- **å„²å­˜**: 500GB+ NVMe SSD
- **ç¶²è·¯**: 1Gbps+

#### è»Ÿé«”è¦æ±‚
- Docker 24.0+
- Docker Compose 2.20+
- Linux ç³»çµ± (Ubuntu 22.04 LTS æ¨è–¦)
- Git 2.30+

### ç¶²è·¯ç«¯å£é…ç½®

| æœå‹™ | ç«¯å£ | å”è­° | èªªæ˜ |
|------|------|------|------|
| Nginx | 80, 443 | HTTP/HTTPS | è² è¼‰å‡è¡¡å™¨ |
| API Gateway | 8000 | HTTP | ä¸»è¦ API å…¥å£ |
| Frontend | 3000 | HTTP | Web æ‡‰ç”¨ |
| Auth Service | 8001 | HTTP | èªè­‰æœå‹™ |
| Video Service | 8004 | HTTP | å½±ç‰‡è™•ç† |
| AI Service | 8005 | HTTP | AI æœå‹™ |
| PostgreSQL | 5432 | TCP | ä¸»è³‡æ–™åº« |
| Redis | 6379 | TCP | å¿«å–å’Œæœƒè©± |
| Prometheus | 9090 | HTTP | ç›£æ§æŒ‡æ¨™ |
| Grafana | 3001 | HTTP | ç›£æ§å„€è¡¨æ¿ |

## ğŸ—ï¸ éƒ¨ç½²æ–¹å¼

### æ–¹å¼ä¸€ï¼šDocker Composeï¼ˆæ¨è–¦ç”¨æ–¼é–‹ç™¼å’Œå°è¦æ¨¡éƒ¨ç½²ï¼‰

#### 1. æº–å‚™éƒ¨ç½²ç’°å¢ƒ

```bash
# å‰µå»ºéƒ¨ç½²ç›®éŒ„
mkdir -p /opt/autovideo
cd /opt/autovideo

# å…‹éš†å°ˆæ¡ˆ
git clone https://github.com/your-org/auto-video.git .

# å‰µå»ºå¿…è¦çš„ç›®éŒ„
mkdir -p {logs,data,ssl,backup}
```

#### 2. ç’°å¢ƒè®Šæ•¸é…ç½®

å‰µå»ºç”Ÿç”¢ç’°å¢ƒé…ç½®æ–‡ä»¶ï¼š

```bash
# è¤‡è£½ç’°å¢ƒè®Šæ•¸ç¯„æœ¬
cp .env.example .env.prod

# ç·¨è¼¯ç”Ÿç”¢ç’°å¢ƒé…ç½®
nano .env.prod
```

**`.env.prod` é…ç½®ç¯„ä¾‹ï¼š**

```bash
# åŸºæœ¬é…ç½®
ENVIRONMENT=production
DEBUG=false
SECRET_KEY=your-super-secret-key-32-chars-minimum

# è³‡æ–™åº«é…ç½®
DATABASE_URL=postgresql://autovideo:secure_password@postgres:5432/autovideo_prod
REDIS_URL=redis://redis:6379/0

# JWT é…ç½®
JWT_SECRET_KEY=your-jwt-secret-key-must-be-32-chars-or-longer
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=60

# AI æœå‹™ API é‡‘é‘°
OPENAI_API_KEY=sk-your-openai-api-key
GEMINI_API_KEY=your-gemini-api-key
ELEVENLABS_API_KEY=your-elevenlabs-api-key
STABILITY_API_KEY=your-stability-ai-key

# ç¤¾ç¾¤åª’é«” API
YOUTUBE_CLIENT_ID=your-youtube-client-id
YOUTUBE_CLIENT_SECRET=your-youtube-client-secret
TIKTOK_CLIENT_ID=your-tiktok-client-id
TIKTOK_CLIENT_SECRET=your-tiktok-client-secret

# æª”æ¡ˆå„²å­˜
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_REGION=ap-southeast-1
S3_BUCKET_NAME=autovideo-prod-storage

# éƒµä»¶æœå‹™
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# ç›£æ§é…ç½®
GRAFANA_ADMIN_PASSWORD=secure_grafana_password
PROMETHEUS_RETENTION_TIME=15d

# åŸŸåé…ç½®
DOMAIN=yourdomain.com
FRONTEND_URL=https://yourdomain.com
API_URL=https://api.yourdomain.com

# SSL é…ç½®
SSL_EMAIL=admin@yourdomain.com
```

#### 3. SSL è­‰æ›¸è¨­ç½®

**ä½¿ç”¨ Let's Encryptï¼ˆæ¨è–¦ï¼‰ï¼š**

```bash
# å®‰è£ Certbot
sudo apt install certbot python3-certbot-nginx

# ç”Ÿæˆ SSL è­‰æ›¸
sudo certbot --nginx -d yourdomain.com -d api.yourdomain.com

# è¤‡è£½è­‰æ›¸åˆ°å°ˆæ¡ˆç›®éŒ„
sudo cp /etc/letsencrypt/live/yourdomain.com/*.pem ssl/
sudo chown $(whoami):$(whoami) ssl/*.pem
```

**ä½¿ç”¨è‡ªç°½åè­‰æ›¸ï¼ˆåƒ…æ¸¬è©¦ç”¨ï¼‰ï¼š**

```bash
# ç”Ÿæˆè‡ªç°½åè­‰æ›¸
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout ssl/private.key \
  -out ssl/certificate.crt \
  -subj "/C=TW/ST=Taiwan/L=Taipei/O=AutoVideo/OU=IT/CN=yourdomain.com"
```

#### 4. éƒ¨ç½²åŸ·è¡Œ

```bash
# è¨­ç½®åŸ·è¡Œæ¬Šé™
chmod +x scripts/*.sh

# åŸ·è¡Œå¥åº·æª¢æŸ¥
./scripts/pre-deployment-check.sh

# å•Ÿå‹•ç”Ÿç”¢ç’°å¢ƒ
docker-compose -f docker-compose.prod.yml up -d

# æª¢æŸ¥æœå‹™ç‹€æ…‹
docker-compose -f docker-compose.prod.yml ps

# æŸ¥çœ‹æ—¥èªŒ
docker-compose -f docker-compose.prod.yml logs -f
```

#### 5. è³‡æ–™åº«åˆå§‹åŒ–

```bash
# ç­‰å¾…è³‡æ–™åº«å•Ÿå‹•
sleep 30

# åŸ·è¡Œè³‡æ–™åº«é·ç§»
docker-compose -f docker-compose.prod.yml exec api-gateway alembic upgrade head

# å‰µå»ºç®¡ç†å“¡å¸³æˆ¶
docker-compose -f docker-compose.prod.yml exec api-gateway python scripts/create-admin.py \
  --email admin@yourdomain.com \
  --password SecureAdminPassword123!

# è¼‰å…¥åˆå§‹æ•¸æ“š
docker-compose -f docker-compose.prod.yml exec api-gateway python scripts/load-initial-data.py
```

### æ–¹å¼äºŒï¼šKubernetes éƒ¨ç½²ï¼ˆæ¨è–¦ç”¨æ–¼å¤§è¦æ¨¡ç”Ÿç”¢ç’°å¢ƒï¼‰

#### 1. æº–å‚™ Kubernetes é›†ç¾¤

**ä½¿ç”¨ kubeadm æ­å»ºé›†ç¾¤ï¼š**

```bash
# ä¸»ç¯€é»åˆå§‹åŒ–
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

# é…ç½® kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# å®‰è£ç¶²è·¯å¤–æ›ï¼ˆFlannelï¼‰
kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml

# å…è¨±ä¸»ç¯€é»é‹è¡Œ Podï¼ˆå–®ç¯€é»éƒ¨ç½²ï¼‰
kubectl taint nodes --all node-role.kubernetes.io/control-plane-
```

**æˆ–ä½¿ç”¨æ‰˜ç®¡ Kubernetesï¼ˆæ¨è–¦ï¼‰ï¼š**
- AWS EKS
- Google GKE
- Azure AKS
- DigitalOcean Kubernetes

#### 2. å‰µå»º Kubernetes é…ç½®æ–‡ä»¶

**å‘½åç©ºé–“é…ç½® (`k8s/namespace.yaml`)ï¼š**

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: autovideo
  labels:
    name: autovideo
    environment: production
```

**ConfigMap é…ç½® (`k8s/configmap.yaml`)ï¼š**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: autovideo-config
  namespace: autovideo
data:
  ENVIRONMENT: "production"
  DEBUG: "false"
  DATABASE_HOST: "postgresql"
  DATABASE_PORT: "5432"
  DATABASE_NAME: "autovideo_prod"
  REDIS_HOST: "redis"
  REDIS_PORT: "6379"
  JWT_ALGORITHM: "HS256"
  JWT_EXPIRE_MINUTES: "60"
  FRONTEND_URL: "https://yourdomain.com"
  API_URL: "https://api.yourdomain.com"
```

**Secret é…ç½® (`k8s/secrets.yaml`)ï¼š**

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: autovideo-secrets
  namespace: autovideo
type: Opaque
data:
  DATABASE_PASSWORD: <base64-encoded-password>
  JWT_SECRET_KEY: <base64-encoded-jwt-secret>
  OPENAI_API_KEY: <base64-encoded-openai-key>
  GEMINI_API_KEY: <base64-encoded-gemini-key>
  AWS_ACCESS_KEY_ID: <base64-encoded-aws-key>
  AWS_SECRET_ACCESS_KEY: <base64-encoded-aws-secret>
```

**PostgreSQL éƒ¨ç½² (`k8s/postgresql.yaml`)ï¼š**

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
  namespace: autovideo
spec:
  serviceName: postgresql
  replicas: 1
  selector:
    matchLabels:
      app: postgresql
  template:
    metadata:
      labels:
        app: postgresql
    spec:
      containers:
      - name: postgresql
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          valueFrom:
            configMapKeyRef:
              name: autovideo-config
              key: DATABASE_NAME
        - name: POSTGRES_USER
          value: "autovideo"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: autovideo-secrets
              key: DATABASE_PASSWORD
        volumeMounts:
        - name: postgresql-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
  volumeClaimTemplates:
  - metadata:
      name: postgresql-storage
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "standard"
      resources:
        requests:
          storage: 20Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgresql
  namespace: autovideo
spec:
  selector:
    app: postgresql
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
```

**API Gateway éƒ¨ç½² (`k8s/api-gateway.yaml`)ï¼š**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: autovideo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: autovideo/api-gateway:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          value: "postgresql://autovideo:$(DATABASE_PASSWORD)@postgresql:5432/autovideo_prod"
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: autovideo-secrets
              key: DATABASE_PASSWORD
        - name: JWT_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: autovideo-secrets
              key: JWT_SECRET_KEY
        envFrom:
        - configMapRef:
            name: autovideo-config
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
  namespace: autovideo
spec:
  selector:
    app: api-gateway
  ports:
  - port: 8000
    targetPort: 8000
  type: ClusterIP
```

**Ingress é…ç½® (`k8s/ingress.yaml`)ï¼š**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: autovideo-ingress
  namespace: autovideo
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/use-regex: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - yourdomain.com
    - api.yourdomain.com
    secretName: autovideo-tls
  rules:
  - host: yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend
            port:
              number: 3000
  - host: api.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-gateway
            port:
              number: 8000
```

#### 3. éƒ¨ç½²åˆ° Kubernetes

```bash
# å‰µå»ºå‘½åç©ºé–“
kubectl apply -f k8s/namespace.yaml

# å‰µå»º ConfigMap å’Œ Secrets
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secrets.yaml

# éƒ¨ç½²è³‡æ–™åº«
kubectl apply -f k8s/postgresql.yaml
kubectl apply -f k8s/redis.yaml

# ç­‰å¾…è³‡æ–™åº«å•Ÿå‹•
kubectl wait --for=condition=ready pod -l app=postgresql -n autovideo --timeout=300s

# éƒ¨ç½²å¾®æœå‹™
kubectl apply -f k8s/api-gateway.yaml
kubectl apply -f k8s/auth-service.yaml
kubectl apply -f k8s/video-service.yaml
kubectl apply -f k8s/ai-service.yaml

# éƒ¨ç½²å‰ç«¯
kubectl apply -f k8s/frontend.yaml

# è¨­ç½® Ingress
kubectl apply -f k8s/ingress.yaml

# æª¢æŸ¥éƒ¨ç½²ç‹€æ…‹
kubectl get pods -n autovideo
kubectl get services -n autovideo
kubectl get ingress -n autovideo
```

## ğŸ” å¥åº·æª¢æŸ¥èˆ‡ç›£æ§

### æ‡‰ç”¨å¥åº·æª¢æŸ¥

æ¯å€‹æœå‹™éƒ½æ‡‰å¯¦ç¾ä»¥ä¸‹å¥åº·æª¢æŸ¥ç«¯é»ï¼š

```python
# å¥åº·æª¢æŸ¥ç«¯é»å¯¦ç¾
from fastapi import FastAPI, HTTPException
import asyncio
import asyncpg
import redis

app = FastAPI()

@app.get("/health")
async def health_check():
    """åŸºæœ¬å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "service": "api-gateway",
        "version": "1.0.0"
    }

@app.get("/ready")
async def readiness_check():
    """å°±ç·’æª¢æŸ¥ - æª¢æŸ¥ä¾è³´æœå‹™"""
    checks = {
        "database": False,
        "redis": False,
        "external_apis": False
    }
    
    try:
        # æª¢æŸ¥è³‡æ–™åº«é€£æ¥
        conn = await asyncpg.connect(DATABASE_URL)
        await conn.fetchval("SELECT 1")
        await conn.close()
        checks["database"] = True
    except Exception:
        pass
    
    try:
        # æª¢æŸ¥ Redis é€£æ¥
        r = redis.Redis.from_url(REDIS_URL)
        r.ping()
        checks["redis"] = True
    except Exception:
        pass
    
    try:
        # æª¢æŸ¥å¤–éƒ¨ API
        async with httpx.AsyncClient() as client:
            response = await client.get("https://api.openai.com/v1/models", timeout=5)
            if response.status_code == 200:
                checks["external_apis"] = True
    except Exception:
        pass
    
    all_healthy = all(checks.values())
    status_code = 200 if all_healthy else 503
    
    return JSONResponse(
        status_code=status_code,
        content={
            "status": "ready" if all_healthy else "not_ready",
            "checks": checks,
            "timestamp": datetime.utcnow().isoformat()
        }
    )
```

### ç›£æ§é…ç½®

**Prometheus é…ç½® (`monitoring/prometheus/prometheus.yml`)ï¼š**

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'api-gateway'
    static_configs:
      - targets: ['api-gateway:8000']
    metrics_path: /metrics
    scrape_interval: 30s

  - job_name: 'auth-service'
    static_configs:
      - targets: ['auth-service:8001']
    metrics_path: /metrics

  - job_name: 'video-service'
    static_configs:
      - targets: ['video-service:8004']
    metrics_path: /metrics

  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
```

**å‘Šè­¦è¦å‰‡ (`monitoring/prometheus/rules/alerts.yml`)ï¼š**

```yaml
groups:
  - name: autovideo_alerts
    rules:
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.instance }} is down"
          description: "{{ $labels.instance }} has been down for more than 1 minute."

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second."

      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }} seconds."

      - alert: DatabaseConnectionFailure
        expr: postgresql_up == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Database connection failure"
          description: "Cannot connect to PostgreSQL database."

      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 90%."

      - alert: DiskSpaceLow
        expr: (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / node_filesystem_size_bytes{fstype!="tmpfs"} > 0.8
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Disk space low"
          description: "Disk usage is above 80%."
```

## ğŸ”„ CI/CD æµç¨‹

### GitHub Actions é…ç½®

**ä¸»è¦å·¥ä½œæµç¨‹ (`.github/workflows/deploy.yml`)ï¼š**

```yaml
name: Deploy to Production

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run tests
      run: |
        pytest tests/ --cov=. --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Run security scan
      uses: github/super-linter@v4
      env:
        DEFAULT_BRANCH: main
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Run Snyk security scan
      uses: snyk/actions/python@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

  build:
    needs: [test, security]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [api-gateway, auth-service, video-service, ai-service, frontend]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./services/${{ matrix.service }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG }}
    
    - name: Deploy to Kubernetes
      run: |
        # æ›´æ–°æ˜ åƒæ¨™ç±¤
        sed -i "s/:latest/:${{ github.sha }}/g" k8s/*.yaml
        
        # æ‡‰ç”¨é…ç½®
        kubectl apply -f k8s/
        
        # ç­‰å¾…éƒ¨ç½²å®Œæˆ
        kubectl rollout status deployment/api-gateway -n autovideo
        kubectl rollout status deployment/auth-service -n autovideo
        kubectl rollout status deployment/video-service -n autovideo
        kubectl rollout status deployment/ai-service -n autovideo
        kubectl rollout status deployment/frontend -n autovideo
    
    - name: Run smoke tests
      run: |
        # ç­‰å¾…æœå‹™å°±ç·’
        sleep 30
        
        # åŸ·è¡Œç…™éœ§æ¸¬è©¦
        curl -f https://api.yourdomain.com/health || exit 1
        curl -f https://yourdomain.com || exit 1
        
        # åŸ·è¡Œ API æ¸¬è©¦
        python scripts/smoke-tests.py

  notify:
    needs: [deploy]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Notify Slack
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

### è—ç¶ éƒ¨ç½²è…³æœ¬

```bash
#!/bin/bash
# scripts/blue-green-deploy.sh

set -e

NAMESPACE="autovideo"
NEW_VERSION=$1
CURRENT_VERSION=$(kubectl get deployment api-gateway -n $NAMESPACE -o jsonpath='{.spec.template.spec.containers[0].image}' | cut -d':' -f2)

if [ -z "$NEW_VERSION" ]; then
    echo "Usage: $0 <new-version>"
    exit 1
fi

echo "Starting blue-green deployment..."
echo "Current version: $CURRENT_VERSION"
echo "New version: $NEW_VERSION"

# 1. éƒ¨ç½²æ–°ç‰ˆæœ¬ï¼ˆç¶ è‰²ç’°å¢ƒï¼‰
echo "Deploying green environment..."
sed "s/:$CURRENT_VERSION/:$NEW_VERSION/g" k8s/*.yaml | kubectl apply -f -

# 2. ç­‰å¾…æ–°ç‰ˆæœ¬å°±ç·’
echo "Waiting for green environment to be ready..."
kubectl rollout status deployment/api-gateway -n $NAMESPACE --timeout=600s
kubectl rollout status deployment/auth-service -n $NAMESPACE --timeout=600s
kubectl rollout status deployment/video-service -n $NAMESPACE --timeout=600s

# 3. åŸ·è¡Œå¥åº·æª¢æŸ¥
echo "Running health checks..."
for i in {1..30}; do
    if kubectl exec deployment/api-gateway -n $NAMESPACE -- curl -f http://localhost:8000/health; then
        echo "Health check passed"
        break
    fi
    
    if [ $i -eq 30 ]; then
        echo "Health check failed, rolling back..."
        kubectl rollout undo deployment/api-gateway -n $NAMESPACE
        kubectl rollout undo deployment/auth-service -n $NAMESPACE
        kubectl rollout undo deployment/video-service -n $NAMESPACE
        exit 1
    fi
    
    echo "Health check attempt $i failed, retrying..."
    sleep 10
done

# 4. åŸ·è¡Œç…™éœ§æ¸¬è©¦
echo "Running smoke tests..."
if ! python scripts/smoke-tests.py; then
    echo "Smoke tests failed, rolling back..."
    kubectl rollout undo deployment/api-gateway -n $NAMESPACE
    exit 1
fi

# 5. åˆ‡æ›æµé‡ï¼ˆæ›´æ–° Ingressï¼‰
echo "Switching traffic to green environment..."
kubectl patch ingress autovideo-ingress -n $NAMESPACE -p '{"metadata":{"labels":{"version":"'$NEW_VERSION'"}}}'

echo "Blue-green deployment completed successfully!"
echo "New version $NEW_VERSION is now live"

# 6. æ¸…ç†èˆŠç‰ˆæœ¬ï¼ˆå¯é¸ï¼Œå»ºè­°ä¿ç•™ä¸€æ®µæ™‚é–“ä»¥ä¾¿å¿«é€Ÿå›æ»¾ï¼‰
read -p "Do you want to clean up the blue environment? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "Cleaning up blue environment..."
    # é€™è£¡å¯ä»¥æ·»åŠ æ¸…ç†é‚è¼¯
fi
```

## ğŸ” å®‰å…¨é…ç½®

### SSL/TLS è¨­ç½®

**Nginx SSL é…ç½®ï¼š**

```nginx
# /etc/nginx/sites-available/autovideo
server {
    listen 80;
    server_name yourdomain.com api.yourdomain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name yourdomain.com;

    ssl_certificate /etc/ssl/certs/yourdomain.com.crt;
    ssl_certificate_key /etc/ssl/private/yourdomain.com.key;
    
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Referrer-Policy "strict-origin-when-cross-origin";

    location / {
        proxy_pass http://frontend:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket æ”¯æ´
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}

server {
    listen 443 ssl http2;
    server_name api.yourdomain.com;

    ssl_certificate /etc/ssl/certs/yourdomain.com.crt;
    ssl_certificate_key /etc/ssl/private/yourdomain.com.key;
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req zone=api burst=20 nodelay;

    location / {
        proxy_pass http://api-gateway:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # CORS headers
        add_header 'Access-Control-Allow-Origin' 'https://yourdomain.com' always;
        add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;
        add_header 'Access-Control-Allow-Headers' 'Authorization, Content-Type' always;
        
        if ($request_method = 'OPTIONS') {
            return 204;
        }
    }
}
```

### é˜²ç«ç‰†è¨­ç½®

```bash
# UFW é˜²ç«ç‰†é…ç½®
sudo ufw --force reset
sudo ufw default deny incoming
sudo ufw default allow outgoing

# å…è¨± SSH
sudo ufw allow 22/tcp

# å…è¨± HTTP/HTTPS
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp

# å…è¨±ç›£æ§ç«¯å£ï¼ˆåƒ…å…§éƒ¨ï¼‰
sudo ufw allow from 10.0.0.0/8 to any port 9090
sudo ufw allow from 10.0.0.0/8 to any port 3001

# å•Ÿç”¨é˜²ç«ç‰†
sudo ufw --force enable

# æª¢æŸ¥ç‹€æ…‹
sudo ufw status
```

## ğŸ“Š æ•ˆèƒ½èª¿æ ¡

### è³‡æ–™åº«å„ªåŒ–

**PostgreSQL é…ç½® (`postgresql.conf`)ï¼š**

```ini
# è¨˜æ†¶é«”è¨­å®š
shared_buffers = 4GB                    # ç³»çµ±è¨˜æ†¶é«”çš„ 25%
effective_cache_size = 12GB             # ç³»çµ±è¨˜æ†¶é«”çš„ 75%
maintenance_work_mem = 512MB
work_mem = 16MB

# æª¢æŸ¥é»è¨­å®š
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100

# é€£æ¥è¨­å®š
max_connections = 200
shared_preload_libraries = 'pg_stat_statements'

# æ—¥èªŒè¨­å®š
log_destination = 'stderr'
logging_collector = on
log_directory = 'log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_min_duration_statement = 1000      # è¨˜éŒ„åŸ·è¡Œè¶…é 1 ç§’çš„æŸ¥è©¢
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on
```

### Redis èª¿æ ¡

**Redis é…ç½® (`redis.conf`)ï¼š**

```ini
# è¨˜æ†¶é«”è¨­å®š
maxmemory 2gb
maxmemory-policy allkeys-lru

# æŒä¹…æ€§è¨­å®š
save 900 1
save 300 10
save 60 10000
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes

# ç¶²è·¯è¨­å®š
tcp-keepalive 300
timeout 0

# å®‰å…¨è¨­å®š
requirepass your_redis_password
rename-command FLUSHDB ""
rename-command FLUSHALL ""
rename-command CONFIG "CONFIG_c0nf1g_ch4ng3_m3"
```

## ğŸ”§ ç¶­è­·èˆ‡å‚™ä»½

### è‡ªå‹•åŒ–å‚™ä»½è…³æœ¬

```bash
#!/bin/bash
# scripts/backup.sh

set -e

BACKUP_DIR="/opt/autovideo/backup"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

# å‰µå»ºå‚™ä»½ç›®éŒ„
mkdir -p $BACKUP_DIR/{database,files,config}

echo "Starting backup process at $(date)"

# 1. è³‡æ–™åº«å‚™ä»½
echo "Backing up PostgreSQL..."
docker-compose exec -T postgres pg_dump -U autovideo -d autovideo_prod > \
    $BACKUP_DIR/database/postgres_backup_$DATE.sql

# 2. Redis å‚™ä»½
echo "Backing up Redis..."
docker-compose exec -T redis redis-cli BGSAVE
sleep 5
docker cp $(docker-compose ps -q redis):/data/dump.rdb \
    $BACKUP_DIR/database/redis_backup_$DATE.rdb

# 3. æª”æ¡ˆå‚™ä»½
echo "Backing up uploaded files..."
if [ -d "/opt/autovideo/data/uploads" ]; then
    tar -czf $BACKUP_DIR/files/uploads_backup_$DATE.tar.gz \
        -C /opt/autovideo/data uploads/
fi

# 4. é…ç½®å‚™ä»½
echo "Backing up configuration..."
tar -czf $BACKUP_DIR/config/config_backup_$DATE.tar.gz \
    -C /opt/autovideo \
    .env.prod docker-compose.prod.yml config/ k8s/

# 5. ä¸Šå‚³åˆ°é›²ç«¯å­˜å„²ï¼ˆå¯é¸ï¼‰
if [ ! -z "$AWS_BACKUP_BUCKET" ]; then
    echo "Uploading to S3..."
    aws s3 sync $BACKUP_DIR s3://$AWS_BACKUP_BUCKET/autovideo-backup/$DATE/
fi

# 6. æ¸…ç†èˆŠå‚™ä»½
echo "Cleaning up old backups..."
find $BACKUP_DIR -type f -mtime +$RETENTION_DAYS -delete

# 7. é©—è­‰å‚™ä»½
echo "Verifying backup integrity..."
if [ -f "$BACKUP_DIR/database/postgres_backup_$DATE.sql" ]; then
    if pg_restore --list $BACKUP_DIR/database/postgres_backup_$DATE.sql > /dev/null 2>&1; then
        echo "PostgreSQL backup verified successfully"
    else
        echo "WARNING: PostgreSQL backup verification failed"
    fi
fi

echo "Backup process completed at $(date)"

# ç™¼é€é€šçŸ¥
curl -X POST "$SLACK_WEBHOOK_URL" \
    -H 'Content-type: application/json' \
    --data '{"text":"âœ… AutoVideo backup completed successfully at '$(date)'"}'
```

### ç³»çµ±æ›´æ–°è…³æœ¬

```bash
#!/bin/bash
# scripts/update-system.sh

set -e

echo "Starting system update process..."

# 1. å‚™ä»½ç•¶å‰ç‹€æ…‹
echo "Creating backup before update..."
./scripts/backup.sh

# 2. æ‹‰å–æœ€æ–°ç¨‹å¼ç¢¼
echo "Pulling latest code..."
git pull origin main

# 3. æ›´æ–° Docker æ˜ åƒ
echo "Updating Docker images..."
docker-compose -f docker-compose.prod.yml pull

# 4. åŸ·è¡Œè³‡æ–™åº«é·ç§»
echo "Running database migrations..."
docker-compose -f docker-compose.prod.yml run --rm api-gateway alembic upgrade head

# 5. é‡å•Ÿæœå‹™
echo "Restarting services..."
docker-compose -f docker-compose.prod.yml up -d

# 6. å¥åº·æª¢æŸ¥
echo "Performing health checks..."
sleep 30

for service in api-gateway auth-service video-service ai-service frontend; do
    if ! docker-compose -f docker-compose.prod.yml exec $service curl -f http://localhost:8000/health; then
        echo "Health check failed for $service"
        
        # å›æ»¾
        echo "Rolling back..."
        git checkout HEAD~1
        docker-compose -f docker-compose.prod.yml up -d
        exit 1
    fi
done

echo "System update completed successfully!"
```

## ğŸš¨ æ•…éšœè™•ç†

### å¸¸è¦‹å•é¡Œæ’è§£

#### 1. æœå‹™ç„¡æ³•å•Ÿå‹•

```bash
# æª¢æŸ¥æœå‹™ç‹€æ…‹
docker-compose -f docker-compose.prod.yml ps

# æŸ¥çœ‹æœå‹™æ—¥èªŒ
docker-compose -f docker-compose.prod.yml logs service-name

# æª¢æŸ¥è³‡æºä½¿ç”¨
docker stats

# æª¢æŸ¥ç£ç¢Ÿç©ºé–“
df -h

# æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨
free -h
```

#### 2. è³‡æ–™åº«é€£æ¥å•é¡Œ

```bash
# æª¢æŸ¥ PostgreSQL ç‹€æ…‹
docker-compose -f docker-compose.prod.yml exec postgres pg_isready -U autovideo

# æª¢æŸ¥é€£æ¥æ•¸
docker-compose -f docker-compose.prod.yml exec postgres psql -U autovideo -d autovideo_prod -c "SELECT count(*) FROM pg_stat_activity;"

# æª¢æŸ¥è³‡æ–™åº«å¤§å°
docker-compose -f docker-compose.prod.yml exec postgres psql -U autovideo -d autovideo_prod -c "SELECT pg_size_pretty(pg_database_size('autovideo_prod'));"
```

#### 3. æ•ˆèƒ½å•é¡Œè¨ºæ–·

```bash
# æª¢æŸ¥ç³»çµ±è² è¼‰
htop

# æª¢æŸ¥ I/O ä½¿ç”¨
iotop

# æª¢æŸ¥ç¶²è·¯é€£æ¥
netstat -tulpn

# æª¢æŸ¥æ‡‰ç”¨æ—¥èªŒä¸­çš„æ…¢æŸ¥è©¢
grep "slow query" /opt/autovideo/logs/*.log
```

### ç½é›£æ¢å¾©æµç¨‹

```bash
#!/bin/bash
# scripts/disaster-recovery.sh

BACKUP_DATE=$1
BACKUP_DIR="/opt/autovideo/backup"

if [ -z "$BACKUP_DATE" ]; then
    echo "Usage: $0 <backup-date>"
    echo "Available backups:"
    ls -la $BACKUP_DIR/database/postgres_backup_*.sql | head -10
    exit 1
fi

echo "Starting disaster recovery process..."
echo "WARNING: This will overwrite current data!"
read -p "Are you sure you want to continue? (yes/no): " -r

if [[ ! $REPLY =~ ^yes$ ]]; then
    echo "Recovery cancelled"
    exit 1
fi

# 1. åœæ­¢æ‰€æœ‰æœå‹™
echo "Stopping services..."
docker-compose -f docker-compose.prod.yml down

# 2. æ¢å¾©è³‡æ–™åº«
echo "Restoring PostgreSQL database..."
docker-compose -f docker-compose.prod.yml up -d postgres
sleep 30

# åˆªé™¤ç¾æœ‰è³‡æ–™åº«
docker-compose -f docker-compose.prod.yml exec postgres dropdb -U autovideo autovideo_prod
docker-compose -f docker-compose.prod.yml exec postgres createdb -U autovideo autovideo_prod

# æ¢å¾©è³‡æ–™
docker-compose -f docker-compose.prod.yml exec -T postgres psql -U autovideo -d autovideo_prod < \
    $BACKUP_DIR/database/postgres_backup_$BACKUP_DATE.sql

# 3. æ¢å¾© Redis
echo "Restoring Redis..."
docker-compose -f docker-compose.prod.yml up -d redis
sleep 10
docker cp $BACKUP_DIR/database/redis_backup_$BACKUP_DATE.rdb \
    $(docker-compose ps -q redis):/data/dump.rdb
docker-compose -f docker-compose.prod.yml restart redis

# 4. æ¢å¾©æª”æ¡ˆ
echo "Restoring files..."
if [ -f "$BACKUP_DIR/files/uploads_backup_$BACKUP_DATE.tar.gz" ]; then
    tar -xzf $BACKUP_DIR/files/uploads_backup_$BACKUP_DATE.tar.gz -C /opt/autovideo/data/
fi

# 5. å•Ÿå‹•æ‰€æœ‰æœå‹™
echo "Starting all services..."
docker-compose -f docker-compose.prod.yml up -d

# 6. é©—è­‰æ¢å¾©
echo "Verifying recovery..."
sleep 60

if curl -f http://localhost:8000/health; then
    echo "âœ… Disaster recovery completed successfully!"
else
    echo "âŒ Recovery verification failed"
    exit 1
fi
```

---

## ğŸ“ æ”¯æ´èˆ‡ç¶­è­·

### æ—¥å¸¸ç¶­è­·æª¢æŸ¥æ¸…å–®

**æ¯æ—¥æª¢æŸ¥ï¼š**
- [ ] æª¢æŸ¥æ‰€æœ‰æœå‹™å¥åº·ç‹€æ…‹
- [ ] æŸ¥çœ‹éŒ¯èª¤æ—¥èªŒ
- [ ] ç›£æ§è³‡æºä½¿ç”¨ç‡
- [ ] é©—è­‰å‚™ä»½å®Œæˆ

**æ¯é€±æª¢æŸ¥ï¼š**
- [ ] æ›´æ–°ä¾è³´å¥—ä»¶
- [ ] æª¢æŸ¥å®‰å…¨æ¼æ´
- [ ] æ¸…ç†æ—¥èªŒæ–‡ä»¶
- [ ] æ¸¬è©¦ç½é›£æ¢å¾©æµç¨‹

**æ¯æœˆæª¢æŸ¥ï¼š**
- [ ] åŸ·è¡Œå®Œæ•´ç³»çµ±æ¸¬è©¦
- [ ] æ›´æ–° SSL è­‰æ›¸ï¼ˆå¦‚éœ€è¦ï¼‰
- [ ] æª¢æŸ¥æ•ˆèƒ½æŒ‡æ¨™è¶¨å‹¢
- [ ] æ›´æ–°éƒ¨ç½²æ–‡æª”

### è¯ç¹«è³‡è¨Š

- **æŠ€è¡“æ”¯æ´**: support@autovideo.com
- **ç·Šæ€¥è¯ç¹«**: +886 2 1234 5678
- **æ–‡æª”æ›´æ–°**: è«‹æäº¤ GitHub Issues

---

*æœ¬éƒ¨ç½²æŒ‡å—æœƒæŒçºŒæ›´æ–°ï¼Œå¦‚æœ‰ä»»ä½•å•é¡Œæˆ–å»ºè­°ï¼Œæ­¡è¿é€é GitHub Issues å›é¥‹ã€‚*